{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Soal 3.ipynb","provenance":[],"collapsed_sections":["cScGgSubT0ek","ox8GcKg1UWov","p8tcBAhNUIfp","zRxR_pfKUnQp"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cScGgSubT0ek"},"source":["# Install dan Download Category Encoder\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tq47dLSHlcV4","executionInfo":{"status":"ok","timestamp":1610160717758,"user_tz":-420,"elapsed":4818,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"489f6de7-9226-44db-b645-999d7d9788a0"},"source":["pip install category_encoders"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting category_encoders\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n","\r\u001b[K     |████                            | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 16.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.19.4)\n","Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.0)\n","Installing collected packages: category-encoders\n","Successfully installed category-encoders-2.2.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ox8GcKg1UWov"},"source":["# Install Ipython Autotime"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2cOigV4moN4","executionInfo":{"status":"ok","timestamp":1610160720591,"user_tz":-420,"elapsed":7642,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"68292f7f-cf48-44eb-b772-17047d904440"},"source":["!pip install ipython-autotime\r\n","%load_ext autotime"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting ipython-autotime\n","  Downloading https://files.pythonhosted.org/packages/d6/c5/013f5aa3b56c6d2c58634bc979773df44ab2226cf4fa787daf0bfeeea0b4/ipython_autotime-0.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (51.1.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.6.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n","Installing collected packages: ipython-autotime\n","Successfully installed ipython-autotime-0.3.0\n","time: 221 µs (started: 2021-01-09 02:51:59 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p8tcBAhNUIfp"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9telD4jy3LC6","executionInfo":{"status":"ok","timestamp":1610160723698,"user_tz":-420,"elapsed":10742,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"d111fe33-0dd3-49b1-ca86-762ab950c8b6"},"source":["import keras\r\n","import numpy as np\r\n","import pandas as pd\r\n","import math\r\n","from sklearn.model_selection import train_test_split\r\n","from matplotlib import pyplot\r\n","from keras.callbacks import EarlyStopping\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\r\n","from sklearn.svm import SVC\r\n","from sklearn.neighbors import KNeighborsClassifier\r\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\r\n","from sklearn.model_selection import train_test_split # Import train_test_split function\r\n","from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\r\n","from sklearn import svm\r\n","from sklearn.model_selection import KFold\r\n","from category_encoders.target_encoder import TargetEncoder\r\n","\r\n","from sklearn import tree\r\n","import matplotlib.pyplot as plt\r\n","\r\n","from category_encoders.target_encoder import TargetEncoder"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["time: 3.14 s (started: 2021-01-09 02:51:59 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zRxR_pfKUnQp"},"source":["# Load Data"]},{"cell_type":"markdown","metadata":{"id":"Z4HFtROXUymR"},"source":["Read data dan drop kolom yang tidak dibutuhkan"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"zCDDvlfC3S71","executionInfo":{"status":"ok","timestamp":1610160724254,"user_tz":-420,"elapsed":11290,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"00cb17d8-d985-4044-ac31-4557fbd7bf55"},"source":["df = pd.read_csv(\"winemag-data_first150k.csv\")\r\n","df.drop(columns=['description', 'Unnamed: 0', 'region_2'], inplace=True)\r\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>country</th>\n","      <th>designation</th>\n","      <th>points</th>\n","      <th>price</th>\n","      <th>province</th>\n","      <th>region_1</th>\n","      <th>variety</th>\n","      <th>winery</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>US</td>\n","      <td>Martha's Vineyard</td>\n","      <td>96</td>\n","      <td>235.0</td>\n","      <td>California</td>\n","      <td>Napa Valley</td>\n","      <td>Cabernet Sauvignon</td>\n","      <td>Heitz</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Spain</td>\n","      <td>Carodorum Selección Especial Reserva</td>\n","      <td>96</td>\n","      <td>110.0</td>\n","      <td>Northern Spain</td>\n","      <td>Toro</td>\n","      <td>Tinta de Toro</td>\n","      <td>Bodega Carmen Rodríguez</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>US</td>\n","      <td>Special Selected Late Harvest</td>\n","      <td>96</td>\n","      <td>90.0</td>\n","      <td>California</td>\n","      <td>Knights Valley</td>\n","      <td>Sauvignon Blanc</td>\n","      <td>Macauley</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>US</td>\n","      <td>Reserve</td>\n","      <td>96</td>\n","      <td>65.0</td>\n","      <td>Oregon</td>\n","      <td>Willamette Valley</td>\n","      <td>Pinot Noir</td>\n","      <td>Ponzi</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>France</td>\n","      <td>La Brûlade</td>\n","      <td>95</td>\n","      <td>66.0</td>\n","      <td>Provence</td>\n","      <td>Bandol</td>\n","      <td>Provence red blend</td>\n","      <td>Domaine de la Bégude</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>150925</th>\n","      <td>Italy</td>\n","      <td>NaN</td>\n","      <td>91</td>\n","      <td>20.0</td>\n","      <td>Southern Italy</td>\n","      <td>Fiano di Avellino</td>\n","      <td>White Blend</td>\n","      <td>Feudi di San Gregorio</td>\n","    </tr>\n","    <tr>\n","      <th>150926</th>\n","      <td>France</td>\n","      <td>Cuvée Prestige</td>\n","      <td>91</td>\n","      <td>27.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>H.Germain</td>\n","    </tr>\n","    <tr>\n","      <th>150927</th>\n","      <td>Italy</td>\n","      <td>Terre di Dora</td>\n","      <td>91</td>\n","      <td>20.0</td>\n","      <td>Southern Italy</td>\n","      <td>Fiano di Avellino</td>\n","      <td>White Blend</td>\n","      <td>Terredora</td>\n","    </tr>\n","    <tr>\n","      <th>150928</th>\n","      <td>France</td>\n","      <td>Grand Brut Rosé</td>\n","      <td>90</td>\n","      <td>52.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>Gosset</td>\n","    </tr>\n","    <tr>\n","      <th>150929</th>\n","      <td>Italy</td>\n","      <td>NaN</td>\n","      <td>90</td>\n","      <td>15.0</td>\n","      <td>Northeastern Italy</td>\n","      <td>Alto Adige</td>\n","      <td>Pinot Grigio</td>\n","      <td>Alois Lageder</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150930 rows × 8 columns</p>\n","</div>"],"text/plain":["       country  ...                   winery\n","0           US  ...                    Heitz\n","1        Spain  ...  Bodega Carmen Rodríguez\n","2           US  ...                 Macauley\n","3           US  ...                    Ponzi\n","4       France  ...     Domaine de la Bégude\n","...        ...  ...                      ...\n","150925   Italy  ...    Feudi di San Gregorio\n","150926  France  ...                H.Germain\n","150927   Italy  ...                Terredora\n","150928  France  ...                   Gosset\n","150929   Italy  ...            Alois Lageder\n","\n","[150930 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"stream","text":["time: 786 ms (started: 2021-01-09 02:52:02 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bEZKqwADSIeI"},"source":["# Membersihkan Data"]},{"cell_type":"markdown","metadata":{"id":"-eGEHwmqVB6j"},"source":["Assign df_disc dengan data yang tidak memiliki nilai null"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"paZNPf7O39YM","executionInfo":{"status":"ok","timestamp":1610160724617,"user_tz":-420,"elapsed":11647,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"c3889d0e-50f9-4742-e99e-20eb3bbcc9c2"},"source":["df_disc = df.copy()\r\n","for col in df_disc.columns:\r\n","    df_disc = df_disc[df_disc[col].notnull()]\r\n","\r\n","df_disc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>country</th>\n","      <th>designation</th>\n","      <th>points</th>\n","      <th>price</th>\n","      <th>province</th>\n","      <th>region_1</th>\n","      <th>variety</th>\n","      <th>winery</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>US</td>\n","      <td>Martha's Vineyard</td>\n","      <td>96</td>\n","      <td>235.0</td>\n","      <td>California</td>\n","      <td>Napa Valley</td>\n","      <td>Cabernet Sauvignon</td>\n","      <td>Heitz</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Spain</td>\n","      <td>Carodorum Selección Especial Reserva</td>\n","      <td>96</td>\n","      <td>110.0</td>\n","      <td>Northern Spain</td>\n","      <td>Toro</td>\n","      <td>Tinta de Toro</td>\n","      <td>Bodega Carmen Rodríguez</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>US</td>\n","      <td>Special Selected Late Harvest</td>\n","      <td>96</td>\n","      <td>90.0</td>\n","      <td>California</td>\n","      <td>Knights Valley</td>\n","      <td>Sauvignon Blanc</td>\n","      <td>Macauley</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>US</td>\n","      <td>Reserve</td>\n","      <td>96</td>\n","      <td>65.0</td>\n","      <td>Oregon</td>\n","      <td>Willamette Valley</td>\n","      <td>Pinot Noir</td>\n","      <td>Ponzi</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>France</td>\n","      <td>La Brûlade</td>\n","      <td>95</td>\n","      <td>66.0</td>\n","      <td>Provence</td>\n","      <td>Bandol</td>\n","      <td>Provence red blend</td>\n","      <td>Domaine de la Bégude</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>150923</th>\n","      <td>France</td>\n","      <td>Demi-Sec</td>\n","      <td>91</td>\n","      <td>30.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>Jacquart</td>\n","    </tr>\n","    <tr>\n","      <th>150924</th>\n","      <td>France</td>\n","      <td>Diamant Bleu</td>\n","      <td>91</td>\n","      <td>70.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>Heidsieck &amp; Co Monopole</td>\n","    </tr>\n","    <tr>\n","      <th>150926</th>\n","      <td>France</td>\n","      <td>Cuvée Prestige</td>\n","      <td>91</td>\n","      <td>27.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>H.Germain</td>\n","    </tr>\n","    <tr>\n","      <th>150927</th>\n","      <td>Italy</td>\n","      <td>Terre di Dora</td>\n","      <td>91</td>\n","      <td>20.0</td>\n","      <td>Southern Italy</td>\n","      <td>Fiano di Avellino</td>\n","      <td>White Blend</td>\n","      <td>Terredora</td>\n","    </tr>\n","    <tr>\n","      <th>150928</th>\n","      <td>France</td>\n","      <td>Grand Brut Rosé</td>\n","      <td>90</td>\n","      <td>52.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>Gosset</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>77284 rows × 8 columns</p>\n","</div>"],"text/plain":["       country  ...                   winery\n","0           US  ...                    Heitz\n","1        Spain  ...  Bodega Carmen Rodríguez\n","2           US  ...                 Macauley\n","3           US  ...                    Ponzi\n","4       France  ...     Domaine de la Bégude\n","...        ...  ...                      ...\n","150923  France  ...                 Jacquart\n","150924  France  ...  Heidsieck & Co Monopole\n","150926  France  ...                H.Germain\n","150927   Italy  ...                Terredora\n","150928  France  ...                   Gosset\n","\n","[77284 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":5},{"output_type":"stream","text":["time: 149 ms (started: 2021-01-09 02:52:03 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sST7j2Y5VYvX"},"source":["Assign df_disc dengan data yang pada kolom \"winery\" memiliki nilai yang duplicate"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwNxgWeggcWW","executionInfo":{"status":"ok","timestamp":1610160724618,"user_tz":-420,"elapsed":11642,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"ae481a27-1d61-4ee5-df85-2c817c807908"},"source":["df_disc = df_disc[df_disc.duplicated(subset=[\"winery\"], keep=False)]\r\n","print(df_disc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["       country  ...                   winery\n","0           US  ...                    Heitz\n","1        Spain  ...  Bodega Carmen Rodríguez\n","2           US  ...                 Macauley\n","3           US  ...                    Ponzi\n","4       France  ...     Domaine de la Bégude\n","...        ...  ...                      ...\n","150923  France  ...                 Jacquart\n","150924  France  ...  Heidsieck & Co Monopole\n","150926  France  ...                H.Germain\n","150927   Italy  ...                Terredora\n","150928  France  ...                   Gosset\n","\n","[75408 rows x 8 columns]\n","time: 43.3 ms (started: 2021-01-09 02:52:03 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lvP-dr6IWN_P"},"source":["Assign df_disc dengan data yang pada kolom \"designation\" memiliki nilai yang duplicate"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70eGoHFGjv0J","executionInfo":{"status":"ok","timestamp":1610160724619,"user_tz":-420,"elapsed":11639,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"f6ed9580-fd68-496a-e07a-1f10b0a5fc7c"},"source":["df_disc = df_disc[df_disc.duplicated(subset=[\"designation\"], keep=False)]\r\n","print(df_disc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["       country  ...                   winery\n","0           US  ...                    Heitz\n","3           US  ...                    Ponzi\n","5        Spain  ...                Numanthia\n","6        Spain  ...                 Maurodos\n","9           US  ...                Blue Farm\n","...        ...  ...                      ...\n","150923  France  ...                 Jacquart\n","150924  France  ...  Heidsieck & Co Monopole\n","150926  France  ...                H.Germain\n","150927   Italy  ...                Terredora\n","150928  France  ...                   Gosset\n","\n","[66668 rows x 8 columns]\n","time: 44.6 ms (started: 2021-01-09 02:52:03 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FtYAQgQCWb73"},"source":["Assign df_disc dengan data yang pada kolom \"region_1\" memiliki nilai yang duplicate"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n2w7OdAKj6k6","executionInfo":{"status":"ok","timestamp":1610160724620,"user_tz":-420,"elapsed":11635,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"98862181-3689-4606-978f-53898724e44f"},"source":["df_disc = df_disc[df_disc.duplicated(subset=[\"region_1\"], keep=False)]\r\n","print(df_disc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["       country  ...                   winery\n","0           US  ...                    Heitz\n","3           US  ...                    Ponzi\n","5        Spain  ...                Numanthia\n","6        Spain  ...                 Maurodos\n","9           US  ...                Blue Farm\n","...        ...  ...                      ...\n","150923  France  ...                 Jacquart\n","150924  France  ...  Heidsieck & Co Monopole\n","150926  France  ...                H.Germain\n","150927   Italy  ...                Terredora\n","150928  France  ...                   Gosset\n","\n","[66605 rows x 8 columns]\n","time: 37.2 ms (started: 2021-01-09 02:52:03 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qKHe38CwWxC-"},"source":["Assign df_disc dengan data yang pada kolom \"variety\" memiliki nilai yang duplicate"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wE1_28diWwv0","executionInfo":{"status":"ok","timestamp":1610160724621,"user_tz":-420,"elapsed":11629,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"0e9a86e7-df73-4d52-f76d-425bde4d4ade"},"source":["df_disc = df_disc[df_disc.duplicated(subset=[\"variety\"], keep=False)]\r\n","print(df_disc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["       country  ...                   winery\n","0           US  ...                    Heitz\n","3           US  ...                    Ponzi\n","5        Spain  ...                Numanthia\n","6        Spain  ...                 Maurodos\n","9           US  ...                Blue Farm\n","...        ...  ...                      ...\n","150923  France  ...                 Jacquart\n","150924  France  ...  Heidsieck & Co Monopole\n","150926  France  ...                H.Germain\n","150927   Italy  ...                Terredora\n","150928  France  ...                   Gosset\n","\n","[66571 rows x 8 columns]\n","time: 37.5 ms (started: 2021-01-09 02:52:03 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XdCia0ITXIfZ"},"source":["Mendiskritkan target menjadi kontinu menggunakan qcut dari pandas dengan parameter pd.qcut(kolom, jumlah_kelas, label) dan replace kolom target (price) dengan angka"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"hRbiEc4yAwF2","executionInfo":{"status":"ok","timestamp":1610160724959,"user_tz":-420,"elapsed":11960,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"e7cc5cd5-7dbe-4bac-ee48-077d41323093"},"source":["df_disc['points'] = pd.qcut(df_disc['points'], 2, labels=['low', 'high'])\r\n","df_disc['points'].replace({'low': 0, 'high': 1}, inplace=True)\r\n","df_disc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>country</th>\n","      <th>designation</th>\n","      <th>points</th>\n","      <th>price</th>\n","      <th>province</th>\n","      <th>region_1</th>\n","      <th>variety</th>\n","      <th>winery</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>US</td>\n","      <td>Martha's Vineyard</td>\n","      <td>1</td>\n","      <td>235.0</td>\n","      <td>California</td>\n","      <td>Napa Valley</td>\n","      <td>Cabernet Sauvignon</td>\n","      <td>Heitz</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>US</td>\n","      <td>Reserve</td>\n","      <td>1</td>\n","      <td>65.0</td>\n","      <td>Oregon</td>\n","      <td>Willamette Valley</td>\n","      <td>Pinot Noir</td>\n","      <td>Ponzi</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Spain</td>\n","      <td>Numanthia</td>\n","      <td>1</td>\n","      <td>73.0</td>\n","      <td>Northern Spain</td>\n","      <td>Toro</td>\n","      <td>Tinta de Toro</td>\n","      <td>Numanthia</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Spain</td>\n","      <td>San Román</td>\n","      <td>1</td>\n","      <td>65.0</td>\n","      <td>Northern Spain</td>\n","      <td>Toro</td>\n","      <td>Tinta de Toro</td>\n","      <td>Maurodos</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>US</td>\n","      <td>Gap's Crown Vineyard</td>\n","      <td>1</td>\n","      <td>60.0</td>\n","      <td>California</td>\n","      <td>Sonoma Coast</td>\n","      <td>Pinot Noir</td>\n","      <td>Blue Farm</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>150923</th>\n","      <td>France</td>\n","      <td>Demi-Sec</td>\n","      <td>1</td>\n","      <td>30.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>Jacquart</td>\n","    </tr>\n","    <tr>\n","      <th>150924</th>\n","      <td>France</td>\n","      <td>Diamant Bleu</td>\n","      <td>1</td>\n","      <td>70.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>Heidsieck &amp; Co Monopole</td>\n","    </tr>\n","    <tr>\n","      <th>150926</th>\n","      <td>France</td>\n","      <td>Cuvée Prestige</td>\n","      <td>1</td>\n","      <td>27.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>H.Germain</td>\n","    </tr>\n","    <tr>\n","      <th>150927</th>\n","      <td>Italy</td>\n","      <td>Terre di Dora</td>\n","      <td>1</td>\n","      <td>20.0</td>\n","      <td>Southern Italy</td>\n","      <td>Fiano di Avellino</td>\n","      <td>White Blend</td>\n","      <td>Terredora</td>\n","    </tr>\n","    <tr>\n","      <th>150928</th>\n","      <td>France</td>\n","      <td>Grand Brut Rosé</td>\n","      <td>1</td>\n","      <td>52.0</td>\n","      <td>Champagne</td>\n","      <td>Champagne</td>\n","      <td>Champagne Blend</td>\n","      <td>Gosset</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>66571 rows × 8 columns</p>\n","</div>"],"text/plain":["       country  ...                   winery\n","0           US  ...                    Heitz\n","3           US  ...                    Ponzi\n","5        Spain  ...                Numanthia\n","6        Spain  ...                 Maurodos\n","9           US  ...                Blue Farm\n","...        ...  ...                      ...\n","150923  France  ...                 Jacquart\n","150924  France  ...  Heidsieck & Co Monopole\n","150926  France  ...                H.Germain\n","150927   Italy  ...                Terredora\n","150928  France  ...                   Gosset\n","\n","[66571 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":10},{"output_type":"stream","text":["time: 87.4 ms (started: 2021-01-09 02:52:03 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aNJHqMt5ZBbG"},"source":["# Encoding"]},{"cell_type":"markdown","metadata":{"id":"Nm8rxTFqYUIj"},"source":["Menggunakan Target Encoder yang meng-encode berdasarkan target. Value yang diberikan antara 0 sampai 1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"zZQU1En-_SMd","executionInfo":{"status":"ok","timestamp":1610160725331,"user_tz":-420,"elapsed":12325,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"0d2ada50-96e8-494b-de1d-226213ccce57"},"source":["te = TargetEncoder()\r\n","\r\n","y = df_disc['points'].values\r\n","X = df_disc.drop(columns=['points']).values\r\n","te.fit(X, y)\r\n","X = te.transform(X)\r\n","\r\n","X.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n","  elif pd.api.types.is_categorical(cols):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.462723</td>\n","      <td>0.851715</td>\n","      <td>0.999498</td>\n","      <td>0.452261</td>\n","      <td>0.557334</td>\n","      <td>0.531222</td>\n","      <td>0.851715</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.462723</td>\n","      <td>0.372807</td>\n","      <td>0.783105</td>\n","      <td>0.557117</td>\n","      <td>0.516393</td>\n","      <td>0.598954</td>\n","      <td>0.795918</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.270993</td>\n","      <td>0.999498</td>\n","      <td>0.787879</td>\n","      <td>0.296432</td>\n","      <td>0.439614</td>\n","      <td>0.542169</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.270993</td>\n","      <td>0.973851</td>\n","      <td>0.783105</td>\n","      <td>0.296432</td>\n","      <td>0.439614</td>\n","      <td>0.542169</td>\n","      <td>0.899944</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.462723</td>\n","      <td>0.781250</td>\n","      <td>0.759768</td>\n","      <td>0.452261</td>\n","      <td>0.671525</td>\n","      <td>0.598954</td>\n","      <td>0.973851</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1         2         3         4         5         6\n","0  0.462723  0.851715  0.999498  0.452261  0.557334  0.531222  0.851715\n","1  0.462723  0.372807  0.783105  0.557117  0.516393  0.598954  0.795918\n","2  0.270993  0.999498  0.787879  0.296432  0.439614  0.542169  1.000000\n","3  0.270993  0.973851  0.783105  0.296432  0.439614  0.542169  0.899944\n","4  0.462723  0.781250  0.759768  0.452261  0.671525  0.598954  0.973851"]},"metadata":{"tags":[]},"execution_count":11},{"output_type":"stream","text":["time: 535 ms (started: 2021-01-09 02:52:03 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xTwv2RgJZMvX"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"lIzA7S8xZgR2"},"source":["## ANN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUvzZoBeBfC8","executionInfo":{"status":"ok","timestamp":1610160725332,"user_tz":-420,"elapsed":12319,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"48b35fa0-5293-44c1-8c3a-712985fcf9f7"},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 13.7 ms (started: 2021-01-09 02:52:04 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aI7PF7sWBnAF","executionInfo":{"status":"ok","timestamp":1610160725681,"user_tz":-420,"elapsed":12663,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"903fbbdc-7da6-470f-f6c6-09958f53062a"},"source":["model=keras.models.Sequential([\r\n","    keras.layers.Dense(512, input_dim = X_train.shape[1], activation='relu'),\r\n","    keras.layers.Dense(units=256, activation='relu'),\r\n","    keras.layers.Dense(units=128, activation='relu'),\r\n","\r\n","    keras.layers.Dense(units=1, activation=\"sigmoid\"),\r\n","],name=\"Initial_model\",)\r\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"Initial_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 512)               4096      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 168,449\n","Trainable params: 168,449\n","Non-trainable params: 0\n","_________________________________________________________________\n","time: 267 ms (started: 2021-01-09 02:52:04 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOln_lhU4VNN","executionInfo":{"status":"ok","timestamp":1610160725682,"user_tz":-420,"elapsed":12658,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"21a3200e-db39-4c5f-be44-365d333f3b81"},"source":["learning_rate = 0.005\r\n","optimizer = keras.optimizers.Adam(lr=learning_rate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 2.18 ms (started: 2021-01-09 02:52:04 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5r_b7es4XxF","executionInfo":{"status":"ok","timestamp":1610160725682,"user_tz":-420,"elapsed":12652,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"50967668-028d-42b9-a4ff-8bb7313813f2"},"source":["model.compile(optimizer=optimizer,\r\n","            loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 27.5 ms (started: 2021-01-09 02:52:04 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hUL50u7l4aw2","executionInfo":{"status":"ok","timestamp":1610160725683,"user_tz":-420,"elapsed":12649,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"1daf88f5-1683-4ade-af07-bd28d2bae71e"},"source":["early_stopping_monitor = EarlyStopping(\r\n","    monitor='val_loss',\r\n","    min_delta=0,\r\n","    patience=1000,\r\n","    verbose=0,\r\n","    mode='auto',\r\n","    baseline=None,\r\n","    restore_best_weights=True\r\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 2.77 ms (started: 2021-01-09 02:52:04 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_c5zURT4dx8","executionInfo":{"status":"ok","timestamp":1610161178008,"user_tz":-420,"elapsed":464968,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"61416427-447a-4486-973c-5f9024d1d569"},"source":["history = model.fit(X_train, y_train,\r\n","                    epochs=500, batch_size=1024,\r\n","                    validation_data=(X_test, y_test), \r\n","                    verbose=1, callbacks=[early_stopping_monitor])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n","20/20 [==============================] - 2s 67ms/step - loss: 0.4752 - accuracy: 0.7742 - val_loss: 0.3165 - val_accuracy: 0.8653\n","Epoch 2/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2963 - accuracy: 0.8724 - val_loss: 0.2781 - val_accuracy: 0.8771\n","Epoch 3/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2836 - accuracy: 0.8747 - val_loss: 0.2726 - val_accuracy: 0.8789\n","Epoch 4/500\n","20/20 [==============================] - 1s 50ms/step - loss: 0.2722 - accuracy: 0.8758 - val_loss: 0.2701 - val_accuracy: 0.8777\n","Epoch 5/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2713 - accuracy: 0.8749 - val_loss: 0.2688 - val_accuracy: 0.8778\n","Epoch 6/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2695 - accuracy: 0.8758 - val_loss: 0.2605 - val_accuracy: 0.8803\n","Epoch 7/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2614 - accuracy: 0.8803 - val_loss: 0.2582 - val_accuracy: 0.8791\n","Epoch 8/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2533 - accuracy: 0.8804 - val_loss: 0.2552 - val_accuracy: 0.8792\n","Epoch 9/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2551 - accuracy: 0.8761 - val_loss: 0.2556 - val_accuracy: 0.8783\n","Epoch 10/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2563 - accuracy: 0.8825 - val_loss: 0.2624 - val_accuracy: 0.8767\n","Epoch 11/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2540 - accuracy: 0.8838 - val_loss: 0.2525 - val_accuracy: 0.8803\n","Epoch 12/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2541 - accuracy: 0.8802 - val_loss: 0.2512 - val_accuracy: 0.8807\n","Epoch 13/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2493 - accuracy: 0.8789 - val_loss: 0.2499 - val_accuracy: 0.8798\n","Epoch 14/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2499 - accuracy: 0.8806 - val_loss: 0.2487 - val_accuracy: 0.8811\n","Epoch 15/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2542 - accuracy: 0.8818 - val_loss: 0.2480 - val_accuracy: 0.8805\n","Epoch 16/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2482 - accuracy: 0.8831 - val_loss: 0.2488 - val_accuracy: 0.8811\n","Epoch 17/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2530 - accuracy: 0.8788 - val_loss: 0.2496 - val_accuracy: 0.8814\n","Epoch 18/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2449 - accuracy: 0.8829 - val_loss: 0.2494 - val_accuracy: 0.8816\n","Epoch 19/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2443 - accuracy: 0.8813 - val_loss: 0.2499 - val_accuracy: 0.8807\n","Epoch 20/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2476 - accuracy: 0.8805 - val_loss: 0.2491 - val_accuracy: 0.8805\n","Epoch 21/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2495 - accuracy: 0.8763 - val_loss: 0.2571 - val_accuracy: 0.8787\n","Epoch 22/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2507 - accuracy: 0.8833 - val_loss: 0.2488 - val_accuracy: 0.8805\n","Epoch 23/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2513 - accuracy: 0.8817 - val_loss: 0.2544 - val_accuracy: 0.8794\n","Epoch 24/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2521 - accuracy: 0.8796 - val_loss: 0.2488 - val_accuracy: 0.8806\n","Epoch 25/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2482 - accuracy: 0.8790 - val_loss: 0.2513 - val_accuracy: 0.8812\n","Epoch 26/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2409 - accuracy: 0.8857 - val_loss: 0.2482 - val_accuracy: 0.8812\n","Epoch 27/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2477 - accuracy: 0.8824 - val_loss: 0.2502 - val_accuracy: 0.8809\n","Epoch 28/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2481 - accuracy: 0.8820 - val_loss: 0.2478 - val_accuracy: 0.8805\n","Epoch 29/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2451 - accuracy: 0.8832 - val_loss: 0.2472 - val_accuracy: 0.8813\n","Epoch 30/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2439 - accuracy: 0.8839 - val_loss: 0.2501 - val_accuracy: 0.8813\n","Epoch 31/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2453 - accuracy: 0.8816 - val_loss: 0.2518 - val_accuracy: 0.8814\n","Epoch 32/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2394 - accuracy: 0.8860 - val_loss: 0.2491 - val_accuracy: 0.8818\n","Epoch 33/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2456 - accuracy: 0.8815 - val_loss: 0.2601 - val_accuracy: 0.8748\n","Epoch 34/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2537 - accuracy: 0.8779 - val_loss: 0.2476 - val_accuracy: 0.8826\n","Epoch 35/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2474 - accuracy: 0.8813 - val_loss: 0.2523 - val_accuracy: 0.8784\n","Epoch 36/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2491 - accuracy: 0.8778 - val_loss: 0.2527 - val_accuracy: 0.8791\n","Epoch 37/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2481 - accuracy: 0.8813 - val_loss: 0.2474 - val_accuracy: 0.8812\n","Epoch 38/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2412 - accuracy: 0.8861 - val_loss: 0.2579 - val_accuracy: 0.8785\n","Epoch 39/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2473 - accuracy: 0.8848 - val_loss: 0.2739 - val_accuracy: 0.8707\n","Epoch 40/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2564 - accuracy: 0.8763 - val_loss: 0.2488 - val_accuracy: 0.8809\n","Epoch 41/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2445 - accuracy: 0.8817 - val_loss: 0.2531 - val_accuracy: 0.8808\n","Epoch 42/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2457 - accuracy: 0.8823 - val_loss: 0.2553 - val_accuracy: 0.8808\n","Epoch 43/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2429 - accuracy: 0.8846 - val_loss: 0.2468 - val_accuracy: 0.8802\n","Epoch 44/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2469 - accuracy: 0.8787 - val_loss: 0.2482 - val_accuracy: 0.8813\n","Epoch 45/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2402 - accuracy: 0.8836 - val_loss: 0.2482 - val_accuracy: 0.8820\n","Epoch 46/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2410 - accuracy: 0.8846 - val_loss: 0.2485 - val_accuracy: 0.8803\n","Epoch 47/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2444 - accuracy: 0.8841 - val_loss: 0.2478 - val_accuracy: 0.8827\n","Epoch 48/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2459 - accuracy: 0.8796 - val_loss: 0.2541 - val_accuracy: 0.8780\n","Epoch 49/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2466 - accuracy: 0.8845 - val_loss: 0.2486 - val_accuracy: 0.8815\n","Epoch 50/500\n","20/20 [==============================] - 1s 51ms/step - loss: 0.2513 - accuracy: 0.8796 - val_loss: 0.2484 - val_accuracy: 0.8811\n","Epoch 51/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2385 - accuracy: 0.8838 - val_loss: 0.2467 - val_accuracy: 0.8813\n","Epoch 52/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2431 - accuracy: 0.8844 - val_loss: 0.2501 - val_accuracy: 0.8805\n","Epoch 53/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2436 - accuracy: 0.8820 - val_loss: 0.2516 - val_accuracy: 0.8810\n","Epoch 54/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2427 - accuracy: 0.8810 - val_loss: 0.2477 - val_accuracy: 0.8827\n","Epoch 55/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2445 - accuracy: 0.8823 - val_loss: 0.2483 - val_accuracy: 0.8826\n","Epoch 56/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2417 - accuracy: 0.8827 - val_loss: 0.2500 - val_accuracy: 0.8824\n","Epoch 57/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2491 - accuracy: 0.8813 - val_loss: 0.2477 - val_accuracy: 0.8827\n","Epoch 58/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2474 - accuracy: 0.8814 - val_loss: 0.2500 - val_accuracy: 0.8806\n","Epoch 59/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2434 - accuracy: 0.8827 - val_loss: 0.2486 - val_accuracy: 0.8820\n","Epoch 60/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2450 - accuracy: 0.8844 - val_loss: 0.2511 - val_accuracy: 0.8823\n","Epoch 61/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2449 - accuracy: 0.8825 - val_loss: 0.2519 - val_accuracy: 0.8782\n","Epoch 62/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2462 - accuracy: 0.8792 - val_loss: 0.2490 - val_accuracy: 0.8827\n","Epoch 63/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2444 - accuracy: 0.8821 - val_loss: 0.2504 - val_accuracy: 0.8786\n","Epoch 64/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2425 - accuracy: 0.8818 - val_loss: 0.2499 - val_accuracy: 0.8800\n","Epoch 65/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2385 - accuracy: 0.8835 - val_loss: 0.2498 - val_accuracy: 0.8810\n","Epoch 66/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2339 - accuracy: 0.8880 - val_loss: 0.2576 - val_accuracy: 0.8782\n","Epoch 67/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2443 - accuracy: 0.8846 - val_loss: 0.2467 - val_accuracy: 0.8812\n","Epoch 68/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2412 - accuracy: 0.8847 - val_loss: 0.2477 - val_accuracy: 0.8812\n","Epoch 69/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2371 - accuracy: 0.8856 - val_loss: 0.2490 - val_accuracy: 0.8814\n","Epoch 70/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2374 - accuracy: 0.8853 - val_loss: 0.2496 - val_accuracy: 0.8824\n","Epoch 71/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2383 - accuracy: 0.8864 - val_loss: 0.2553 - val_accuracy: 0.8777\n","Epoch 72/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2426 - accuracy: 0.8844 - val_loss: 0.2472 - val_accuracy: 0.8816\n","Epoch 73/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2376 - accuracy: 0.8871 - val_loss: 0.2514 - val_accuracy: 0.8819\n","Epoch 74/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2435 - accuracy: 0.8796 - val_loss: 0.2479 - val_accuracy: 0.8837\n","Epoch 75/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2413 - accuracy: 0.8845 - val_loss: 0.2503 - val_accuracy: 0.8805\n","Epoch 76/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2397 - accuracy: 0.8868 - val_loss: 0.2487 - val_accuracy: 0.8812\n","Epoch 77/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2331 - accuracy: 0.8876 - val_loss: 0.2489 - val_accuracy: 0.8801\n","Epoch 78/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2365 - accuracy: 0.8842 - val_loss: 0.2499 - val_accuracy: 0.8830\n","Epoch 79/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2429 - accuracy: 0.8836 - val_loss: 0.2490 - val_accuracy: 0.8813\n","Epoch 80/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2371 - accuracy: 0.8857 - val_loss: 0.2509 - val_accuracy: 0.8829\n","Epoch 81/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2378 - accuracy: 0.8858 - val_loss: 0.2565 - val_accuracy: 0.8799\n","Epoch 82/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2427 - accuracy: 0.8834 - val_loss: 0.2538 - val_accuracy: 0.8815\n","Epoch 83/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2413 - accuracy: 0.8860 - val_loss: 0.2561 - val_accuracy: 0.8815\n","Epoch 84/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2360 - accuracy: 0.8843 - val_loss: 0.2518 - val_accuracy: 0.8788\n","Epoch 85/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2356 - accuracy: 0.8843 - val_loss: 0.2491 - val_accuracy: 0.8810\n","Epoch 86/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2371 - accuracy: 0.8853 - val_loss: 0.2508 - val_accuracy: 0.8820\n","Epoch 87/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2392 - accuracy: 0.8831 - val_loss: 0.2550 - val_accuracy: 0.8785\n","Epoch 88/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2351 - accuracy: 0.8872 - val_loss: 0.2494 - val_accuracy: 0.8826\n","Epoch 89/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2351 - accuracy: 0.8856 - val_loss: 0.2499 - val_accuracy: 0.8803\n","Epoch 90/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2340 - accuracy: 0.8887 - val_loss: 0.2517 - val_accuracy: 0.8796\n","Epoch 91/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2332 - accuracy: 0.8895 - val_loss: 0.2490 - val_accuracy: 0.8820\n","Epoch 92/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2362 - accuracy: 0.8869 - val_loss: 0.2491 - val_accuracy: 0.8809\n","Epoch 93/500\n","20/20 [==============================] - 1s 50ms/step - loss: 0.2327 - accuracy: 0.8878 - val_loss: 0.2482 - val_accuracy: 0.8813\n","Epoch 94/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2298 - accuracy: 0.8897 - val_loss: 0.2528 - val_accuracy: 0.8766\n","Epoch 95/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2361 - accuracy: 0.8851 - val_loss: 0.2507 - val_accuracy: 0.8813\n","Epoch 96/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2326 - accuracy: 0.8867 - val_loss: 0.2554 - val_accuracy: 0.8799\n","Epoch 97/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2400 - accuracy: 0.8878 - val_loss: 0.2583 - val_accuracy: 0.8766\n","Epoch 98/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2345 - accuracy: 0.8895 - val_loss: 0.2520 - val_accuracy: 0.8801\n","Epoch 99/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2348 - accuracy: 0.8902 - val_loss: 0.2513 - val_accuracy: 0.8816\n","Epoch 100/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2307 - accuracy: 0.8867 - val_loss: 0.2608 - val_accuracy: 0.8778\n","Epoch 101/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2346 - accuracy: 0.8902 - val_loss: 0.2516 - val_accuracy: 0.8810\n","Epoch 102/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2336 - accuracy: 0.8854 - val_loss: 0.2539 - val_accuracy: 0.8810\n","Epoch 103/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2442 - accuracy: 0.8827 - val_loss: 0.2634 - val_accuracy: 0.8777\n","Epoch 104/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2375 - accuracy: 0.8847 - val_loss: 0.2520 - val_accuracy: 0.8815\n","Epoch 105/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2306 - accuracy: 0.8905 - val_loss: 0.2522 - val_accuracy: 0.8837\n","Epoch 106/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2288 - accuracy: 0.8890 - val_loss: 0.2527 - val_accuracy: 0.8801\n","Epoch 107/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2302 - accuracy: 0.8898 - val_loss: 0.2524 - val_accuracy: 0.8816\n","Epoch 108/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2355 - accuracy: 0.8876 - val_loss: 0.2539 - val_accuracy: 0.8803\n","Epoch 109/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2279 - accuracy: 0.8917 - val_loss: 0.2553 - val_accuracy: 0.8804\n","Epoch 110/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2287 - accuracy: 0.8906 - val_loss: 0.2558 - val_accuracy: 0.8783\n","Epoch 111/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2352 - accuracy: 0.8840 - val_loss: 0.2540 - val_accuracy: 0.8811\n","Epoch 112/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2295 - accuracy: 0.8896 - val_loss: 0.2568 - val_accuracy: 0.8805\n","Epoch 113/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2306 - accuracy: 0.8899 - val_loss: 0.2546 - val_accuracy: 0.8808\n","Epoch 114/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2306 - accuracy: 0.8908 - val_loss: 0.2562 - val_accuracy: 0.8815\n","Epoch 115/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2289 - accuracy: 0.8893 - val_loss: 0.2541 - val_accuracy: 0.8761\n","Epoch 116/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.2272 - accuracy: 0.8907 - val_loss: 0.2560 - val_accuracy: 0.8803\n","Epoch 117/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2315 - accuracy: 0.8879 - val_loss: 0.2610 - val_accuracy: 0.8803\n","Epoch 118/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2297 - accuracy: 0.8895 - val_loss: 0.2569 - val_accuracy: 0.8754\n","Epoch 119/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2318 - accuracy: 0.8857 - val_loss: 0.2561 - val_accuracy: 0.8806\n","Epoch 120/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2264 - accuracy: 0.8882 - val_loss: 0.2596 - val_accuracy: 0.8779\n","Epoch 121/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2247 - accuracy: 0.8918 - val_loss: 0.2555 - val_accuracy: 0.8801\n","Epoch 122/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2227 - accuracy: 0.8923 - val_loss: 0.2538 - val_accuracy: 0.8812\n","Epoch 123/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2245 - accuracy: 0.8910 - val_loss: 0.2581 - val_accuracy: 0.8806\n","Epoch 124/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2233 - accuracy: 0.8930 - val_loss: 0.2637 - val_accuracy: 0.8734\n","Epoch 125/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2287 - accuracy: 0.8910 - val_loss: 0.2615 - val_accuracy: 0.8765\n","Epoch 126/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2279 - accuracy: 0.8914 - val_loss: 0.2598 - val_accuracy: 0.8786\n","Epoch 127/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2212 - accuracy: 0.8931 - val_loss: 0.2578 - val_accuracy: 0.8786\n","Epoch 128/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2240 - accuracy: 0.8901 - val_loss: 0.2616 - val_accuracy: 0.8778\n","Epoch 129/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2209 - accuracy: 0.8920 - val_loss: 0.2608 - val_accuracy: 0.8776\n","Epoch 130/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2186 - accuracy: 0.8920 - val_loss: 0.2632 - val_accuracy: 0.8776\n","Epoch 131/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2289 - accuracy: 0.8883 - val_loss: 0.2647 - val_accuracy: 0.8787\n","Epoch 132/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2214 - accuracy: 0.8909 - val_loss: 0.2618 - val_accuracy: 0.8791\n","Epoch 133/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2283 - accuracy: 0.8860 - val_loss: 0.2644 - val_accuracy: 0.8797\n","Epoch 134/500\n","20/20 [==============================] - 1s 43ms/step - loss: 0.2177 - accuracy: 0.8962 - val_loss: 0.2658 - val_accuracy: 0.8781\n","Epoch 135/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2221 - accuracy: 0.8905 - val_loss: 0.2689 - val_accuracy: 0.8765\n","Epoch 136/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2214 - accuracy: 0.8922 - val_loss: 0.2627 - val_accuracy: 0.8792\n","Epoch 137/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2212 - accuracy: 0.8946 - val_loss: 0.2642 - val_accuracy: 0.8806\n","Epoch 138/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2181 - accuracy: 0.8959 - val_loss: 0.2658 - val_accuracy: 0.8798\n","Epoch 139/500\n","20/20 [==============================] - 1s 52ms/step - loss: 0.2153 - accuracy: 0.8951 - val_loss: 0.2695 - val_accuracy: 0.8801\n","Epoch 140/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.2161 - accuracy: 0.8932 - val_loss: 0.2653 - val_accuracy: 0.8786\n","Epoch 141/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.2187 - accuracy: 0.8920 - val_loss: 0.2685 - val_accuracy: 0.8790\n","Epoch 142/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2098 - accuracy: 0.8986 - val_loss: 0.2710 - val_accuracy: 0.8752\n","Epoch 143/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2153 - accuracy: 0.8984 - val_loss: 0.2691 - val_accuracy: 0.8771\n","Epoch 144/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2161 - accuracy: 0.8961 - val_loss: 0.2733 - val_accuracy: 0.8740\n","Epoch 145/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2164 - accuracy: 0.8943 - val_loss: 0.2690 - val_accuracy: 0.8801\n","Epoch 146/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2115 - accuracy: 0.8955 - val_loss: 0.2705 - val_accuracy: 0.8773\n","Epoch 147/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2121 - accuracy: 0.8997 - val_loss: 0.2754 - val_accuracy: 0.8761\n","Epoch 148/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2106 - accuracy: 0.8979 - val_loss: 0.2745 - val_accuracy: 0.8759\n","Epoch 149/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.2152 - accuracy: 0.8940 - val_loss: 0.2736 - val_accuracy: 0.8726\n","Epoch 150/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2198 - accuracy: 0.8947 - val_loss: 0.2720 - val_accuracy: 0.8780\n","Epoch 151/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2132 - accuracy: 0.8989 - val_loss: 0.2749 - val_accuracy: 0.8810\n","Epoch 152/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2076 - accuracy: 0.9009 - val_loss: 0.2727 - val_accuracy: 0.8777\n","Epoch 153/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2181 - accuracy: 0.8944 - val_loss: 0.2782 - val_accuracy: 0.8777\n","Epoch 154/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2121 - accuracy: 0.8993 - val_loss: 0.2759 - val_accuracy: 0.8778\n","Epoch 155/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2083 - accuracy: 0.8989 - val_loss: 0.2759 - val_accuracy: 0.8782\n","Epoch 156/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2151 - accuracy: 0.8959 - val_loss: 0.2716 - val_accuracy: 0.8778\n","Epoch 157/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2112 - accuracy: 0.8971 - val_loss: 0.2725 - val_accuracy: 0.8776\n","Epoch 158/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2054 - accuracy: 0.8992 - val_loss: 0.2735 - val_accuracy: 0.8804\n","Epoch 159/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2146 - accuracy: 0.8957 - val_loss: 0.2816 - val_accuracy: 0.8778\n","Epoch 160/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2076 - accuracy: 0.9014 - val_loss: 0.2761 - val_accuracy: 0.8761\n","Epoch 161/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2026 - accuracy: 0.9034 - val_loss: 0.2768 - val_accuracy: 0.8770\n","Epoch 162/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2070 - accuracy: 0.8996 - val_loss: 0.2807 - val_accuracy: 0.8764\n","Epoch 163/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2056 - accuracy: 0.9001 - val_loss: 0.2775 - val_accuracy: 0.8798\n","Epoch 164/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2075 - accuracy: 0.8976 - val_loss: 0.2817 - val_accuracy: 0.8790\n","Epoch 165/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2005 - accuracy: 0.9006 - val_loss: 0.2846 - val_accuracy: 0.8753\n","Epoch 166/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2079 - accuracy: 0.8974 - val_loss: 0.2833 - val_accuracy: 0.8694\n","Epoch 167/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2030 - accuracy: 0.8994 - val_loss: 0.2832 - val_accuracy: 0.8742\n","Epoch 168/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2089 - accuracy: 0.8984 - val_loss: 0.2880 - val_accuracy: 0.8746\n","Epoch 169/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2049 - accuracy: 0.8989 - val_loss: 0.2943 - val_accuracy: 0.8750\n","Epoch 170/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.2053 - accuracy: 0.9014 - val_loss: 0.2880 - val_accuracy: 0.8772\n","Epoch 171/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.2014 - accuracy: 0.9026 - val_loss: 0.2844 - val_accuracy: 0.8785\n","Epoch 172/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1925 - accuracy: 0.9049 - val_loss: 0.2834 - val_accuracy: 0.8771\n","Epoch 173/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1985 - accuracy: 0.9026 - val_loss: 0.2820 - val_accuracy: 0.8785\n","Epoch 174/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.2025 - accuracy: 0.9025 - val_loss: 0.2917 - val_accuracy: 0.8727\n","Epoch 175/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1988 - accuracy: 0.9033 - val_loss: 0.2901 - val_accuracy: 0.8747\n","Epoch 176/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1994 - accuracy: 0.9016 - val_loss: 0.2914 - val_accuracy: 0.8760\n","Epoch 177/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1932 - accuracy: 0.9049 - val_loss: 0.2932 - val_accuracy: 0.8736\n","Epoch 178/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1993 - accuracy: 0.9022 - val_loss: 0.2997 - val_accuracy: 0.8758\n","Epoch 179/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1998 - accuracy: 0.9026 - val_loss: 0.2989 - val_accuracy: 0.8752\n","Epoch 180/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1928 - accuracy: 0.9059 - val_loss: 0.3027 - val_accuracy: 0.8737\n","Epoch 181/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1946 - accuracy: 0.9028 - val_loss: 0.2935 - val_accuracy: 0.8763\n","Epoch 182/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1952 - accuracy: 0.9063 - val_loss: 0.2956 - val_accuracy: 0.8763\n","Epoch 183/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1971 - accuracy: 0.9038 - val_loss: 0.2963 - val_accuracy: 0.8770\n","Epoch 184/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1932 - accuracy: 0.9065 - val_loss: 0.2961 - val_accuracy: 0.8749\n","Epoch 185/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1980 - accuracy: 0.9021 - val_loss: 0.3072 - val_accuracy: 0.8733\n","Epoch 186/500\n","20/20 [==============================] - 1s 52ms/step - loss: 0.1971 - accuracy: 0.9023 - val_loss: 0.3061 - val_accuracy: 0.8736\n","Epoch 187/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1955 - accuracy: 0.9058 - val_loss: 0.3006 - val_accuracy: 0.8752\n","Epoch 188/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1976 - accuracy: 0.9047 - val_loss: 0.3114 - val_accuracy: 0.8691\n","Epoch 189/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1901 - accuracy: 0.9095 - val_loss: 0.3010 - val_accuracy: 0.8755\n","Epoch 190/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1898 - accuracy: 0.9076 - val_loss: 0.3045 - val_accuracy: 0.8715\n","Epoch 191/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1862 - accuracy: 0.9095 - val_loss: 0.3120 - val_accuracy: 0.8747\n","Epoch 192/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1862 - accuracy: 0.9113 - val_loss: 0.3056 - val_accuracy: 0.8756\n","Epoch 193/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1936 - accuracy: 0.9070 - val_loss: 0.3011 - val_accuracy: 0.8759\n","Epoch 194/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1933 - accuracy: 0.9062 - val_loss: 0.3054 - val_accuracy: 0.8677\n","Epoch 195/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1963 - accuracy: 0.9039 - val_loss: 0.3104 - val_accuracy: 0.8764\n","Epoch 196/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1848 - accuracy: 0.9121 - val_loss: 0.3236 - val_accuracy: 0.8744\n","Epoch 197/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1862 - accuracy: 0.9078 - val_loss: 0.3168 - val_accuracy: 0.8735\n","Epoch 198/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1871 - accuracy: 0.9068 - val_loss: 0.3134 - val_accuracy: 0.8750\n","Epoch 199/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1891 - accuracy: 0.9087 - val_loss: 0.3093 - val_accuracy: 0.8725\n","Epoch 200/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1838 - accuracy: 0.9113 - val_loss: 0.3198 - val_accuracy: 0.8752\n","Epoch 201/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1917 - accuracy: 0.9088 - val_loss: 0.3125 - val_accuracy: 0.8739\n","Epoch 202/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1854 - accuracy: 0.9108 - val_loss: 0.3196 - val_accuracy: 0.8712\n","Epoch 203/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1860 - accuracy: 0.9106 - val_loss: 0.3207 - val_accuracy: 0.8761\n","Epoch 204/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1850 - accuracy: 0.9085 - val_loss: 0.3268 - val_accuracy: 0.8771\n","Epoch 205/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1835 - accuracy: 0.9120 - val_loss: 0.3243 - val_accuracy: 0.8702\n","Epoch 206/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1836 - accuracy: 0.9131 - val_loss: 0.3162 - val_accuracy: 0.8750\n","Epoch 207/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1790 - accuracy: 0.9134 - val_loss: 0.3272 - val_accuracy: 0.8728\n","Epoch 208/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1831 - accuracy: 0.9123 - val_loss: 0.3286 - val_accuracy: 0.8788\n","Epoch 209/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1860 - accuracy: 0.9108 - val_loss: 0.3228 - val_accuracy: 0.8732\n","Epoch 210/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1813 - accuracy: 0.9103 - val_loss: 0.3264 - val_accuracy: 0.8753\n","Epoch 211/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1817 - accuracy: 0.9139 - val_loss: 0.3237 - val_accuracy: 0.8723\n","Epoch 212/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1795 - accuracy: 0.9132 - val_loss: 0.3270 - val_accuracy: 0.8691\n","Epoch 213/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1718 - accuracy: 0.9172 - val_loss: 0.3299 - val_accuracy: 0.8715\n","Epoch 214/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1770 - accuracy: 0.9135 - val_loss: 0.3369 - val_accuracy: 0.8741\n","Epoch 215/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1890 - accuracy: 0.9098 - val_loss: 0.3401 - val_accuracy: 0.8758\n","Epoch 216/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1821 - accuracy: 0.9126 - val_loss: 0.3390 - val_accuracy: 0.8715\n","Epoch 217/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1762 - accuracy: 0.9177 - val_loss: 0.3398 - val_accuracy: 0.8719\n","Epoch 218/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1769 - accuracy: 0.9172 - val_loss: 0.3335 - val_accuracy: 0.8732\n","Epoch 219/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1778 - accuracy: 0.9147 - val_loss: 0.3489 - val_accuracy: 0.8723\n","Epoch 220/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1845 - accuracy: 0.9112 - val_loss: 0.3405 - val_accuracy: 0.8732\n","Epoch 221/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1779 - accuracy: 0.9160 - val_loss: 0.3283 - val_accuracy: 0.8703\n","Epoch 222/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1812 - accuracy: 0.9140 - val_loss: 0.3358 - val_accuracy: 0.8633\n","Epoch 223/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1817 - accuracy: 0.9133 - val_loss: 0.3336 - val_accuracy: 0.8736\n","Epoch 224/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1751 - accuracy: 0.9175 - val_loss: 0.3297 - val_accuracy: 0.8749\n","Epoch 225/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1703 - accuracy: 0.9173 - val_loss: 0.3382 - val_accuracy: 0.8791\n","Epoch 226/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1723 - accuracy: 0.9181 - val_loss: 0.3381 - val_accuracy: 0.8686\n","Epoch 227/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1740 - accuracy: 0.9134 - val_loss: 0.3477 - val_accuracy: 0.8735\n","Epoch 228/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1710 - accuracy: 0.9170 - val_loss: 0.3508 - val_accuracy: 0.8704\n","Epoch 229/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1721 - accuracy: 0.9163 - val_loss: 0.3408 - val_accuracy: 0.8728\n","Epoch 230/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1700 - accuracy: 0.9178 - val_loss: 0.3458 - val_accuracy: 0.8738\n","Epoch 231/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1725 - accuracy: 0.9175 - val_loss: 0.3458 - val_accuracy: 0.8710\n","Epoch 232/500\n","20/20 [==============================] - 1s 51ms/step - loss: 0.1721 - accuracy: 0.9194 - val_loss: 0.3483 - val_accuracy: 0.8694\n","Epoch 233/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1675 - accuracy: 0.9220 - val_loss: 0.3520 - val_accuracy: 0.8733\n","Epoch 234/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1657 - accuracy: 0.9219 - val_loss: 0.3601 - val_accuracy: 0.8719\n","Epoch 235/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1673 - accuracy: 0.9215 - val_loss: 0.3540 - val_accuracy: 0.8714\n","Epoch 236/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1702 - accuracy: 0.9172 - val_loss: 0.3546 - val_accuracy: 0.8702\n","Epoch 237/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1653 - accuracy: 0.9218 - val_loss: 0.3579 - val_accuracy: 0.8688\n","Epoch 238/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1649 - accuracy: 0.9220 - val_loss: 0.3758 - val_accuracy: 0.8698\n","Epoch 239/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1687 - accuracy: 0.9190 - val_loss: 0.3581 - val_accuracy: 0.8671\n","Epoch 240/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1642 - accuracy: 0.9226 - val_loss: 0.3719 - val_accuracy: 0.8704\n","Epoch 241/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1691 - accuracy: 0.9203 - val_loss: 0.3599 - val_accuracy: 0.8751\n","Epoch 242/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1620 - accuracy: 0.9240 - val_loss: 0.3629 - val_accuracy: 0.8714\n","Epoch 243/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1612 - accuracy: 0.9227 - val_loss: 0.3765 - val_accuracy: 0.8691\n","Epoch 244/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1588 - accuracy: 0.9249 - val_loss: 0.3790 - val_accuracy: 0.8691\n","Epoch 245/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1626 - accuracy: 0.9212 - val_loss: 0.3757 - val_accuracy: 0.8740\n","Epoch 246/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1641 - accuracy: 0.9213 - val_loss: 0.3727 - val_accuracy: 0.8748\n","Epoch 247/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1664 - accuracy: 0.9209 - val_loss: 0.3763 - val_accuracy: 0.8653\n","Epoch 248/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1605 - accuracy: 0.9252 - val_loss: 0.3741 - val_accuracy: 0.8676\n","Epoch 249/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1640 - accuracy: 0.9201 - val_loss: 0.3694 - val_accuracy: 0.8753\n","Epoch 250/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1620 - accuracy: 0.9214 - val_loss: 0.3772 - val_accuracy: 0.8711\n","Epoch 251/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1662 - accuracy: 0.9209 - val_loss: 0.3684 - val_accuracy: 0.8736\n","Epoch 252/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1677 - accuracy: 0.9204 - val_loss: 0.3932 - val_accuracy: 0.8658\n","Epoch 253/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1611 - accuracy: 0.9245 - val_loss: 0.3810 - val_accuracy: 0.8715\n","Epoch 254/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1592 - accuracy: 0.9251 - val_loss: 0.3874 - val_accuracy: 0.8733\n","Epoch 255/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1527 - accuracy: 0.9295 - val_loss: 0.3900 - val_accuracy: 0.8676\n","Epoch 256/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1614 - accuracy: 0.9219 - val_loss: 0.3843 - val_accuracy: 0.8732\n","Epoch 257/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1535 - accuracy: 0.9297 - val_loss: 0.3754 - val_accuracy: 0.8723\n","Epoch 258/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1598 - accuracy: 0.9234 - val_loss: 0.3874 - val_accuracy: 0.8710\n","Epoch 259/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1550 - accuracy: 0.9238 - val_loss: 0.3935 - val_accuracy: 0.8659\n","Epoch 260/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1539 - accuracy: 0.9257 - val_loss: 0.4027 - val_accuracy: 0.8697\n","Epoch 261/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1607 - accuracy: 0.9233 - val_loss: 0.3859 - val_accuracy: 0.8680\n","Epoch 262/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1587 - accuracy: 0.9252 - val_loss: 0.3963 - val_accuracy: 0.8724\n","Epoch 263/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1514 - accuracy: 0.9292 - val_loss: 0.3868 - val_accuracy: 0.8670\n","Epoch 264/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1565 - accuracy: 0.9266 - val_loss: 0.3965 - val_accuracy: 0.8689\n","Epoch 265/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1611 - accuracy: 0.9247 - val_loss: 0.3895 - val_accuracy: 0.8697\n","Epoch 266/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1554 - accuracy: 0.9270 - val_loss: 0.3953 - val_accuracy: 0.8712\n","Epoch 267/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1584 - accuracy: 0.9261 - val_loss: 0.3997 - val_accuracy: 0.8720\n","Epoch 268/500\n","20/20 [==============================] - 1s 44ms/step - loss: 0.1577 - accuracy: 0.9259 - val_loss: 0.3901 - val_accuracy: 0.8692\n","Epoch 269/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1563 - accuracy: 0.9266 - val_loss: 0.3901 - val_accuracy: 0.8700\n","Epoch 270/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1533 - accuracy: 0.9284 - val_loss: 0.3964 - val_accuracy: 0.8734\n","Epoch 271/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1495 - accuracy: 0.9268 - val_loss: 0.3883 - val_accuracy: 0.8636\n","Epoch 272/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1545 - accuracy: 0.9268 - val_loss: 0.3964 - val_accuracy: 0.8596\n","Epoch 273/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1543 - accuracy: 0.9289 - val_loss: 0.4070 - val_accuracy: 0.8685\n","Epoch 274/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1539 - accuracy: 0.9304 - val_loss: 0.3958 - val_accuracy: 0.8645\n","Epoch 275/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1563 - accuracy: 0.9271 - val_loss: 0.3933 - val_accuracy: 0.8620\n","Epoch 276/500\n","20/20 [==============================] - 1s 51ms/step - loss: 0.1530 - accuracy: 0.9273 - val_loss: 0.4045 - val_accuracy: 0.8677\n","Epoch 277/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1488 - accuracy: 0.9290 - val_loss: 0.4014 - val_accuracy: 0.8709\n","Epoch 278/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1478 - accuracy: 0.9301 - val_loss: 0.4023 - val_accuracy: 0.8687\n","Epoch 279/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1464 - accuracy: 0.9303 - val_loss: 0.4159 - val_accuracy: 0.8650\n","Epoch 280/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1461 - accuracy: 0.9324 - val_loss: 0.4195 - val_accuracy: 0.8708\n","Epoch 281/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1473 - accuracy: 0.9301 - val_loss: 0.4165 - val_accuracy: 0.8741\n","Epoch 282/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1470 - accuracy: 0.9301 - val_loss: 0.4175 - val_accuracy: 0.8707\n","Epoch 283/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1432 - accuracy: 0.9325 - val_loss: 0.4088 - val_accuracy: 0.8730\n","Epoch 284/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1426 - accuracy: 0.9342 - val_loss: 0.4283 - val_accuracy: 0.8712\n","Epoch 285/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1465 - accuracy: 0.9306 - val_loss: 0.4263 - val_accuracy: 0.8680\n","Epoch 286/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1435 - accuracy: 0.9339 - val_loss: 0.4227 - val_accuracy: 0.8670\n","Epoch 287/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1454 - accuracy: 0.9329 - val_loss: 0.4261 - val_accuracy: 0.8656\n","Epoch 288/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1466 - accuracy: 0.9305 - val_loss: 0.4095 - val_accuracy: 0.8675\n","Epoch 289/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1422 - accuracy: 0.9313 - val_loss: 0.4451 - val_accuracy: 0.8676\n","Epoch 290/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1518 - accuracy: 0.9291 - val_loss: 0.4371 - val_accuracy: 0.8739\n","Epoch 291/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1393 - accuracy: 0.9356 - val_loss: 0.4382 - val_accuracy: 0.8702\n","Epoch 292/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1459 - accuracy: 0.9310 - val_loss: 0.4429 - val_accuracy: 0.8723\n","Epoch 293/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1403 - accuracy: 0.9338 - val_loss: 0.4423 - val_accuracy: 0.8691\n","Epoch 294/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1362 - accuracy: 0.9359 - val_loss: 0.4259 - val_accuracy: 0.8682\n","Epoch 295/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1450 - accuracy: 0.9341 - val_loss: 0.4426 - val_accuracy: 0.8700\n","Epoch 296/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1388 - accuracy: 0.9360 - val_loss: 0.4244 - val_accuracy: 0.8679\n","Epoch 297/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1384 - accuracy: 0.9380 - val_loss: 0.4540 - val_accuracy: 0.8708\n","Epoch 298/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1434 - accuracy: 0.9327 - val_loss: 0.4341 - val_accuracy: 0.8626\n","Epoch 299/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1479 - accuracy: 0.9306 - val_loss: 0.4289 - val_accuracy: 0.8693\n","Epoch 300/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1409 - accuracy: 0.9340 - val_loss: 0.4344 - val_accuracy: 0.8632\n","Epoch 301/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1440 - accuracy: 0.9326 - val_loss: 0.4491 - val_accuracy: 0.8631\n","Epoch 302/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1416 - accuracy: 0.9330 - val_loss: 0.4278 - val_accuracy: 0.8677\n","Epoch 303/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1371 - accuracy: 0.9367 - val_loss: 0.4151 - val_accuracy: 0.8652\n","Epoch 304/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1459 - accuracy: 0.9325 - val_loss: 0.4413 - val_accuracy: 0.8630\n","Epoch 305/500\n","20/20 [==============================] - 1s 45ms/step - loss: 0.1362 - accuracy: 0.9361 - val_loss: 0.4375 - val_accuracy: 0.8641\n","Epoch 306/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1388 - accuracy: 0.9363 - val_loss: 0.4434 - val_accuracy: 0.8645\n","Epoch 307/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1382 - accuracy: 0.9355 - val_loss: 0.4521 - val_accuracy: 0.8658\n","Epoch 308/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1360 - accuracy: 0.9356 - val_loss: 0.4426 - val_accuracy: 0.8649\n","Epoch 309/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1443 - accuracy: 0.9311 - val_loss: 0.4618 - val_accuracy: 0.8567\n","Epoch 310/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1428 - accuracy: 0.9340 - val_loss: 0.4439 - val_accuracy: 0.8644\n","Epoch 311/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1417 - accuracy: 0.9327 - val_loss: 0.4607 - val_accuracy: 0.8643\n","Epoch 312/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1354 - accuracy: 0.9378 - val_loss: 0.4477 - val_accuracy: 0.8724\n","Epoch 313/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1368 - accuracy: 0.9368 - val_loss: 0.4550 - val_accuracy: 0.8705\n","Epoch 314/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1377 - accuracy: 0.9360 - val_loss: 0.4584 - val_accuracy: 0.8678\n","Epoch 315/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1373 - accuracy: 0.9371 - val_loss: 0.4682 - val_accuracy: 0.8642\n","Epoch 316/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1353 - accuracy: 0.9391 - val_loss: 0.4454 - val_accuracy: 0.8670\n","Epoch 317/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1318 - accuracy: 0.9375 - val_loss: 0.4742 - val_accuracy: 0.8673\n","Epoch 318/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1335 - accuracy: 0.9378 - val_loss: 0.4602 - val_accuracy: 0.8677\n","Epoch 319/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1348 - accuracy: 0.9385 - val_loss: 0.4973 - val_accuracy: 0.8681\n","Epoch 320/500\n","20/20 [==============================] - 1s 53ms/step - loss: 0.1289 - accuracy: 0.9411 - val_loss: 0.4450 - val_accuracy: 0.8695\n","Epoch 321/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1308 - accuracy: 0.9426 - val_loss: 0.4675 - val_accuracy: 0.8729\n","Epoch 322/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1343 - accuracy: 0.9385 - val_loss: 0.4688 - val_accuracy: 0.8657\n","Epoch 323/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1341 - accuracy: 0.9384 - val_loss: 0.4719 - val_accuracy: 0.8672\n","Epoch 324/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1308 - accuracy: 0.9372 - val_loss: 0.4652 - val_accuracy: 0.8729\n","Epoch 325/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1350 - accuracy: 0.9379 - val_loss: 0.4634 - val_accuracy: 0.8723\n","Epoch 326/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1306 - accuracy: 0.9396 - val_loss: 0.4696 - val_accuracy: 0.8727\n","Epoch 327/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1321 - accuracy: 0.9382 - val_loss: 0.4706 - val_accuracy: 0.8656\n","Epoch 328/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1259 - accuracy: 0.9411 - val_loss: 0.4693 - val_accuracy: 0.8723\n","Epoch 329/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1235 - accuracy: 0.9430 - val_loss: 0.4885 - val_accuracy: 0.8711\n","Epoch 330/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1250 - accuracy: 0.9417 - val_loss: 0.4851 - val_accuracy: 0.8706\n","Epoch 331/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1248 - accuracy: 0.9438 - val_loss: 0.4884 - val_accuracy: 0.8682\n","Epoch 332/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1219 - accuracy: 0.9427 - val_loss: 0.4907 - val_accuracy: 0.8676\n","Epoch 333/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1247 - accuracy: 0.9429 - val_loss: 0.4954 - val_accuracy: 0.8721\n","Epoch 334/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1320 - accuracy: 0.9376 - val_loss: 0.4882 - val_accuracy: 0.8684\n","Epoch 335/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1266 - accuracy: 0.9401 - val_loss: 0.4869 - val_accuracy: 0.8684\n","Epoch 336/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1219 - accuracy: 0.9455 - val_loss: 0.5054 - val_accuracy: 0.8679\n","Epoch 337/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1274 - accuracy: 0.9423 - val_loss: 0.4859 - val_accuracy: 0.8673\n","Epoch 338/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1280 - accuracy: 0.9414 - val_loss: 0.4870 - val_accuracy: 0.8653\n","Epoch 339/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1275 - accuracy: 0.9406 - val_loss: 0.5005 - val_accuracy: 0.8602\n","Epoch 340/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1283 - accuracy: 0.9426 - val_loss: 0.4831 - val_accuracy: 0.8707\n","Epoch 341/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1257 - accuracy: 0.9426 - val_loss: 0.4876 - val_accuracy: 0.8643\n","Epoch 342/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1264 - accuracy: 0.9416 - val_loss: 0.4994 - val_accuracy: 0.8673\n","Epoch 343/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1217 - accuracy: 0.9463 - val_loss: 0.4830 - val_accuracy: 0.8693\n","Epoch 344/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1289 - accuracy: 0.9398 - val_loss: 0.5247 - val_accuracy: 0.8704\n","Epoch 345/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1417 - accuracy: 0.9343 - val_loss: 0.4836 - val_accuracy: 0.8696\n","Epoch 346/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1286 - accuracy: 0.9398 - val_loss: 0.4864 - val_accuracy: 0.8675\n","Epoch 347/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1250 - accuracy: 0.9443 - val_loss: 0.4932 - val_accuracy: 0.8687\n","Epoch 348/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1223 - accuracy: 0.9444 - val_loss: 0.4945 - val_accuracy: 0.8680\n","Epoch 349/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1214 - accuracy: 0.9451 - val_loss: 0.4940 - val_accuracy: 0.8687\n","Epoch 350/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1258 - accuracy: 0.9420 - val_loss: 0.5114 - val_accuracy: 0.8719\n","Epoch 351/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1263 - accuracy: 0.9417 - val_loss: 0.5088 - val_accuracy: 0.8732\n","Epoch 352/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1293 - accuracy: 0.9374 - val_loss: 0.5118 - val_accuracy: 0.8669\n","Epoch 353/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1245 - accuracy: 0.9426 - val_loss: 0.5009 - val_accuracy: 0.8661\n","Epoch 354/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1219 - accuracy: 0.9471 - val_loss: 0.5035 - val_accuracy: 0.8702\n","Epoch 355/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1237 - accuracy: 0.9416 - val_loss: 0.5233 - val_accuracy: 0.8756\n","Epoch 356/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1211 - accuracy: 0.9432 - val_loss: 0.5263 - val_accuracy: 0.8709\n","Epoch 357/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1214 - accuracy: 0.9465 - val_loss: 0.5024 - val_accuracy: 0.8684\n","Epoch 358/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1213 - accuracy: 0.9404 - val_loss: 0.5135 - val_accuracy: 0.8655\n","Epoch 359/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1250 - accuracy: 0.9414 - val_loss: 0.5087 - val_accuracy: 0.8647\n","Epoch 360/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1224 - accuracy: 0.9427 - val_loss: 0.5173 - val_accuracy: 0.8679\n","Epoch 361/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1213 - accuracy: 0.9451 - val_loss: 0.5325 - val_accuracy: 0.8734\n","Epoch 362/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1260 - accuracy: 0.9418 - val_loss: 0.5194 - val_accuracy: 0.8707\n","Epoch 363/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1185 - accuracy: 0.9446 - val_loss: 0.5243 - val_accuracy: 0.8723\n","Epoch 364/500\n","20/20 [==============================] - 1s 52ms/step - loss: 0.1163 - accuracy: 0.9464 - val_loss: 0.5301 - val_accuracy: 0.8684\n","Epoch 365/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1195 - accuracy: 0.9450 - val_loss: 0.5116 - val_accuracy: 0.8686\n","Epoch 366/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1160 - accuracy: 0.9480 - val_loss: 0.5153 - val_accuracy: 0.8690\n","Epoch 367/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1167 - accuracy: 0.9458 - val_loss: 0.5085 - val_accuracy: 0.8670\n","Epoch 368/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1135 - accuracy: 0.9493 - val_loss: 0.5309 - val_accuracy: 0.8705\n","Epoch 369/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1169 - accuracy: 0.9466 - val_loss: 0.5181 - val_accuracy: 0.8668\n","Epoch 370/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1204 - accuracy: 0.9459 - val_loss: 0.5284 - val_accuracy: 0.8710\n","Epoch 371/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1177 - accuracy: 0.9447 - val_loss: 0.5308 - val_accuracy: 0.8696\n","Epoch 372/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1182 - accuracy: 0.9476 - val_loss: 0.5415 - val_accuracy: 0.8708\n","Epoch 373/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1092 - accuracy: 0.9516 - val_loss: 0.5329 - val_accuracy: 0.8728\n","Epoch 374/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1171 - accuracy: 0.9472 - val_loss: 0.5315 - val_accuracy: 0.8679\n","Epoch 375/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1174 - accuracy: 0.9475 - val_loss: 0.5512 - val_accuracy: 0.8662\n","Epoch 376/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1172 - accuracy: 0.9475 - val_loss: 0.5511 - val_accuracy: 0.8709\n","Epoch 377/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1196 - accuracy: 0.9459 - val_loss: 0.5374 - val_accuracy: 0.8710\n","Epoch 378/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1223 - accuracy: 0.9434 - val_loss: 0.5331 - val_accuracy: 0.8681\n","Epoch 379/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1273 - accuracy: 0.9400 - val_loss: 0.5336 - val_accuracy: 0.8731\n","Epoch 380/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1219 - accuracy: 0.9423 - val_loss: 0.5468 - val_accuracy: 0.8688\n","Epoch 381/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1166 - accuracy: 0.9468 - val_loss: 0.5567 - val_accuracy: 0.8737\n","Epoch 382/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1277 - accuracy: 0.9425 - val_loss: 0.5412 - val_accuracy: 0.8664\n","Epoch 383/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1198 - accuracy: 0.9465 - val_loss: 0.5169 - val_accuracy: 0.8682\n","Epoch 384/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1118 - accuracy: 0.9501 - val_loss: 0.5422 - val_accuracy: 0.8657\n","Epoch 385/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1171 - accuracy: 0.9466 - val_loss: 0.5566 - val_accuracy: 0.8661\n","Epoch 386/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1176 - accuracy: 0.9472 - val_loss: 0.5436 - val_accuracy: 0.8609\n","Epoch 387/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1121 - accuracy: 0.9472 - val_loss: 0.5448 - val_accuracy: 0.8668\n","Epoch 388/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1133 - accuracy: 0.9483 - val_loss: 0.5304 - val_accuracy: 0.8723\n","Epoch 389/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1078 - accuracy: 0.9501 - val_loss: 0.5454 - val_accuracy: 0.8597\n","Epoch 390/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1124 - accuracy: 0.9498 - val_loss: 0.5367 - val_accuracy: 0.8712\n","Epoch 391/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1135 - accuracy: 0.9488 - val_loss: 0.5568 - val_accuracy: 0.8689\n","Epoch 392/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1043 - accuracy: 0.9520 - val_loss: 0.5652 - val_accuracy: 0.8735\n","Epoch 393/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1171 - accuracy: 0.9465 - val_loss: 0.5653 - val_accuracy: 0.8722\n","Epoch 394/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1131 - accuracy: 0.9496 - val_loss: 0.5562 - val_accuracy: 0.8728\n","Epoch 395/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1118 - accuracy: 0.9490 - val_loss: 0.5396 - val_accuracy: 0.8727\n","Epoch 396/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1166 - accuracy: 0.9469 - val_loss: 0.5564 - val_accuracy: 0.8682\n","Epoch 397/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1150 - accuracy: 0.9481 - val_loss: 0.5540 - val_accuracy: 0.8697\n","Epoch 398/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1137 - accuracy: 0.9489 - val_loss: 0.5602 - val_accuracy: 0.8684\n","Epoch 399/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1094 - accuracy: 0.9512 - val_loss: 0.5520 - val_accuracy: 0.8677\n","Epoch 400/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1139 - accuracy: 0.9461 - val_loss: 0.5492 - val_accuracy: 0.8720\n","Epoch 401/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1097 - accuracy: 0.9497 - val_loss: 0.5610 - val_accuracy: 0.8686\n","Epoch 402/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1121 - accuracy: 0.9481 - val_loss: 0.5724 - val_accuracy: 0.8677\n","Epoch 403/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1192 - accuracy: 0.9442 - val_loss: 0.5533 - val_accuracy: 0.8726\n","Epoch 404/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1131 - accuracy: 0.9490 - val_loss: 0.5672 - val_accuracy: 0.8669\n","Epoch 405/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1074 - accuracy: 0.9521 - val_loss: 0.5642 - val_accuracy: 0.8703\n","Epoch 406/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1019 - accuracy: 0.9531 - val_loss: 0.5625 - val_accuracy: 0.8711\n","Epoch 407/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1017 - accuracy: 0.9548 - val_loss: 0.5696 - val_accuracy: 0.8673\n","Epoch 408/500\n","20/20 [==============================] - 1s 53ms/step - loss: 0.1060 - accuracy: 0.9526 - val_loss: 0.5676 - val_accuracy: 0.8677\n","Epoch 409/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1092 - accuracy: 0.9498 - val_loss: 0.5642 - val_accuracy: 0.8635\n","Epoch 410/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1134 - accuracy: 0.9505 - val_loss: 0.5659 - val_accuracy: 0.8630\n","Epoch 411/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1120 - accuracy: 0.9489 - val_loss: 0.5698 - val_accuracy: 0.8711\n","Epoch 412/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1049 - accuracy: 0.9514 - val_loss: 0.5819 - val_accuracy: 0.8699\n","Epoch 413/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1085 - accuracy: 0.9511 - val_loss: 0.5701 - val_accuracy: 0.8667\n","Epoch 414/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1067 - accuracy: 0.9512 - val_loss: 0.5727 - val_accuracy: 0.8632\n","Epoch 415/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1065 - accuracy: 0.9493 - val_loss: 0.5809 - val_accuracy: 0.8673\n","Epoch 416/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1028 - accuracy: 0.9526 - val_loss: 0.5721 - val_accuracy: 0.8689\n","Epoch 417/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1098 - accuracy: 0.9499 - val_loss: 0.5867 - val_accuracy: 0.8692\n","Epoch 418/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1085 - accuracy: 0.9501 - val_loss: 0.5975 - val_accuracy: 0.8708\n","Epoch 419/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1011 - accuracy: 0.9542 - val_loss: 0.5844 - val_accuracy: 0.8714\n","Epoch 420/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1043 - accuracy: 0.9541 - val_loss: 0.5870 - val_accuracy: 0.8724\n","Epoch 421/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1043 - accuracy: 0.9514 - val_loss: 0.6010 - val_accuracy: 0.8691\n","Epoch 422/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1102 - accuracy: 0.9488 - val_loss: 0.5768 - val_accuracy: 0.8683\n","Epoch 423/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1074 - accuracy: 0.9519 - val_loss: 0.5808 - val_accuracy: 0.8718\n","Epoch 424/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1045 - accuracy: 0.9528 - val_loss: 0.5896 - val_accuracy: 0.8643\n","Epoch 425/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1054 - accuracy: 0.9526 - val_loss: 0.6024 - val_accuracy: 0.8733\n","Epoch 426/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1060 - accuracy: 0.9520 - val_loss: 0.5864 - val_accuracy: 0.8680\n","Epoch 427/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1115 - accuracy: 0.9459 - val_loss: 0.5572 - val_accuracy: 0.8737\n","Epoch 428/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1064 - accuracy: 0.9511 - val_loss: 0.5802 - val_accuracy: 0.8735\n","Epoch 429/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1087 - accuracy: 0.9502 - val_loss: 0.6134 - val_accuracy: 0.8713\n","Epoch 430/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1056 - accuracy: 0.9521 - val_loss: 0.5765 - val_accuracy: 0.8704\n","Epoch 431/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1049 - accuracy: 0.9549 - val_loss: 0.5860 - val_accuracy: 0.8699\n","Epoch 432/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1093 - accuracy: 0.9524 - val_loss: 0.5769 - val_accuracy: 0.8675\n","Epoch 433/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1048 - accuracy: 0.9522 - val_loss: 0.5885 - val_accuracy: 0.8699\n","Epoch 434/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.1066 - accuracy: 0.9528 - val_loss: 0.5975 - val_accuracy: 0.8702\n","Epoch 435/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1027 - accuracy: 0.9524 - val_loss: 0.5986 - val_accuracy: 0.8659\n","Epoch 436/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1011 - accuracy: 0.9537 - val_loss: 0.5956 - val_accuracy: 0.8682\n","Epoch 437/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1029 - accuracy: 0.9542 - val_loss: 0.6022 - val_accuracy: 0.8680\n","Epoch 438/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1034 - accuracy: 0.9530 - val_loss: 0.6188 - val_accuracy: 0.8683\n","Epoch 439/500\n","20/20 [==============================] - 1s 46ms/step - loss: 0.0990 - accuracy: 0.9535 - val_loss: 0.5940 - val_accuracy: 0.8698\n","Epoch 440/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.0994 - accuracy: 0.9566 - val_loss: 0.5835 - val_accuracy: 0.8690\n","Epoch 441/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1076 - accuracy: 0.9516 - val_loss: 0.5935 - val_accuracy: 0.8708\n","Epoch 442/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1052 - accuracy: 0.9524 - val_loss: 0.5971 - val_accuracy: 0.8712\n","Epoch 443/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0991 - accuracy: 0.9536 - val_loss: 0.5951 - val_accuracy: 0.8720\n","Epoch 444/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1056 - accuracy: 0.9513 - val_loss: 0.6078 - val_accuracy: 0.8697\n","Epoch 445/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.0962 - accuracy: 0.9565 - val_loss: 0.5999 - val_accuracy: 0.8703\n","Epoch 446/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1001 - accuracy: 0.9551 - val_loss: 0.5873 - val_accuracy: 0.8623\n","Epoch 447/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1105 - accuracy: 0.9507 - val_loss: 0.5940 - val_accuracy: 0.8704\n","Epoch 448/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1126 - accuracy: 0.9475 - val_loss: 0.5939 - val_accuracy: 0.8674\n","Epoch 449/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1009 - accuracy: 0.9568 - val_loss: 0.6170 - val_accuracy: 0.8695\n","Epoch 450/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1054 - accuracy: 0.9543 - val_loss: 0.6207 - val_accuracy: 0.8718\n","Epoch 451/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1074 - accuracy: 0.9497 - val_loss: 0.5939 - val_accuracy: 0.8683\n","Epoch 452/500\n","20/20 [==============================] - 1s 54ms/step - loss: 0.0978 - accuracy: 0.9576 - val_loss: 0.5964 - val_accuracy: 0.8686\n","Epoch 453/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1010 - accuracy: 0.9548 - val_loss: 0.6221 - val_accuracy: 0.8690\n","Epoch 454/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1027 - accuracy: 0.9537 - val_loss: 0.6270 - val_accuracy: 0.8703\n","Epoch 455/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0985 - accuracy: 0.9554 - val_loss: 0.6276 - val_accuracy: 0.8711\n","Epoch 456/500\n","20/20 [==============================] - 1s 49ms/step - loss: 0.1000 - accuracy: 0.9548 - val_loss: 0.6056 - val_accuracy: 0.8697\n","Epoch 457/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0961 - accuracy: 0.9568 - val_loss: 0.6456 - val_accuracy: 0.8676\n","Epoch 458/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1056 - accuracy: 0.9538 - val_loss: 0.6314 - val_accuracy: 0.8700\n","Epoch 459/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0940 - accuracy: 0.9583 - val_loss: 0.6097 - val_accuracy: 0.8700\n","Epoch 460/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.0969 - accuracy: 0.9566 - val_loss: 0.6132 - val_accuracy: 0.8717\n","Epoch 461/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0980 - accuracy: 0.9578 - val_loss: 0.6367 - val_accuracy: 0.8679\n","Epoch 462/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1034 - accuracy: 0.9551 - val_loss: 0.6251 - val_accuracy: 0.8673\n","Epoch 463/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0996 - accuracy: 0.9536 - val_loss: 0.6139 - val_accuracy: 0.8658\n","Epoch 464/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0974 - accuracy: 0.9567 - val_loss: 0.6121 - val_accuracy: 0.8664\n","Epoch 465/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1033 - accuracy: 0.9538 - val_loss: 0.6225 - val_accuracy: 0.8707\n","Epoch 466/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1001 - accuracy: 0.9551 - val_loss: 0.6188 - val_accuracy: 0.8685\n","Epoch 467/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0987 - accuracy: 0.9555 - val_loss: 0.6338 - val_accuracy: 0.8722\n","Epoch 468/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1005 - accuracy: 0.9540 - val_loss: 0.6240 - val_accuracy: 0.8683\n","Epoch 469/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1036 - accuracy: 0.9528 - val_loss: 0.6517 - val_accuracy: 0.8713\n","Epoch 470/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.1023 - accuracy: 0.9525 - val_loss: 0.6259 - val_accuracy: 0.8704\n","Epoch 471/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.1011 - accuracy: 0.9545 - val_loss: 0.6258 - val_accuracy: 0.8670\n","Epoch 472/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0960 - accuracy: 0.9581 - val_loss: 0.6511 - val_accuracy: 0.8666\n","Epoch 473/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0984 - accuracy: 0.9557 - val_loss: 0.6369 - val_accuracy: 0.8689\n","Epoch 474/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0985 - accuracy: 0.9567 - val_loss: 0.6199 - val_accuracy: 0.8629\n","Epoch 475/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0972 - accuracy: 0.9544 - val_loss: 0.6459 - val_accuracy: 0.8666\n","Epoch 476/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0934 - accuracy: 0.9602 - val_loss: 0.6293 - val_accuracy: 0.8691\n","Epoch 477/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0989 - accuracy: 0.9546 - val_loss: 0.6151 - val_accuracy: 0.8648\n","Epoch 478/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0963 - accuracy: 0.9581 - val_loss: 0.6173 - val_accuracy: 0.8717\n","Epoch 479/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0956 - accuracy: 0.9565 - val_loss: 0.6206 - val_accuracy: 0.8668\n","Epoch 480/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.0902 - accuracy: 0.9597 - val_loss: 0.6336 - val_accuracy: 0.8663\n","Epoch 481/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0946 - accuracy: 0.9563 - val_loss: 0.6437 - val_accuracy: 0.8728\n","Epoch 482/500\n","20/20 [==============================] - 1s 49ms/step - loss: 0.0964 - accuracy: 0.9573 - val_loss: 0.6390 - val_accuracy: 0.8686\n","Epoch 483/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0921 - accuracy: 0.9595 - val_loss: 0.6487 - val_accuracy: 0.8676\n","Epoch 484/500\n","20/20 [==============================] - 1s 49ms/step - loss: 0.0936 - accuracy: 0.9582 - val_loss: 0.6288 - val_accuracy: 0.8688\n","Epoch 485/500\n","20/20 [==============================] - 1s 49ms/step - loss: 0.0917 - accuracy: 0.9608 - val_loss: 0.6622 - val_accuracy: 0.8724\n","Epoch 486/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0943 - accuracy: 0.9577 - val_loss: 0.6459 - val_accuracy: 0.8722\n","Epoch 487/500\n","20/20 [==============================] - 1s 49ms/step - loss: 0.0991 - accuracy: 0.9576 - val_loss: 0.6435 - val_accuracy: 0.8630\n","Epoch 488/500\n","20/20 [==============================] - 1s 49ms/step - loss: 0.0923 - accuracy: 0.9584 - val_loss: 0.6417 - val_accuracy: 0.8665\n","Epoch 489/500\n","20/20 [==============================] - 1s 49ms/step - loss: 0.0969 - accuracy: 0.9582 - val_loss: 0.6595 - val_accuracy: 0.8648\n","Epoch 490/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0956 - accuracy: 0.9571 - val_loss: 0.6363 - val_accuracy: 0.8666\n","Epoch 491/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0968 - accuracy: 0.9557 - val_loss: 0.6260 - val_accuracy: 0.8660\n","Epoch 492/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0935 - accuracy: 0.9579 - val_loss: 0.6485 - val_accuracy: 0.8711\n","Epoch 493/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0907 - accuracy: 0.9594 - val_loss: 0.6623 - val_accuracy: 0.8714\n","Epoch 494/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.0886 - accuracy: 0.9616 - val_loss: 0.6636 - val_accuracy: 0.8633\n","Epoch 495/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0962 - accuracy: 0.9550 - val_loss: 0.6690 - val_accuracy: 0.8692\n","Epoch 496/500\n","20/20 [==============================] - 1s 52ms/step - loss: 0.0952 - accuracy: 0.9576 - val_loss: 0.6447 - val_accuracy: 0.8674\n","Epoch 497/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.0954 - accuracy: 0.9563 - val_loss: 0.6453 - val_accuracy: 0.8695\n","Epoch 498/500\n","20/20 [==============================] - 1s 47ms/step - loss: 0.0904 - accuracy: 0.9590 - val_loss: 0.6741 - val_accuracy: 0.8701\n","Epoch 499/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0949 - accuracy: 0.9556 - val_loss: 0.6585 - val_accuracy: 0.8710\n","Epoch 500/500\n","20/20 [==============================] - 1s 48ms/step - loss: 0.0948 - accuracy: 0.9561 - val_loss: 0.6470 - val_accuracy: 0.8690\n","time: 7min 32s (started: 2021-01-09 02:52:04 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gQdeKMIwBOCF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610161180256,"user_tz":-420,"elapsed":467212,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"42dfb45c-6bff-4d72-f5e8-54be1b8e85c3"},"source":["_, train_acc = model.evaluate(X_train, y_train, verbose=0)\r\n","_, test_acc = model.evaluate(X_test, y_test, verbose=0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 2.31 s (started: 2021-01-09 02:59:36 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qtqtdZBWCkfU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610161180257,"user_tz":-420,"elapsed":467211,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"b7567ccd-9261-47c1-8ec9-a8827c6b9087"},"source":["print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train: 0.963, Test: 0.869\n","time: 1.75 ms (started: 2021-01-09 02:59:39 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r-TigtSodiYY"},"source":["## Decision Tree"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3R_KFiT9dhdn","executionInfo":{"status":"ok","timestamp":1610161180258,"user_tz":-420,"elapsed":467208,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"6c62f83b-9a02-467c-c3bf-0a2b82853ba5"},"source":["param_dt = {\r\n","    'test_size': [0.9, 0.7, 0.5, 0.3, 0.1],\r\n","    'max_depth': [3, 5, 7],\r\n","    'criterion': ['gini', 'entropy']\r\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 2.42 ms (started: 2021-01-09 02:59:39 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHqSQIvTfdO4","executionInfo":{"status":"ok","timestamp":1610161182760,"user_tz":-420,"elapsed":469703,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"7368d5b6-ceb1-4f58-840e-f9dca2976b30"},"source":["row_format =\"{:>10}\" * (len(param_dt) + 2)\r\n","print(row_format.format('t_size', 'max_depth', 'criterion', 'akurasi', 'f1'))\r\n","acc_bfr = -math.inf\r\n","for i in param_dt['test_size']:\r\n","  for j in param_dt['max_depth']:\r\n","    for k in param_dt['criterion']:\r\n","      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\r\n","      dt = DecisionTreeClassifier(random_state=42, max_depth=j, criterion=k)\r\n","      dt.fit(X_train, y_train)\r\n","\r\n","      # print(y_test)\r\n","      pred = dt.predict(X_test)\r\n","      acc = metrics.accuracy_score(y_test, pred)\r\n","      f1 = metrics.f1_score(y_test, pred)\r\n","      if(acc > acc_bfr):\r\n","        acc_bfr = acc\r\n","        best_param_dt = {'t_size': i, 'max_depth': j, 'criterion': k, 'accuracy': acc, 'f1': f1}\r\n","        best_dt = dt\r\n","      print(row_format.format(str(i), str(j), str(k), '%.3f' % acc, '%.3f' % f1))\r\n","print('best param: ', best_param_dt)     "],"execution_count":null,"outputs":[{"output_type":"stream","text":["    t_size max_depth criterion   akurasi        f1\n","       0.9         3      gini     0.871     0.863\n","       0.9         3   entropy     0.870     0.863\n","       0.9         5      gini     0.875     0.859\n","       0.9         5   entropy     0.877     0.866\n","       0.9         7      gini     0.868     0.850\n","       0.9         7   entropy     0.875     0.862\n","       0.7         3      gini     0.871     0.864\n","       0.7         3   entropy     0.869     0.862\n","       0.7         5      gini     0.876     0.863\n","       0.7         5   entropy     0.877     0.865\n","       0.7         7      gini     0.876     0.863\n","       0.7         7   entropy     0.878     0.867\n","       0.5         3      gini     0.871     0.864\n","       0.5         3   entropy     0.865     0.860\n","       0.5         5      gini     0.877     0.866\n","       0.5         5   entropy     0.876     0.865\n","       0.5         7      gini     0.874     0.857\n","       0.5         7   entropy     0.876     0.859\n","       0.3         3      gini     0.868     0.863\n","       0.3         3   entropy     0.864     0.860\n","       0.3         5      gini     0.876     0.866\n","       0.3         5   entropy     0.875     0.865\n","       0.3         7      gini     0.876     0.862\n","       0.3         7   entropy     0.876     0.864\n","       0.1         3      gini     0.866     0.858\n","       0.1         3   entropy     0.864     0.857\n","       0.1         5      gini     0.870     0.858\n","       0.1         5   entropy     0.869     0.858\n","       0.1         7      gini     0.876     0.865\n","       0.1         7   entropy     0.874     0.862\n","best param:  {'t_size': 0.7, 'max_depth': 7, 'criterion': 'entropy', 'accuracy': 0.8776609442060086, 'f1': 0.866683815447934}\n","time: 2.54 s (started: 2021-01-09 02:59:39 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c5uVDVPwgXlP"},"source":["## SVM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S0thU-8DggA3","executionInfo":{"status":"ok","timestamp":1610161182761,"user_tz":-420,"elapsed":469697,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"cfa4f173-eeea-469b-b2a3-4d79689cde21"},"source":["param_svm = {\r\n","  'test_size': [0.9, 0.7, 0.5, 0.3, 0.1],  \r\n","  'C'    : [1, 10, 100, 0.1],\r\n","  'gamma': [0.1, 0.01, 0.001, 1.0],\r\n","  'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\r\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 2.66 ms (started: 2021-01-09 02:59:41 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwS1Kovsghju","executionInfo":{"status":"ok","timestamp":1610171849678,"user_tz":-420,"elapsed":11136607,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"760fc7c9-8399-4a37-d904-6ef3f44785eb"},"source":["row_format =\"{:>10}\" * (len(param_svm) + 2)\r\n","print(row_format.format(*param_svm, 'akurasi', 'f1'))\r\n","acc_bfr = -math.inf\r\n","for i in param_svm['test_size']:\r\n","  for j in param_svm['C']:\r\n","    for k in param_svm['gamma']:\r\n","      for l in param_svm['kernel']:\r\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\r\n","        svc = SVC(C=j, gamma=k, kernel=l)\r\n","        svc.fit(X_train, y_train)\r\n","\r\n","        # print(y_test)\r\n","        pred = svc.predict(X_test)\r\n","        acc = metrics.accuracy_score(y_test, pred)\r\n","        f1 = metrics.f1_score(y_test, pred)\r\n","        if(acc > acc_bfr):\r\n","          acc_bfr = acc\r\n","          best_param_svm = {'t_size': i, 'C': j, 'gamma': k, 'kernel': l, 'accuracy': acc, 'f1': f1}\r\n","        print(row_format.format(str(i), str(j), str(k), str(l), '%.3f' % acc, '%.3f' % f1))\r\n","print('best param: ', best_param_svm)     "],"execution_count":null,"outputs":[{"output_type":"stream","text":[" test_size         C     gamma    kernel   akurasi        f1\n","       0.9         1       0.1    linear     0.878     0.863\n","       0.9         1       0.1      poly     0.865     0.840\n","       0.9         1       0.1       rbf     0.877     0.862\n","       0.9         1       0.1   sigmoid     0.878     0.863\n","       0.9         1      0.01    linear     0.878     0.863\n","       0.9         1      0.01      poly     0.551     0.000\n","       0.9         1      0.01       rbf     0.877     0.862\n","       0.9         1      0.01   sigmoid     0.877     0.861\n","       0.9         1     0.001    linear     0.878     0.863\n","       0.9         1     0.001      poly     0.551     0.000\n","       0.9         1     0.001       rbf     0.874     0.857\n","       0.9         1     0.001   sigmoid     0.873     0.854\n","       0.9         1       1.0    linear     0.878     0.863\n","       0.9         1       1.0      poly     0.877     0.857\n","       0.9         1       1.0       rbf     0.878     0.863\n","       0.9         1       1.0   sigmoid     0.321     0.243\n","       0.9        10       0.1    linear     0.878     0.863\n","       0.9        10       0.1      poly     0.873     0.852\n","       0.9        10       0.1       rbf     0.878     0.863\n","       0.9        10       0.1   sigmoid     0.878     0.863\n","       0.9        10      0.01    linear     0.878     0.863\n","       0.9        10      0.01      poly     0.553     0.006\n","       0.9        10      0.01       rbf     0.878     0.862\n","       0.9        10      0.01   sigmoid     0.878     0.862\n","       0.9        10     0.001    linear     0.878     0.863\n","       0.9        10     0.001      poly     0.551     0.000\n","       0.9        10     0.001       rbf     0.877     0.862\n","       0.9        10     0.001   sigmoid     0.877     0.861\n","       0.9        10       1.0    linear     0.878     0.863\n","       0.9        10       1.0      poly     0.878     0.859\n","       0.9        10       1.0       rbf     0.880     0.864\n","       0.9        10       1.0   sigmoid     0.320     0.244\n","       0.9       100       0.1    linear     0.878     0.863\n","       0.9       100       0.1      poly     0.875     0.855\n","       0.9       100       0.1       rbf     0.878     0.863\n","       0.9       100       0.1   sigmoid     0.852     0.833\n","       0.9       100      0.01    linear     0.878     0.863\n","       0.9       100      0.01      poly     0.832     0.784\n","       0.9       100      0.01       rbf     0.878     0.863\n","       0.9       100      0.01   sigmoid     0.878     0.863\n","       0.9       100     0.001    linear     0.878     0.863\n","       0.9       100     0.001      poly     0.551     0.000\n","       0.9       100     0.001       rbf     0.878     0.862\n","       0.9       100     0.001   sigmoid     0.878     0.862\n","       0.9       100       1.0    linear     0.878     0.863\n","       0.9       100       1.0      poly     0.878     0.860\n","       0.9       100       1.0       rbf     0.880     0.865\n","       0.9       100       1.0   sigmoid     0.320     0.244\n","       0.9       0.1       0.1    linear     0.878     0.862\n","       0.9       0.1       0.1      poly     0.832     0.784\n","       0.9       0.1       0.1       rbf     0.877     0.862\n","       0.9       0.1       0.1   sigmoid     0.877     0.862\n","       0.9       0.1      0.01    linear     0.878     0.862\n","       0.9       0.1      0.01      poly     0.551     0.000\n","       0.9       0.1      0.01       rbf     0.874     0.857\n","       0.9       0.1      0.01   sigmoid     0.873     0.854\n","       0.9       0.1     0.001    linear     0.878     0.862\n","       0.9       0.1     0.001      poly     0.551     0.000\n","       0.9       0.1     0.001       rbf     0.551     0.000\n","       0.9       0.1     0.001   sigmoid     0.551     0.000\n","       0.9       0.1       1.0    linear     0.878     0.862\n","       0.9       0.1       1.0      poly     0.875     0.855\n","       0.9       0.1       1.0       rbf     0.877     0.862\n","       0.9       0.1       1.0   sigmoid     0.337     0.243\n","       0.7         1       0.1    linear     0.877     0.862\n","       0.7         1       0.1      poly     0.869     0.846\n","       0.7         1       0.1       rbf     0.877     0.861\n","       0.7         1       0.1   sigmoid     0.878     0.863\n","       0.7         1      0.01    linear     0.877     0.862\n","       0.7         1      0.01      poly     0.551     0.000\n","       0.7         1      0.01       rbf     0.877     0.862\n","       0.7         1      0.01   sigmoid     0.877     0.861\n","       0.7         1     0.001    linear     0.877     0.862\n","       0.7         1     0.001      poly     0.551     0.000\n","       0.7         1     0.001       rbf     0.875     0.859\n","       0.7         1     0.001   sigmoid     0.875     0.858\n","       0.7         1       1.0    linear     0.877     0.862\n","       0.7         1       1.0      poly     0.876     0.857\n","       0.7         1       1.0       rbf     0.879     0.864\n","       0.7         1       1.0   sigmoid     0.324     0.244\n","       0.7        10       0.1    linear     0.878     0.863\n","       0.7        10       0.1      poly     0.874     0.854\n","       0.7        10       0.1       rbf     0.877     0.863\n","       0.7        10       0.1   sigmoid     0.865     0.846\n","       0.7        10      0.01    linear     0.878     0.863\n","       0.7        10      0.01      poly     0.756     0.634\n","       0.7        10      0.01       rbf     0.877     0.862\n","       0.7        10      0.01   sigmoid     0.877     0.862\n","       0.7        10     0.001    linear     0.878     0.863\n","       0.7        10     0.001      poly     0.551     0.000\n","       0.7        10     0.001       rbf     0.877     0.862\n","       0.7        10     0.001   sigmoid     0.877     0.861\n","       0.7        10       1.0    linear     0.878     0.863\n","       0.7        10       1.0      poly     0.878     0.860\n","       0.7        10       1.0       rbf     0.881     0.866\n","       0.7        10       1.0   sigmoid     0.323     0.244\n","       0.7       100       0.1    linear     0.877     0.862\n","       0.7       100       0.1      poly     0.875     0.855\n","       0.7       100       0.1       rbf     0.879     0.864\n","       0.7       100       0.1   sigmoid     0.841     0.822\n","       0.7       100      0.01    linear     0.877     0.862\n","       0.7       100      0.01      poly     0.853     0.820\n","       0.7       100      0.01       rbf     0.877     0.862\n","       0.7       100      0.01   sigmoid     0.877     0.862\n","       0.7       100     0.001    linear     0.877     0.862\n","       0.7       100     0.001      poly     0.551     0.000\n","       0.7       100     0.001       rbf     0.877     0.863\n","       0.7       100     0.001   sigmoid     0.877     0.862\n","       0.7       100       1.0    linear     0.877     0.862\n","       0.7       100       1.0      poly     0.879     0.861\n","       0.7       100       1.0       rbf     0.881     0.866\n","       0.7       100       1.0   sigmoid     0.323     0.244\n","       0.7       0.1       0.1    linear     0.877     0.862\n","       0.7       0.1       0.1      poly     0.853     0.820\n","       0.7       0.1       0.1       rbf     0.877     0.862\n","       0.7       0.1       0.1   sigmoid     0.877     0.862\n","       0.7       0.1      0.01    linear     0.877     0.862\n","       0.7       0.1      0.01      poly     0.551     0.000\n","       0.7       0.1      0.01       rbf     0.875     0.859\n","       0.7       0.1      0.01   sigmoid     0.875     0.858\n","       0.7       0.1     0.001    linear     0.877     0.862\n","       0.7       0.1     0.001      poly     0.551     0.000\n","       0.7       0.1     0.001       rbf     0.864     0.839\n","       0.7       0.1     0.001   sigmoid     0.559     0.035\n","       0.7       0.1       1.0    linear     0.877     0.862\n","       0.7       0.1       1.0      poly     0.875     0.855\n","       0.7       0.1       1.0       rbf     0.877     0.862\n","       0.7       0.1       1.0   sigmoid     0.329     0.244\n","       0.5         1       0.1    linear     0.876     0.861\n","       0.5         1       0.1      poly     0.870     0.847\n","       0.5         1       0.1       rbf     0.876     0.861\n","       0.5         1       0.1   sigmoid     0.877     0.862\n","       0.5         1      0.01    linear     0.876     0.861\n","       0.5         1      0.01      poly     0.550     0.000\n","       0.5         1      0.01       rbf     0.876     0.861\n","       0.5         1      0.01   sigmoid     0.876     0.861\n","       0.5         1     0.001    linear     0.876     0.861\n","       0.5         1     0.001      poly     0.550     0.000\n","       0.5         1     0.001       rbf     0.875     0.859\n","       0.5         1     0.001   sigmoid     0.874     0.857\n","       0.5         1       1.0    linear     0.876     0.861\n","       0.5         1       1.0      poly     0.876     0.857\n","       0.5         1       1.0       rbf     0.879     0.865\n","       0.5         1       1.0   sigmoid     0.324     0.243\n","       0.5        10       0.1    linear     0.876     0.861\n","       0.5        10       0.1      poly     0.873     0.853\n","       0.5        10       0.1       rbf     0.877     0.863\n","       0.5        10       0.1   sigmoid     0.857     0.837\n","       0.5        10      0.01    linear     0.876     0.861\n","       0.5        10      0.01      poly     0.797     0.721\n","       0.5        10      0.01       rbf     0.876     0.861\n","       0.5        10      0.01   sigmoid     0.876     0.861\n","       0.5        10     0.001    linear     0.876     0.861\n","       0.5        10     0.001      poly     0.550     0.000\n","       0.5        10     0.001       rbf     0.876     0.861\n","       0.5        10     0.001   sigmoid     0.876     0.861\n","       0.5        10       1.0    linear     0.876     0.861\n","       0.5        10       1.0      poly     0.877     0.859\n","       0.5        10       1.0       rbf     0.880     0.865\n","       0.5        10       1.0   sigmoid     0.324     0.243\n","       0.5       100       0.1    linear     0.876     0.861\n","       0.5       100       0.1      poly     0.874     0.854\n","       0.5       100       0.1       rbf     0.878     0.863\n","       0.5       100       0.1   sigmoid     0.841     0.822\n","       0.5       100      0.01    linear     0.876     0.861\n","       0.5       100      0.01      poly     0.859     0.830\n","       0.5       100      0.01       rbf     0.876     0.861\n","       0.5       100      0.01   sigmoid     0.876     0.861\n","       0.5       100     0.001    linear     0.876     0.861\n","       0.5       100     0.001      poly     0.550     0.000\n","       0.5       100     0.001       rbf     0.876     0.861\n","       0.5       100     0.001   sigmoid     0.876     0.861\n","       0.5       100       1.0    linear     0.876     0.861\n","       0.5       100       1.0      poly     0.877     0.860\n","       0.5       100       1.0       rbf     0.881     0.866\n","       0.5       100       1.0   sigmoid     0.324     0.243\n","       0.5       0.1       0.1    linear     0.876     0.861\n","       0.5       0.1       0.1      poly     0.859     0.830\n","       0.5       0.1       0.1       rbf     0.876     0.861\n","       0.5       0.1       0.1   sigmoid     0.876     0.860\n","       0.5       0.1      0.01    linear     0.876     0.861\n","       0.5       0.1      0.01      poly     0.550     0.000\n","       0.5       0.1      0.01       rbf     0.875     0.859\n","       0.5       0.1      0.01   sigmoid     0.874     0.857\n","       0.5       0.1     0.001    linear     0.876     0.861\n","       0.5       0.1     0.001      poly     0.550     0.000\n","       0.5       0.1     0.001       rbf     0.871     0.852\n","       0.5       0.1     0.001   sigmoid     0.835     0.788\n","       0.5       0.1       1.0    linear     0.876     0.861\n","       0.5       0.1       1.0      poly     0.874     0.854\n","       0.5       0.1       1.0       rbf     0.877     0.862\n","       0.5       0.1       1.0   sigmoid     0.327     0.243\n","       0.3         1       0.1    linear     0.876     0.861\n","       0.3         1       0.1      poly     0.870     0.848\n","       0.3         1       0.1       rbf     0.876     0.861\n","       0.3         1       0.1   sigmoid     0.877     0.863\n","       0.3         1      0.01    linear     0.876     0.861\n","       0.3         1      0.01      poly     0.550     0.000\n","       0.3         1      0.01       rbf     0.876     0.861\n","       0.3         1      0.01   sigmoid     0.876     0.861\n","       0.3         1     0.001    linear     0.876     0.861\n","       0.3         1     0.001      poly     0.550     0.000\n","       0.3         1     0.001       rbf     0.875     0.860\n","       0.3         1     0.001   sigmoid     0.874     0.858\n","       0.3         1       1.0    linear     0.876     0.861\n","       0.3         1       1.0      poly     0.875     0.857\n","       0.3         1       1.0       rbf     0.880     0.866\n","       0.3         1       1.0   sigmoid     0.323     0.245\n","       0.3        10       0.1    linear     0.876     0.861\n","       0.3        10       0.1      poly     0.873     0.852\n","       0.3        10       0.1       rbf     0.876     0.864\n","       0.3        10       0.1   sigmoid     0.850     0.831\n","       0.3        10      0.01    linear     0.876     0.861\n","       0.3        10      0.01      poly     0.813     0.750\n","       0.3        10      0.01       rbf     0.876     0.861\n","       0.3        10      0.01   sigmoid     0.876     0.861\n","       0.3        10     0.001    linear     0.876     0.861\n","       0.3        10     0.001      poly     0.550     0.000\n","       0.3        10     0.001       rbf     0.876     0.861\n","       0.3        10     0.001   sigmoid     0.876     0.861\n","       0.3        10       1.0    linear     0.876     0.861\n","       0.3        10       1.0      poly     0.877     0.859\n","       0.3        10       1.0       rbf     0.880     0.867\n","       0.3        10       1.0   sigmoid     0.323     0.245\n","       0.3       100       0.1    linear     0.876     0.861\n","       0.3       100       0.1      poly     0.874     0.854\n","       0.3       100       0.1       rbf     0.878     0.863\n","       0.3       100       0.1   sigmoid     0.837     0.818\n","       0.3       100      0.01    linear     0.876     0.861\n","       0.3       100      0.01      poly     0.860     0.832\n","       0.3       100      0.01       rbf     0.876     0.861\n","       0.3       100      0.01   sigmoid     0.876     0.861\n","       0.3       100     0.001    linear     0.876     0.861\n","       0.3       100     0.001      poly     0.550     0.000\n","       0.3       100     0.001       rbf     0.876     0.861\n","       0.3       100     0.001   sigmoid     0.876     0.861\n","       0.3       100       1.0    linear     0.876     0.861\n","       0.3       100       1.0      poly     0.877     0.860\n","       0.3       100       1.0       rbf     0.880     0.867\n","       0.3       100       1.0   sigmoid     0.323     0.245\n","       0.3       0.1       0.1    linear     0.876     0.861\n","       0.3       0.1       0.1      poly     0.860     0.832\n","       0.3       0.1       0.1       rbf     0.876     0.861\n","       0.3       0.1       0.1   sigmoid     0.876     0.861\n","       0.3       0.1      0.01    linear     0.876     0.861\n","       0.3       0.1      0.01      poly     0.550     0.000\n","       0.3       0.1      0.01       rbf     0.875     0.860\n","       0.3       0.1      0.01   sigmoid     0.874     0.858\n","       0.3       0.1     0.001    linear     0.876     0.861\n","       0.3       0.1     0.001      poly     0.550     0.000\n","       0.3       0.1     0.001       rbf     0.872     0.854\n","       0.3       0.1     0.001   sigmoid     0.867     0.845\n","       0.3       0.1       1.0    linear     0.876     0.861\n","       0.3       0.1       1.0      poly     0.874     0.855\n","       0.3       0.1       1.0       rbf     0.877     0.863\n","       0.3       0.1       1.0   sigmoid     0.325     0.245\n","       0.1         1       0.1    linear     0.870     0.856\n","       0.1         1       0.1      poly     0.864     0.843\n","       0.1         1       0.1       rbf     0.869     0.855\n","       0.1         1       0.1   sigmoid     0.871     0.857\n","       0.1         1      0.01    linear     0.870     0.856\n","       0.1         1      0.01      poly     0.544     0.000\n","       0.1         1      0.01       rbf     0.871     0.856\n","       0.1         1      0.01   sigmoid     0.870     0.856\n","       0.1         1     0.001    linear     0.870     0.856\n","       0.1         1     0.001      poly     0.544     0.000\n","       0.1         1     0.001       rbf     0.869     0.854\n","       0.1         1     0.001   sigmoid     0.869     0.853\n","       0.1         1       1.0    linear     0.870     0.856\n","       0.1         1       1.0      poly     0.872     0.854\n","       0.1         1       1.0       rbf     0.874     0.861\n","       0.1         1       1.0   sigmoid     0.322     0.252\n","       0.1        10       0.1    linear     0.870     0.856\n","       0.1        10       0.1      poly     0.867     0.846\n","       0.1        10       0.1       rbf     0.870     0.858\n","       0.1        10       0.1   sigmoid     0.844     0.825\n","       0.1        10      0.01    linear     0.870     0.856\n","       0.1        10      0.01      poly     0.820     0.769\n","       0.1        10      0.01       rbf     0.870     0.856\n","       0.1        10      0.01   sigmoid     0.871     0.856\n","       0.1        10     0.001    linear     0.870     0.856\n","       0.1        10     0.001      poly     0.544     0.000\n","       0.1        10     0.001       rbf     0.871     0.856\n","       0.1        10     0.001   sigmoid     0.870     0.856\n","       0.1        10       1.0    linear     0.870     0.856\n","       0.1        10       1.0      poly     0.873     0.856\n","       0.1        10       1.0       rbf     0.874     0.861\n","       0.1        10       1.0   sigmoid     0.322     0.252\n","       0.1       100       0.1    linear     0.870     0.856\n","       0.1       100       0.1      poly     0.870     0.850\n","       0.1       100       0.1       rbf     0.873     0.858\n","       0.1       100       0.1   sigmoid     0.833     0.815\n","       0.1       100      0.01    linear     0.870     0.856\n","       0.1       100      0.01      poly     0.856     0.829\n","       0.1       100      0.01       rbf     0.869     0.855\n","       0.1       100      0.01   sigmoid     0.870     0.856\n","       0.1       100     0.001    linear     0.870     0.856\n","       0.1       100     0.001      poly     0.544     0.000\n","       0.1       100     0.001       rbf     0.870     0.855\n","       0.1       100     0.001   sigmoid     0.871     0.856\n","       0.1       100       1.0    linear     0.870     0.856\n","       0.1       100       1.0      poly     0.873     0.856\n","       0.1       100       1.0       rbf     0.875     0.862\n","       0.1       100       1.0   sigmoid     0.322     0.252\n","       0.1       0.1       0.1    linear     0.871     0.856\n","       0.1       0.1       0.1      poly     0.856     0.829\n","       0.1       0.1       0.1       rbf     0.871     0.856\n","       0.1       0.1       0.1   sigmoid     0.871     0.856\n","       0.1       0.1      0.01    linear     0.871     0.856\n","       0.1       0.1      0.01      poly     0.544     0.000\n","       0.1       0.1      0.01       rbf     0.869     0.854\n","       0.1       0.1      0.01   sigmoid     0.869     0.853\n","       0.1       0.1     0.001    linear     0.871     0.856\n","       0.1       0.1     0.001      poly     0.544     0.000\n","       0.1       0.1     0.001       rbf     0.866     0.849\n","       0.1       0.1     0.001   sigmoid     0.863     0.843\n","       0.1       0.1       1.0    linear     0.871     0.856\n","       0.1       0.1       1.0      poly     0.870     0.850\n","       0.1       0.1       1.0       rbf     0.872     0.858\n","       0.1       0.1       1.0   sigmoid     0.324     0.251\n","best param:  {'t_size': 0.7, 'C': 10, 'gamma': 1.0, 'kernel': 'rbf', 'accuracy': 0.8807296137339056, 'f1': 0.8662141344117081}\n","time: 2h 57min 46s (started: 2021-01-09 02:59:41 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kwTUuS5ShORg"},"source":["## KNN"]},{"cell_type":"code","metadata":{"id":"zVqmjSfBhSP_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610176771853,"user_tz":-420,"elapsed":940,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"21d398f9-be92-4fd8-f2fc-24261e089db6"},"source":["param_knn = {\r\n","  'test_size': [0.9, 0.7, 0.5, 0.3, 0.1],  \r\n","  'n_neighbor': [3, 5],\r\n","  'weights': ['uniform', 'distance'],\r\n","  'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\r\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 2.23 ms (started: 2021-01-09 07:19:30 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3uKkftDihU_O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610177142661,"user_tz":-420,"elapsed":370187,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"b003e353-2956-4d21-dffa-dc6c1542e5cf"},"source":["row_format =\"{:>10}\" * (len(param_knn) + 2)\r\n","print(row_format.format(*param_knn, 'akurasi', 'f1'))\r\n","acc_bfr = -math.inf\r\n","for i in param_knn['test_size']:\r\n","  for j in param_knn['n_neighbor']:\r\n","    for k in param_knn['weights']:\r\n","      for l in param_knn['algorithm']:\r\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\r\n","        knn = KNeighborsClassifier(n_neighbors=j, weights=k, algorithm=l)\r\n","        knn.fit(X_train, y_train)\r\n","\r\n","        # print(y_test)\r\n","        pred = knn.predict(X_test)\r\n","        acc = metrics.accuracy_score(y_test, pred)\r\n","        f1 = metrics.f1_score(y_test, pred)\r\n","        if(acc > acc_bfr):\r\n","          acc_bfr = acc\r\n","          best_param_knn = {'t_size': i, 'n_beighbors': j, 'weights': k, 'algorithm': l, 'accuracy': acc, 'f1': f1}\r\n","        print(row_format.format(str(i), str(j), str(k), str(l), '%.3f' % acc, '%.3f' % f1))\r\n","print('best param: ', best_param_knn)     "],"execution_count":null,"outputs":[{"output_type":"stream","text":[" test_sizen_neighbor   weights algorithm   akurasi        f1\n","       0.9         3   uniform      auto     0.862     0.845\n","       0.9         3   uniform ball_tree     0.862     0.846\n","       0.9         3   uniform   kd_tree     0.862     0.845\n","       0.9         3   uniform     brute     0.862     0.845\n","       0.9         3  distance      auto     0.864     0.847\n","       0.9         3  distance ball_tree     0.864     0.847\n","       0.9         3  distance   kd_tree     0.864     0.847\n","       0.9         3  distance     brute     0.864     0.847\n","       0.9         5   uniform      auto     0.869     0.853\n","       0.9         5   uniform ball_tree     0.869     0.853\n","       0.9         5   uniform   kd_tree     0.869     0.853\n","       0.9         5   uniform     brute     0.869     0.853\n","       0.9         5  distance      auto     0.869     0.853\n","       0.9         5  distance ball_tree     0.870     0.853\n","       0.9         5  distance   kd_tree     0.869     0.853\n","       0.9         5  distance     brute     0.870     0.853\n","       0.7         3   uniform      auto     0.865     0.848\n","       0.7         3   uniform ball_tree     0.864     0.848\n","       0.7         3   uniform   kd_tree     0.865     0.848\n","       0.7         3   uniform     brute     0.864     0.848\n","       0.7         3  distance      auto     0.871     0.855\n","       0.7         3  distance ball_tree     0.871     0.855\n","       0.7         3  distance   kd_tree     0.871     0.855\n","       0.7         3  distance     brute     0.871     0.855\n","       0.7         5   uniform      auto     0.868     0.853\n","       0.7         5   uniform ball_tree     0.868     0.853\n","       0.7         5   uniform   kd_tree     0.868     0.853\n","       0.7         5   uniform     brute     0.868     0.853\n","       0.7         5  distance      auto     0.875     0.859\n","       0.7         5  distance ball_tree     0.875     0.860\n","       0.7         5  distance   kd_tree     0.875     0.859\n","       0.7         5  distance     brute     0.875     0.860\n","       0.5         3   uniform      auto     0.869     0.853\n","       0.5         3   uniform ball_tree     0.868     0.853\n","       0.5         3   uniform   kd_tree     0.869     0.853\n","       0.5         3   uniform     brute     0.868     0.853\n","       0.5         3  distance      auto     0.883     0.869\n","       0.5         3  distance ball_tree     0.883     0.868\n","       0.5         3  distance   kd_tree     0.883     0.869\n","       0.5         3  distance     brute     0.883     0.868\n","       0.5         5   uniform      auto     0.871     0.856\n","       0.5         5   uniform ball_tree     0.871     0.856\n","       0.5         5   uniform   kd_tree     0.871     0.856\n","       0.5         5   uniform     brute     0.872     0.857\n","       0.5         5  distance      auto     0.887     0.872\n","       0.5         5  distance ball_tree     0.887     0.873\n","       0.5         5  distance   kd_tree     0.887     0.872\n","       0.5         5  distance     brute     0.887     0.873\n","       0.3         3   uniform      auto     0.872     0.858\n","       0.3         3   uniform ball_tree     0.872     0.858\n","       0.3         3   uniform   kd_tree     0.872     0.858\n","       0.3         3   uniform     brute     0.872     0.858\n","       0.3         3  distance      auto     0.892     0.879\n","       0.3         3  distance ball_tree     0.892     0.879\n","       0.3         3  distance   kd_tree     0.892     0.879\n","       0.3         3  distance     brute     0.891     0.878\n","       0.3         5   uniform      auto     0.873     0.860\n","       0.3         5   uniform ball_tree     0.873     0.859\n","       0.3         5   uniform   kd_tree     0.873     0.860\n","       0.3         5   uniform     brute     0.872     0.859\n","       0.3         5  distance      auto     0.895     0.882\n","       0.3         5  distance ball_tree     0.895     0.882\n","       0.3         5  distance   kd_tree     0.895     0.882\n","       0.3         5  distance     brute     0.894     0.881\n","       0.1         3   uniform      auto     0.869     0.855\n","       0.1         3   uniform ball_tree     0.869     0.855\n","       0.1         3   uniform   kd_tree     0.869     0.855\n","       0.1         3   uniform     brute     0.869     0.856\n","       0.1         3  distance      auto     0.893     0.881\n","       0.1         3  distance ball_tree     0.893     0.881\n","       0.1         3  distance   kd_tree     0.893     0.881\n","       0.1         3  distance     brute     0.893     0.882\n","       0.1         5   uniform      auto     0.868     0.856\n","       0.1         5   uniform ball_tree     0.868     0.856\n","       0.1         5   uniform   kd_tree     0.868     0.856\n","       0.1         5   uniform     brute     0.869     0.856\n","       0.1         5  distance      auto     0.894     0.883\n","       0.1         5  distance ball_tree     0.895     0.883\n","       0.1         5  distance   kd_tree     0.894     0.883\n","       0.1         5  distance     brute     0.895     0.883\n","best param:  {'t_size': 0.3, 'n_beighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'accuracy': 0.8946024434207891, 'f1': 0.8819074333800841}\n","time: 6min 8s (started: 2021-01-09 07:19:32 +00:00)\n"],"name":"stdout"}]}]}