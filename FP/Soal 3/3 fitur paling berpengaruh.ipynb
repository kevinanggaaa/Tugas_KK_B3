{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3 fitur paling berpengaruh.ipynb","provenance":[],"collapsed_sections":["cScGgSubT0ek","ox8GcKg1UWov","zRxR_pfKUnQp"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cScGgSubT0ek"},"source":["# Install dan Download Category Encoder\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tq47dLSHlcV4","executionInfo":{"status":"ok","timestamp":1610162869799,"user_tz":-420,"elapsed":3421,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"2d87277f-48bc-4c7b-c4f1-bba6a8095b78"},"source":["pip install category_encoders"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n","Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.5)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.19.4)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n","time: 2.54 s (started: 2021-01-09 03:27:46 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ox8GcKg1UWov"},"source":["# Install Ipython Autotime"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2cOigV4moN4","executionInfo":{"status":"ok","timestamp":1610162872358,"user_tz":-420,"elapsed":5971,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"847aa32a-94bc-43e0-c2aa-f856e7094bb6"},"source":["!pip install ipython-autotime\r\n","%load_ext autotime"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (51.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.6.0)\n","The autotime extension is already loaded. To reload it, use:\n","  %reload_ext autotime\n","time: 2.54 s (started: 2021-01-09 03:27:48 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p8tcBAhNUIfp"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9telD4jy3LC6","executionInfo":{"status":"ok","timestamp":1610162872359,"user_tz":-420,"elapsed":5967,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"77469d1a-ebbd-4e33-cf09-ecb8ef1b32c6"},"source":["import keras\r\n","import numpy as np\r\n","import pandas as pd\r\n","import math\r\n","from sklearn.model_selection import train_test_split\r\n","from matplotlib import pyplot\r\n","from keras.callbacks import EarlyStopping\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\r\n","from sklearn.svm import SVC\r\n","from sklearn.neighbors import KNeighborsClassifier\r\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\r\n","from sklearn.model_selection import train_test_split # Import train_test_split function\r\n","from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\r\n","from sklearn import svm\r\n","from sklearn.model_selection import KFold\r\n","from category_encoders.target_encoder import TargetEncoder\r\n","\r\n","from sklearn import tree\r\n","import matplotlib.pyplot as plt\r\n","\r\n","from category_encoders.target_encoder import TargetEncoder"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 11.2 ms (started: 2021-01-09 03:27:51 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zRxR_pfKUnQp"},"source":["# Load Data"]},{"cell_type":"markdown","metadata":{"id":"Z4HFtROXUymR"},"source":["Read data dan drop kolom yang tidak dibutuhkan"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"zCDDvlfC3S71","executionInfo":{"status":"ok","timestamp":1610162873305,"user_tz":-420,"elapsed":6906,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"f83410c2-dbb5-4e4f-f2c9-c9e876db56bf"},"source":["df = pd.read_csv(\"winemag-data_first150k.csv\")\r\n","df.drop(columns=['country', 'province', 'region_1', 'variety', 'description', 'Unnamed: 0', 'region_2'], inplace=True)\r\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>designation</th>\n","      <th>points</th>\n","      <th>price</th>\n","      <th>winery</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Martha's Vineyard</td>\n","      <td>96</td>\n","      <td>235.0</td>\n","      <td>Heitz</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Carodorum Selección Especial Reserva</td>\n","      <td>96</td>\n","      <td>110.0</td>\n","      <td>Bodega Carmen Rodríguez</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Special Selected Late Harvest</td>\n","      <td>96</td>\n","      <td>90.0</td>\n","      <td>Macauley</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Reserve</td>\n","      <td>96</td>\n","      <td>65.0</td>\n","      <td>Ponzi</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>La Brûlade</td>\n","      <td>95</td>\n","      <td>66.0</td>\n","      <td>Domaine de la Bégude</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>150925</th>\n","      <td>NaN</td>\n","      <td>91</td>\n","      <td>20.0</td>\n","      <td>Feudi di San Gregorio</td>\n","    </tr>\n","    <tr>\n","      <th>150926</th>\n","      <td>Cuvée Prestige</td>\n","      <td>91</td>\n","      <td>27.0</td>\n","      <td>H.Germain</td>\n","    </tr>\n","    <tr>\n","      <th>150927</th>\n","      <td>Terre di Dora</td>\n","      <td>91</td>\n","      <td>20.0</td>\n","      <td>Terredora</td>\n","    </tr>\n","    <tr>\n","      <th>150928</th>\n","      <td>Grand Brut Rosé</td>\n","      <td>90</td>\n","      <td>52.0</td>\n","      <td>Gosset</td>\n","    </tr>\n","    <tr>\n","      <th>150929</th>\n","      <td>NaN</td>\n","      <td>90</td>\n","      <td>15.0</td>\n","      <td>Alois Lageder</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150930 rows × 4 columns</p>\n","</div>"],"text/plain":["                                 designation  ...                   winery\n","0                          Martha's Vineyard  ...                    Heitz\n","1       Carodorum Selección Especial Reserva  ...  Bodega Carmen Rodríguez\n","2              Special Selected Late Harvest  ...                 Macauley\n","3                                    Reserve  ...                    Ponzi\n","4                                 La Brûlade  ...     Domaine de la Bégude\n","...                                      ...  ...                      ...\n","150925                                   NaN  ...    Feudi di San Gregorio\n","150926                        Cuvée Prestige  ...                H.Germain\n","150927                         Terre di Dora  ...                Terredora\n","150928                       Grand Brut Rosé  ...                   Gosset\n","150929                                   NaN  ...            Alois Lageder\n","\n","[150930 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"stream","text":["time: 751 ms (started: 2021-01-09 03:27:51 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-eGEHwmqVB6j"},"source":["Assign df_disc dengan data yang tidak memiliki nilai null"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"paZNPf7O39YM","executionInfo":{"status":"ok","timestamp":1610162873306,"user_tz":-420,"elapsed":6897,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"284f1d1d-4b6d-4e9e-cb09-8b5b5684c465"},"source":["df_disc = df.copy()\r\n","for col in df_disc.columns:\r\n","    df_disc = df_disc[df_disc[col].notnull()]\r\n","\r\n","df_disc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>designation</th>\n","      <th>points</th>\n","      <th>price</th>\n","      <th>winery</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Martha's Vineyard</td>\n","      <td>96</td>\n","      <td>235.0</td>\n","      <td>Heitz</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Carodorum Selección Especial Reserva</td>\n","      <td>96</td>\n","      <td>110.0</td>\n","      <td>Bodega Carmen Rodríguez</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Special Selected Late Harvest</td>\n","      <td>96</td>\n","      <td>90.0</td>\n","      <td>Macauley</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Reserve</td>\n","      <td>96</td>\n","      <td>65.0</td>\n","      <td>Ponzi</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>La Brûlade</td>\n","      <td>95</td>\n","      <td>66.0</td>\n","      <td>Domaine de la Bégude</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>150923</th>\n","      <td>Demi-Sec</td>\n","      <td>91</td>\n","      <td>30.0</td>\n","      <td>Jacquart</td>\n","    </tr>\n","    <tr>\n","      <th>150924</th>\n","      <td>Diamant Bleu</td>\n","      <td>91</td>\n","      <td>70.0</td>\n","      <td>Heidsieck &amp; Co Monopole</td>\n","    </tr>\n","    <tr>\n","      <th>150926</th>\n","      <td>Cuvée Prestige</td>\n","      <td>91</td>\n","      <td>27.0</td>\n","      <td>H.Germain</td>\n","    </tr>\n","    <tr>\n","      <th>150927</th>\n","      <td>Terre di Dora</td>\n","      <td>91</td>\n","      <td>20.0</td>\n","      <td>Terredora</td>\n","    </tr>\n","    <tr>\n","      <th>150928</th>\n","      <td>Grand Brut Rosé</td>\n","      <td>90</td>\n","      <td>52.0</td>\n","      <td>Gosset</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>94924 rows × 4 columns</p>\n","</div>"],"text/plain":["                                 designation  ...                   winery\n","0                          Martha's Vineyard  ...                    Heitz\n","1       Carodorum Selección Especial Reserva  ...  Bodega Carmen Rodríguez\n","2              Special Selected Late Harvest  ...                 Macauley\n","3                                    Reserve  ...                    Ponzi\n","4                                 La Brûlade  ...     Domaine de la Bégude\n","...                                      ...  ...                      ...\n","150923                              Demi-Sec  ...                 Jacquart\n","150924                          Diamant Bleu  ...  Heidsieck & Co Monopole\n","150926                        Cuvée Prestige  ...                H.Germain\n","150927                         Terre di Dora  ...                Terredora\n","150928                       Grand Brut Rosé  ...                   Gosset\n","\n","[94924 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"stream","text":["time: 85.4 ms (started: 2021-01-09 03:27:51 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sST7j2Y5VYvX"},"source":["Assign df_disc dengan data yang pada kolom \"winery\" memiliki nilai yang duplicate"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwNxgWeggcWW","executionInfo":{"status":"ok","timestamp":1610162873307,"user_tz":-420,"elapsed":6890,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"beb11ee6-ab06-4c71-d08c-29762b985cf8"},"source":["df_disc = df_disc[df_disc.duplicated(subset=[\"designation\"], keep=False)]\r\n","print(df_disc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                 designation  points  price                   winery\n","0          Martha's Vineyard      96  235.0                    Heitz\n","3                    Reserve      96   65.0                    Ponzi\n","5                  Numanthia      95   73.0                Numanthia\n","6                  San Román      95   65.0                 Maurodos\n","9       Gap's Crown Vineyard      95   60.0                Blue Farm\n","...                      ...     ...    ...                      ...\n","150923              Demi-Sec      91   30.0                 Jacquart\n","150924          Diamant Bleu      91   70.0  Heidsieck & Co Monopole\n","150926        Cuvée Prestige      91   27.0                H.Germain\n","150927         Terre di Dora      91   20.0                Terredora\n","150928       Grand Brut Rosé      90   52.0                   Gosset\n","\n","[83055 rows x 4 columns]\n","time: 47.4 ms (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lvP-dr6IWN_P"},"source":["Assign df_disc dengan data yang pada kolom \"designation\" memiliki nilai yang duplicate"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70eGoHFGjv0J","executionInfo":{"status":"ok","timestamp":1610162873308,"user_tz":-420,"elapsed":6884,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"d14147d0-a56d-4eb7-8a1b-2fbcad96282c"},"source":["df_disc = df_disc[df_disc.duplicated(subset=[\"winery\"], keep=False)]\r\n","print(df_disc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                 designation  points  price                   winery\n","0          Martha's Vineyard      96  235.0                    Heitz\n","3                    Reserve      96   65.0                    Ponzi\n","5                  Numanthia      95   73.0                Numanthia\n","6                  San Román      95   65.0                 Maurodos\n","9       Gap's Crown Vineyard      95   60.0                Blue Farm\n","...                      ...     ...    ...                      ...\n","150923              Demi-Sec      91   30.0                 Jacquart\n","150924          Diamant Bleu      91   70.0  Heidsieck & Co Monopole\n","150926        Cuvée Prestige      91   27.0                H.Germain\n","150927         Terre di Dora      91   20.0                Terredora\n","150928       Grand Brut Rosé      90   52.0                   Gosset\n","\n","[81884 rows x 4 columns]\n","time: 35.2 ms (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XdCia0ITXIfZ"},"source":["Mendiskritkan target menjadi kontinu menggunakan qcut dari pandas dengan parameter pd.qcut(kolom, jumlah_kelas, label) dan replace kolom target (price) dengan angka"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hRbiEc4yAwF2","executionInfo":{"status":"ok","timestamp":1610162873309,"user_tz":-420,"elapsed":6879,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"d78ae49f-8ae4-43cc-f922-2aa39b76e568"},"source":["df_disc['points'] = pd.qcut(df_disc['points'], 2, labels=['low', 'high'])\r\n","df_disc['points'].replace({'low': 0, 'high': 1}, inplace=True)\r\n","df_disc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>designation</th>\n","      <th>points</th>\n","      <th>price</th>\n","      <th>winery</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Martha's Vineyard</td>\n","      <td>1</td>\n","      <td>235.0</td>\n","      <td>Heitz</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Reserve</td>\n","      <td>1</td>\n","      <td>65.0</td>\n","      <td>Ponzi</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Numanthia</td>\n","      <td>1</td>\n","      <td>73.0</td>\n","      <td>Numanthia</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>San Román</td>\n","      <td>1</td>\n","      <td>65.0</td>\n","      <td>Maurodos</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Gap's Crown Vineyard</td>\n","      <td>1</td>\n","      <td>60.0</td>\n","      <td>Blue Farm</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>150923</th>\n","      <td>Demi-Sec</td>\n","      <td>1</td>\n","      <td>30.0</td>\n","      <td>Jacquart</td>\n","    </tr>\n","    <tr>\n","      <th>150924</th>\n","      <td>Diamant Bleu</td>\n","      <td>1</td>\n","      <td>70.0</td>\n","      <td>Heidsieck &amp; Co Monopole</td>\n","    </tr>\n","    <tr>\n","      <th>150926</th>\n","      <td>Cuvée Prestige</td>\n","      <td>1</td>\n","      <td>27.0</td>\n","      <td>H.Germain</td>\n","    </tr>\n","    <tr>\n","      <th>150927</th>\n","      <td>Terre di Dora</td>\n","      <td>1</td>\n","      <td>20.0</td>\n","      <td>Terredora</td>\n","    </tr>\n","    <tr>\n","      <th>150928</th>\n","      <td>Grand Brut Rosé</td>\n","      <td>1</td>\n","      <td>52.0</td>\n","      <td>Gosset</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>81884 rows × 4 columns</p>\n","</div>"],"text/plain":["                 designation  points  price                   winery\n","0          Martha's Vineyard       1  235.0                    Heitz\n","3                    Reserve       1   65.0                    Ponzi\n","5                  Numanthia       1   73.0                Numanthia\n","6                  San Román       1   65.0                 Maurodos\n","9       Gap's Crown Vineyard       1   60.0                Blue Farm\n","...                      ...     ...    ...                      ...\n","150923              Demi-Sec       1   30.0                 Jacquart\n","150924          Diamant Bleu       1   70.0  Heidsieck & Co Monopole\n","150926        Cuvée Prestige       1   27.0                H.Germain\n","150927         Terre di Dora       1   20.0                Terredora\n","150928       Grand Brut Rosé       1   52.0                   Gosset\n","\n","[81884 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":16},{"output_type":"stream","text":["time: 86 ms (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aNJHqMt5ZBbG"},"source":["# Encoding"]},{"cell_type":"markdown","metadata":{"id":"Nm8rxTFqYUIj"},"source":["Menggunakan Target Encoder yang meng-encode berdasarkan target. Value yang diberikan antara 0 sampai 1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"zZQU1En-_SMd","executionInfo":{"status":"ok","timestamp":1610162873779,"user_tz":-420,"elapsed":7345,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"c271aaf7-bee2-4649-d629-9eaa2fb7c81e"},"source":["te = TargetEncoder()\r\n","\r\n","y = df_disc['points'].values\r\n","X = df_disc.drop(columns=['points']).values\r\n","te.fit(X, y)\r\n","X = te.transform(X)\r\n","\r\n","X.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n","  elif pd.api.types.is_categorical(cols):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.848404</td>\n","      <td>0.999991</td>\n","      <td>0.848404</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.359072</td>\n","      <td>0.781705</td>\n","      <td>0.795918</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.999486</td>\n","      <td>0.794118</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.973267</td>\n","      <td>0.781705</td>\n","      <td>0.899943</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.781250</td>\n","      <td>0.761444</td>\n","      <td>0.973267</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1         2\n","0  0.848404  0.999991  0.848404\n","1  0.359072  0.781705  0.795918\n","2  0.999486  0.794118  1.000000\n","3  0.973267  0.781705  0.899943\n","4  0.781250  0.761444  0.973267"]},"metadata":{"tags":[]},"execution_count":17},{"output_type":"stream","text":["time: 345 ms (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xTwv2RgJZMvX"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"lIzA7S8xZgR2"},"source":["## ANN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUvzZoBeBfC8","executionInfo":{"status":"ok","timestamp":1610162873780,"user_tz":-420,"elapsed":7342,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"50d9122e-22d0-494c-9866-bcc1fc5e1460"},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 16.3 ms (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aI7PF7sWBnAF","executionInfo":{"status":"ok","timestamp":1610162874153,"user_tz":-420,"elapsed":7711,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"e127b7cb-7054-4026-cb2e-c333be70943b"},"source":["model=keras.models.Sequential([\r\n","    keras.layers.Dense(512, input_dim = X_train.shape[1], activation='relu'),\r\n","    keras.layers.Dense(units=256, activation='relu'),\r\n","    keras.layers.Dense(units=128, activation='relu'),\r\n","\r\n","    keras.layers.Dense(units=1, activation=\"sigmoid\"),\r\n","],name=\"Initial_model\",)\r\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"Initial_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 512)               2048      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 129       \n","=================================================================\n","Total params: 166,401\n","Trainable params: 166,401\n","Non-trainable params: 0\n","_________________________________________________________________\n","time: 300 ms (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOln_lhU4VNN","executionInfo":{"status":"ok","timestamp":1610162874154,"user_tz":-420,"elapsed":7708,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"b9fa7322-e985-49de-ca4e-edbaa23a344a"},"source":["learning_rate = 0.005\r\n","optimizer = keras.optimizers.Adam(lr=learning_rate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 1.66 ms (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5r_b7es4XxF","executionInfo":{"status":"ok","timestamp":1610162874154,"user_tz":-420,"elapsed":7702,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"31aac181-8031-45cb-d0f0-e36ce910547d"},"source":["model.compile(optimizer=optimizer,\r\n","            loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 34.2 ms (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hUL50u7l4aw2","executionInfo":{"status":"ok","timestamp":1610162874155,"user_tz":-420,"elapsed":7699,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"cd62f37d-2894-4db9-9728-9913d9e7db16"},"source":["early_stopping_monitor = EarlyStopping(\r\n","    monitor='val_loss',\r\n","    min_delta=0,\r\n","    patience=1000,\r\n","    verbose=0,\r\n","    mode='auto',\r\n","    baseline=None,\r\n","    restore_best_weights=True\r\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 2.77 ms (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_c5zURT4dx8","executionInfo":{"status":"ok","timestamp":1610163452048,"user_tz":-420,"elapsed":585587,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"ff6f966e-d27d-4567-91ea-301839f8f64e"},"source":["history = model.fit(X_train, y_train,\r\n","                    epochs=500, batch_size=1024,\r\n","                    validation_data=(X_test, y_test), \r\n","                    verbose=1, callbacks=[early_stopping_monitor])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n","24/24 [==============================] - 2s 54ms/step - loss: 0.4685 - accuracy: 0.7360 - val_loss: 0.2753 - val_accuracy: 0.8769\n","Epoch 2/500\n","24/24 [==============================] - 1s 44ms/step - loss: 0.2778 - accuracy: 0.8753 - val_loss: 0.2675 - val_accuracy: 0.8800\n","Epoch 3/500\n","24/24 [==============================] - 1s 45ms/step - loss: 0.2764 - accuracy: 0.8756 - val_loss: 0.2596 - val_accuracy: 0.8812\n","Epoch 4/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2627 - accuracy: 0.8796 - val_loss: 0.2565 - val_accuracy: 0.8797\n","Epoch 5/500\n","24/24 [==============================] - 1s 52ms/step - loss: 0.2578 - accuracy: 0.8782 - val_loss: 0.2513 - val_accuracy: 0.8816\n","Epoch 6/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2592 - accuracy: 0.8756 - val_loss: 0.2507 - val_accuracy: 0.8819\n","Epoch 7/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2509 - accuracy: 0.8803 - val_loss: 0.2543 - val_accuracy: 0.8779\n","Epoch 8/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2547 - accuracy: 0.8773 - val_loss: 0.2489 - val_accuracy: 0.8813\n","Epoch 9/500\n","24/24 [==============================] - 1s 45ms/step - loss: 0.2540 - accuracy: 0.8762 - val_loss: 0.2488 - val_accuracy: 0.8811\n","Epoch 10/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2476 - accuracy: 0.8818 - val_loss: 0.2465 - val_accuracy: 0.8811\n","Epoch 11/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2521 - accuracy: 0.8779 - val_loss: 0.2476 - val_accuracy: 0.8810\n","Epoch 12/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2466 - accuracy: 0.8831 - val_loss: 0.2466 - val_accuracy: 0.8809\n","Epoch 13/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2457 - accuracy: 0.8807 - val_loss: 0.2440 - val_accuracy: 0.8833\n","Epoch 14/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2495 - accuracy: 0.8784 - val_loss: 0.2468 - val_accuracy: 0.8829\n","Epoch 15/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2413 - accuracy: 0.8839 - val_loss: 0.2473 - val_accuracy: 0.8814\n","Epoch 16/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2439 - accuracy: 0.8841 - val_loss: 0.2440 - val_accuracy: 0.8833\n","Epoch 17/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2482 - accuracy: 0.8791 - val_loss: 0.2467 - val_accuracy: 0.8797\n","Epoch 18/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2432 - accuracy: 0.8815 - val_loss: 0.2491 - val_accuracy: 0.8827\n","Epoch 19/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2504 - accuracy: 0.8791 - val_loss: 0.2466 - val_accuracy: 0.8809\n","Epoch 20/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2493 - accuracy: 0.8784 - val_loss: 0.2469 - val_accuracy: 0.8810\n","Epoch 21/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2474 - accuracy: 0.8772 - val_loss: 0.2471 - val_accuracy: 0.8811\n","Epoch 22/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2488 - accuracy: 0.8800 - val_loss: 0.2474 - val_accuracy: 0.8828\n","Epoch 23/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2479 - accuracy: 0.8806 - val_loss: 0.2501 - val_accuracy: 0.8801\n","Epoch 24/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2538 - accuracy: 0.8778 - val_loss: 0.2466 - val_accuracy: 0.8822\n","Epoch 25/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2499 - accuracy: 0.8789 - val_loss: 0.2449 - val_accuracy: 0.8815\n","Epoch 26/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2445 - accuracy: 0.8824 - val_loss: 0.2452 - val_accuracy: 0.8837\n","Epoch 27/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2516 - accuracy: 0.8789 - val_loss: 0.2455 - val_accuracy: 0.8837\n","Epoch 28/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2497 - accuracy: 0.8781 - val_loss: 0.2439 - val_accuracy: 0.8840\n","Epoch 29/500\n","24/24 [==============================] - 1s 45ms/step - loss: 0.2454 - accuracy: 0.8814 - val_loss: 0.2456 - val_accuracy: 0.8813\n","Epoch 30/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2474 - accuracy: 0.8781 - val_loss: 0.2482 - val_accuracy: 0.8833\n","Epoch 31/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2448 - accuracy: 0.8830 - val_loss: 0.2464 - val_accuracy: 0.8836\n","Epoch 32/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2552 - accuracy: 0.8760 - val_loss: 0.2491 - val_accuracy: 0.8819\n","Epoch 33/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2476 - accuracy: 0.8775 - val_loss: 0.2480 - val_accuracy: 0.8816\n","Epoch 34/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2521 - accuracy: 0.8789 - val_loss: 0.2441 - val_accuracy: 0.8823\n","Epoch 35/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2447 - accuracy: 0.8805 - val_loss: 0.2439 - val_accuracy: 0.8829\n","Epoch 36/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2426 - accuracy: 0.8841 - val_loss: 0.2444 - val_accuracy: 0.8817\n","Epoch 37/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2496 - accuracy: 0.8775 - val_loss: 0.2514 - val_accuracy: 0.8788\n","Epoch 38/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2421 - accuracy: 0.8821 - val_loss: 0.2438 - val_accuracy: 0.8833\n","Epoch 39/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2463 - accuracy: 0.8783 - val_loss: 0.2431 - val_accuracy: 0.8832\n","Epoch 40/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2436 - accuracy: 0.8797 - val_loss: 0.2433 - val_accuracy: 0.8823\n","Epoch 41/500\n","24/24 [==============================] - 1s 45ms/step - loss: 0.2450 - accuracy: 0.8819 - val_loss: 0.2436 - val_accuracy: 0.8825\n","Epoch 42/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2433 - accuracy: 0.8825 - val_loss: 0.2473 - val_accuracy: 0.8813\n","Epoch 43/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2464 - accuracy: 0.8798 - val_loss: 0.2446 - val_accuracy: 0.8837\n","Epoch 44/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2446 - accuracy: 0.8807 - val_loss: 0.2461 - val_accuracy: 0.8835\n","Epoch 45/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2474 - accuracy: 0.8787 - val_loss: 0.2481 - val_accuracy: 0.8818\n","Epoch 46/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2435 - accuracy: 0.8825 - val_loss: 0.2456 - val_accuracy: 0.8824\n","Epoch 47/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2425 - accuracy: 0.8813 - val_loss: 0.2440 - val_accuracy: 0.8837\n","Epoch 48/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2480 - accuracy: 0.8801 - val_loss: 0.2454 - val_accuracy: 0.8819\n","Epoch 49/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2429 - accuracy: 0.8811 - val_loss: 0.2422 - val_accuracy: 0.8839\n","Epoch 50/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2384 - accuracy: 0.8837 - val_loss: 0.2446 - val_accuracy: 0.8814\n","Epoch 51/500\n","24/24 [==============================] - 1s 52ms/step - loss: 0.2488 - accuracy: 0.8797 - val_loss: 0.2441 - val_accuracy: 0.8835\n","Epoch 52/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2442 - accuracy: 0.8813 - val_loss: 0.2430 - val_accuracy: 0.8819\n","Epoch 53/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2416 - accuracy: 0.8824 - val_loss: 0.2432 - val_accuracy: 0.8831\n","Epoch 54/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2476 - accuracy: 0.8812 - val_loss: 0.2446 - val_accuracy: 0.8831\n","Epoch 55/500\n","24/24 [==============================] - 1s 46ms/step - loss: 0.2450 - accuracy: 0.8823 - val_loss: 0.2425 - val_accuracy: 0.8835\n","Epoch 56/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2452 - accuracy: 0.8802 - val_loss: 0.2454 - val_accuracy: 0.8835\n","Epoch 57/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2426 - accuracy: 0.8820 - val_loss: 0.2455 - val_accuracy: 0.8828\n","Epoch 58/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2473 - accuracy: 0.8794 - val_loss: 0.2426 - val_accuracy: 0.8835\n","Epoch 59/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2467 - accuracy: 0.8799 - val_loss: 0.2426 - val_accuracy: 0.8834\n","Epoch 60/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2428 - accuracy: 0.8820 - val_loss: 0.2441 - val_accuracy: 0.8830\n","Epoch 61/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2373 - accuracy: 0.8868 - val_loss: 0.2423 - val_accuracy: 0.8831\n","Epoch 62/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2437 - accuracy: 0.8824 - val_loss: 0.2430 - val_accuracy: 0.8831\n","Epoch 63/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2471 - accuracy: 0.8792 - val_loss: 0.2430 - val_accuracy: 0.8819\n","Epoch 64/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2446 - accuracy: 0.8805 - val_loss: 0.2460 - val_accuracy: 0.8831\n","Epoch 65/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2436 - accuracy: 0.8805 - val_loss: 0.2425 - val_accuracy: 0.8836\n","Epoch 66/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2403 - accuracy: 0.8834 - val_loss: 0.2441 - val_accuracy: 0.8838\n","Epoch 67/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2446 - accuracy: 0.8802 - val_loss: 0.2445 - val_accuracy: 0.8815\n","Epoch 68/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2427 - accuracy: 0.8822 - val_loss: 0.2444 - val_accuracy: 0.8839\n","Epoch 69/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2447 - accuracy: 0.8818 - val_loss: 0.2428 - val_accuracy: 0.8831\n","Epoch 70/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2466 - accuracy: 0.8774 - val_loss: 0.2430 - val_accuracy: 0.8829\n","Epoch 71/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2451 - accuracy: 0.8788 - val_loss: 0.2437 - val_accuracy: 0.8835\n","Epoch 72/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2441 - accuracy: 0.8813 - val_loss: 0.2440 - val_accuracy: 0.8818\n","Epoch 73/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2436 - accuracy: 0.8820 - val_loss: 0.2436 - val_accuracy: 0.8833\n","Epoch 74/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2430 - accuracy: 0.8794 - val_loss: 0.2429 - val_accuracy: 0.8833\n","Epoch 75/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2429 - accuracy: 0.8837 - val_loss: 0.2432 - val_accuracy: 0.8821\n","Epoch 76/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2405 - accuracy: 0.8837 - val_loss: 0.2439 - val_accuracy: 0.8830\n","Epoch 77/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2453 - accuracy: 0.8796 - val_loss: 0.2416 - val_accuracy: 0.8830\n","Epoch 78/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2430 - accuracy: 0.8798 - val_loss: 0.2441 - val_accuracy: 0.8840\n","Epoch 79/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2405 - accuracy: 0.8823 - val_loss: 0.2472 - val_accuracy: 0.8802\n","Epoch 80/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2423 - accuracy: 0.8838 - val_loss: 0.2422 - val_accuracy: 0.8835\n","Epoch 81/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2476 - accuracy: 0.8789 - val_loss: 0.2462 - val_accuracy: 0.8817\n","Epoch 82/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2418 - accuracy: 0.8833 - val_loss: 0.2442 - val_accuracy: 0.8805\n","Epoch 83/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2414 - accuracy: 0.8823 - val_loss: 0.2449 - val_accuracy: 0.8810\n","Epoch 84/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2387 - accuracy: 0.8834 - val_loss: 0.2439 - val_accuracy: 0.8814\n","Epoch 85/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2481 - accuracy: 0.8802 - val_loss: 0.2423 - val_accuracy: 0.8836\n","Epoch 86/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2439 - accuracy: 0.8796 - val_loss: 0.2413 - val_accuracy: 0.8838\n","Epoch 87/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2421 - accuracy: 0.8806 - val_loss: 0.2433 - val_accuracy: 0.8832\n","Epoch 88/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2436 - accuracy: 0.8806 - val_loss: 0.2417 - val_accuracy: 0.8837\n","Epoch 89/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2444 - accuracy: 0.8812 - val_loss: 0.2419 - val_accuracy: 0.8830\n","Epoch 90/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2389 - accuracy: 0.8832 - val_loss: 0.2442 - val_accuracy: 0.8816\n","Epoch 91/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2432 - accuracy: 0.8809 - val_loss: 0.2425 - val_accuracy: 0.8836\n","Epoch 92/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2449 - accuracy: 0.8810 - val_loss: 0.2437 - val_accuracy: 0.8831\n","Epoch 93/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2397 - accuracy: 0.8833 - val_loss: 0.2434 - val_accuracy: 0.8831\n","Epoch 94/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2413 - accuracy: 0.8807 - val_loss: 0.2432 - val_accuracy: 0.8831\n","Epoch 95/500\n","24/24 [==============================] - 1s 53ms/step - loss: 0.2415 - accuracy: 0.8832 - val_loss: 0.2415 - val_accuracy: 0.8832\n","Epoch 96/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2394 - accuracy: 0.8830 - val_loss: 0.2438 - val_accuracy: 0.8835\n","Epoch 97/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2452 - accuracy: 0.8782 - val_loss: 0.2432 - val_accuracy: 0.8833\n","Epoch 98/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2443 - accuracy: 0.8796 - val_loss: 0.2439 - val_accuracy: 0.8811\n","Epoch 99/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2377 - accuracy: 0.8833 - val_loss: 0.2434 - val_accuracy: 0.8832\n","Epoch 100/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2407 - accuracy: 0.8828 - val_loss: 0.2413 - val_accuracy: 0.8827\n","Epoch 101/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2411 - accuracy: 0.8827 - val_loss: 0.2419 - val_accuracy: 0.8834\n","Epoch 102/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2454 - accuracy: 0.8796 - val_loss: 0.2418 - val_accuracy: 0.8816\n","Epoch 103/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2423 - accuracy: 0.8823 - val_loss: 0.2454 - val_accuracy: 0.8824\n","Epoch 104/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2439 - accuracy: 0.8805 - val_loss: 0.2505 - val_accuracy: 0.8779\n","Epoch 105/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2422 - accuracy: 0.8823 - val_loss: 0.2419 - val_accuracy: 0.8819\n","Epoch 106/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2427 - accuracy: 0.8809 - val_loss: 0.2431 - val_accuracy: 0.8809\n","Epoch 107/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2409 - accuracy: 0.8800 - val_loss: 0.2410 - val_accuracy: 0.8824\n","Epoch 108/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2439 - accuracy: 0.8795 - val_loss: 0.2450 - val_accuracy: 0.8834\n","Epoch 109/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2435 - accuracy: 0.8822 - val_loss: 0.2408 - val_accuracy: 0.8835\n","Epoch 110/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2391 - accuracy: 0.8819 - val_loss: 0.2435 - val_accuracy: 0.8812\n","Epoch 111/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2440 - accuracy: 0.8806 - val_loss: 0.2429 - val_accuracy: 0.8829\n","Epoch 112/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2404 - accuracy: 0.8821 - val_loss: 0.2422 - val_accuracy: 0.8832\n","Epoch 113/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2432 - accuracy: 0.8806 - val_loss: 0.2415 - val_accuracy: 0.8830\n","Epoch 114/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2396 - accuracy: 0.8849 - val_loss: 0.2413 - val_accuracy: 0.8833\n","Epoch 115/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2465 - accuracy: 0.8788 - val_loss: 0.2462 - val_accuracy: 0.8805\n","Epoch 116/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2481 - accuracy: 0.8749 - val_loss: 0.2430 - val_accuracy: 0.8832\n","Epoch 117/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2400 - accuracy: 0.8828 - val_loss: 0.2438 - val_accuracy: 0.8831\n","Epoch 118/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2405 - accuracy: 0.8832 - val_loss: 0.2418 - val_accuracy: 0.8833\n","Epoch 119/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2386 - accuracy: 0.8835 - val_loss: 0.2428 - val_accuracy: 0.8833\n","Epoch 120/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2398 - accuracy: 0.8832 - val_loss: 0.2417 - val_accuracy: 0.8826\n","Epoch 121/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2388 - accuracy: 0.8822 - val_loss: 0.2412 - val_accuracy: 0.8830\n","Epoch 122/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2408 - accuracy: 0.8836 - val_loss: 0.2418 - val_accuracy: 0.8829\n","Epoch 123/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2390 - accuracy: 0.8829 - val_loss: 0.2411 - val_accuracy: 0.8836\n","Epoch 124/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2407 - accuracy: 0.8806 - val_loss: 0.2412 - val_accuracy: 0.8829\n","Epoch 125/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2411 - accuracy: 0.8814 - val_loss: 0.2411 - val_accuracy: 0.8832\n","Epoch 126/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2375 - accuracy: 0.8836 - val_loss: 0.2427 - val_accuracy: 0.8797\n","Epoch 127/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2393 - accuracy: 0.8813 - val_loss: 0.2433 - val_accuracy: 0.8817\n","Epoch 128/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2392 - accuracy: 0.8826 - val_loss: 0.2428 - val_accuracy: 0.8826\n","Epoch 129/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2410 - accuracy: 0.8829 - val_loss: 0.2422 - val_accuracy: 0.8829\n","Epoch 130/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2446 - accuracy: 0.8796 - val_loss: 0.2442 - val_accuracy: 0.8816\n","Epoch 131/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2414 - accuracy: 0.8796 - val_loss: 0.2418 - val_accuracy: 0.8827\n","Epoch 132/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2417 - accuracy: 0.8801 - val_loss: 0.2421 - val_accuracy: 0.8832\n","Epoch 133/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2401 - accuracy: 0.8826 - val_loss: 0.2430 - val_accuracy: 0.8831\n","Epoch 134/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2354 - accuracy: 0.8852 - val_loss: 0.2416 - val_accuracy: 0.8832\n","Epoch 135/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2377 - accuracy: 0.8809 - val_loss: 0.2454 - val_accuracy: 0.8826\n","Epoch 136/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2447 - accuracy: 0.8820 - val_loss: 0.2415 - val_accuracy: 0.8836\n","Epoch 137/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2419 - accuracy: 0.8798 - val_loss: 0.2424 - val_accuracy: 0.8817\n","Epoch 138/500\n","24/24 [==============================] - 1s 54ms/step - loss: 0.2354 - accuracy: 0.8867 - val_loss: 0.2413 - val_accuracy: 0.8831\n","Epoch 139/500\n","24/24 [==============================] - 1s 54ms/step - loss: 0.2361 - accuracy: 0.8859 - val_loss: 0.2413 - val_accuracy: 0.8832\n","Epoch 140/500\n","24/24 [==============================] - 1s 55ms/step - loss: 0.2387 - accuracy: 0.8823 - val_loss: 0.2432 - val_accuracy: 0.8840\n","Epoch 141/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2375 - accuracy: 0.8836 - val_loss: 0.2407 - val_accuracy: 0.8832\n","Epoch 142/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2414 - accuracy: 0.8802 - val_loss: 0.2409 - val_accuracy: 0.8832\n","Epoch 143/500\n","24/24 [==============================] - 1s 55ms/step - loss: 0.2352 - accuracy: 0.8863 - val_loss: 0.2406 - val_accuracy: 0.8829\n","Epoch 144/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2377 - accuracy: 0.8839 - val_loss: 0.2418 - val_accuracy: 0.8827\n","Epoch 145/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2362 - accuracy: 0.8864 - val_loss: 0.2439 - val_accuracy: 0.8828\n","Epoch 146/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2376 - accuracy: 0.8862 - val_loss: 0.2420 - val_accuracy: 0.8829\n","Epoch 147/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2335 - accuracy: 0.8880 - val_loss: 0.2432 - val_accuracy: 0.8831\n","Epoch 148/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2401 - accuracy: 0.8824 - val_loss: 0.2413 - val_accuracy: 0.8833\n","Epoch 149/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2357 - accuracy: 0.8831 - val_loss: 0.2423 - val_accuracy: 0.8829\n","Epoch 150/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2384 - accuracy: 0.8845 - val_loss: 0.2418 - val_accuracy: 0.8828\n","Epoch 151/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2404 - accuracy: 0.8808 - val_loss: 0.2448 - val_accuracy: 0.8825\n","Epoch 152/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2397 - accuracy: 0.8828 - val_loss: 0.2411 - val_accuracy: 0.8833\n","Epoch 153/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2368 - accuracy: 0.8826 - val_loss: 0.2418 - val_accuracy: 0.8829\n","Epoch 154/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2373 - accuracy: 0.8828 - val_loss: 0.2443 - val_accuracy: 0.8823\n","Epoch 155/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2375 - accuracy: 0.8808 - val_loss: 0.2442 - val_accuracy: 0.8826\n","Epoch 156/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2414 - accuracy: 0.8806 - val_loss: 0.2416 - val_accuracy: 0.8829\n","Epoch 157/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2359 - accuracy: 0.8826 - val_loss: 0.2455 - val_accuracy: 0.8831\n","Epoch 158/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2453 - accuracy: 0.8815 - val_loss: 0.2416 - val_accuracy: 0.8837\n","Epoch 159/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2348 - accuracy: 0.8849 - val_loss: 0.2467 - val_accuracy: 0.8799\n","Epoch 160/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2308 - accuracy: 0.8866 - val_loss: 0.2420 - val_accuracy: 0.8823\n","Epoch 161/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2363 - accuracy: 0.8840 - val_loss: 0.2454 - val_accuracy: 0.8817\n","Epoch 162/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2353 - accuracy: 0.8856 - val_loss: 0.2428 - val_accuracy: 0.8830\n","Epoch 163/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2379 - accuracy: 0.8814 - val_loss: 0.2478 - val_accuracy: 0.8819\n","Epoch 164/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2365 - accuracy: 0.8841 - val_loss: 0.2445 - val_accuracy: 0.8835\n","Epoch 165/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2375 - accuracy: 0.8833 - val_loss: 0.2439 - val_accuracy: 0.8833\n","Epoch 166/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2384 - accuracy: 0.8826 - val_loss: 0.2423 - val_accuracy: 0.8833\n","Epoch 167/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2377 - accuracy: 0.8822 - val_loss: 0.2428 - val_accuracy: 0.8829\n","Epoch 168/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2345 - accuracy: 0.8830 - val_loss: 0.2439 - val_accuracy: 0.8830\n","Epoch 169/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2370 - accuracy: 0.8827 - val_loss: 0.2435 - val_accuracy: 0.8819\n","Epoch 170/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2329 - accuracy: 0.8839 - val_loss: 0.2448 - val_accuracy: 0.8827\n","Epoch 171/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2334 - accuracy: 0.8858 - val_loss: 0.2416 - val_accuracy: 0.8829\n","Epoch 172/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2359 - accuracy: 0.8840 - val_loss: 0.2426 - val_accuracy: 0.8826\n","Epoch 173/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2381 - accuracy: 0.8827 - val_loss: 0.2450 - val_accuracy: 0.8820\n","Epoch 174/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2359 - accuracy: 0.8826 - val_loss: 0.2416 - val_accuracy: 0.8837\n","Epoch 175/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2407 - accuracy: 0.8822 - val_loss: 0.2448 - val_accuracy: 0.8815\n","Epoch 176/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2376 - accuracy: 0.8831 - val_loss: 0.2428 - val_accuracy: 0.8832\n","Epoch 177/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2396 - accuracy: 0.8845 - val_loss: 0.2425 - val_accuracy: 0.8831\n","Epoch 178/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2358 - accuracy: 0.8824 - val_loss: 0.2455 - val_accuracy: 0.8833\n","Epoch 179/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2374 - accuracy: 0.8823 - val_loss: 0.2414 - val_accuracy: 0.8829\n","Epoch 180/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2350 - accuracy: 0.8831 - val_loss: 0.2438 - val_accuracy: 0.8821\n","Epoch 181/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2339 - accuracy: 0.8855 - val_loss: 0.2446 - val_accuracy: 0.8832\n","Epoch 182/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2374 - accuracy: 0.8825 - val_loss: 0.2449 - val_accuracy: 0.8820\n","Epoch 183/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2354 - accuracy: 0.8844 - val_loss: 0.2448 - val_accuracy: 0.8832\n","Epoch 184/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2379 - accuracy: 0.8829 - val_loss: 0.2436 - val_accuracy: 0.8836\n","Epoch 185/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2318 - accuracy: 0.8853 - val_loss: 0.2421 - val_accuracy: 0.8822\n","Epoch 186/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2361 - accuracy: 0.8831 - val_loss: 0.2430 - val_accuracy: 0.8823\n","Epoch 187/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2340 - accuracy: 0.8832 - val_loss: 0.2479 - val_accuracy: 0.8810\n","Epoch 188/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2397 - accuracy: 0.8824 - val_loss: 0.2433 - val_accuracy: 0.8839\n","Epoch 189/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2360 - accuracy: 0.8837 - val_loss: 0.2433 - val_accuracy: 0.8831\n","Epoch 190/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2334 - accuracy: 0.8874 - val_loss: 0.2431 - val_accuracy: 0.8832\n","Epoch 191/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2327 - accuracy: 0.8854 - val_loss: 0.2415 - val_accuracy: 0.8836\n","Epoch 192/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2353 - accuracy: 0.8831 - val_loss: 0.2424 - val_accuracy: 0.8828\n","Epoch 193/500\n","24/24 [==============================] - 1s 53ms/step - loss: 0.2316 - accuracy: 0.8875 - val_loss: 0.2449 - val_accuracy: 0.8823\n","Epoch 194/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2327 - accuracy: 0.8839 - val_loss: 0.2427 - val_accuracy: 0.8817\n","Epoch 195/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2338 - accuracy: 0.8853 - val_loss: 0.2425 - val_accuracy: 0.8830\n","Epoch 196/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2303 - accuracy: 0.8865 - val_loss: 0.2478 - val_accuracy: 0.8820\n","Epoch 197/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2363 - accuracy: 0.8844 - val_loss: 0.2470 - val_accuracy: 0.8827\n","Epoch 198/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2353 - accuracy: 0.8856 - val_loss: 0.2460 - val_accuracy: 0.8808\n","Epoch 199/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2374 - accuracy: 0.8860 - val_loss: 0.2451 - val_accuracy: 0.8824\n","Epoch 200/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2372 - accuracy: 0.8839 - val_loss: 0.2444 - val_accuracy: 0.8827\n","Epoch 201/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2311 - accuracy: 0.8842 - val_loss: 0.2439 - val_accuracy: 0.8825\n","Epoch 202/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2341 - accuracy: 0.8844 - val_loss: 0.2436 - val_accuracy: 0.8830\n","Epoch 203/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2347 - accuracy: 0.8833 - val_loss: 0.2450 - val_accuracy: 0.8832\n","Epoch 204/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2348 - accuracy: 0.8864 - val_loss: 0.2427 - val_accuracy: 0.8811\n","Epoch 205/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2278 - accuracy: 0.8882 - val_loss: 0.2433 - val_accuracy: 0.8828\n","Epoch 206/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2316 - accuracy: 0.8851 - val_loss: 0.2423 - val_accuracy: 0.8829\n","Epoch 207/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2351 - accuracy: 0.8832 - val_loss: 0.2458 - val_accuracy: 0.8809\n","Epoch 208/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2361 - accuracy: 0.8854 - val_loss: 0.2469 - val_accuracy: 0.8823\n","Epoch 209/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2313 - accuracy: 0.8879 - val_loss: 0.2446 - val_accuracy: 0.8813\n","Epoch 210/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2336 - accuracy: 0.8835 - val_loss: 0.2445 - val_accuracy: 0.8815\n","Epoch 211/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2327 - accuracy: 0.8856 - val_loss: 0.2438 - val_accuracy: 0.8831\n","Epoch 212/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2316 - accuracy: 0.8850 - val_loss: 0.2457 - val_accuracy: 0.8821\n","Epoch 213/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2320 - accuracy: 0.8880 - val_loss: 0.2423 - val_accuracy: 0.8816\n","Epoch 214/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2347 - accuracy: 0.8834 - val_loss: 0.2441 - val_accuracy: 0.8822\n","Epoch 215/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2300 - accuracy: 0.8874 - val_loss: 0.2444 - val_accuracy: 0.8824\n","Epoch 216/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2314 - accuracy: 0.8886 - val_loss: 0.2450 - val_accuracy: 0.8813\n","Epoch 217/500\n","24/24 [==============================] - 1s 47ms/step - loss: 0.2329 - accuracy: 0.8842 - val_loss: 0.2428 - val_accuracy: 0.8821\n","Epoch 218/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2354 - accuracy: 0.8848 - val_loss: 0.2450 - val_accuracy: 0.8820\n","Epoch 219/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2316 - accuracy: 0.8861 - val_loss: 0.2451 - val_accuracy: 0.8799\n","Epoch 220/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2339 - accuracy: 0.8846 - val_loss: 0.2434 - val_accuracy: 0.8820\n","Epoch 221/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2304 - accuracy: 0.8865 - val_loss: 0.2456 - val_accuracy: 0.8828\n","Epoch 222/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2310 - accuracy: 0.8878 - val_loss: 0.2436 - val_accuracy: 0.8818\n","Epoch 223/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2343 - accuracy: 0.8821 - val_loss: 0.2443 - val_accuracy: 0.8813\n","Epoch 224/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2302 - accuracy: 0.8856 - val_loss: 0.2486 - val_accuracy: 0.8795\n","Epoch 225/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2378 - accuracy: 0.8811 - val_loss: 0.2441 - val_accuracy: 0.8810\n","Epoch 226/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2295 - accuracy: 0.8868 - val_loss: 0.2428 - val_accuracy: 0.8824\n","Epoch 227/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2304 - accuracy: 0.8853 - val_loss: 0.2460 - val_accuracy: 0.8831\n","Epoch 228/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2318 - accuracy: 0.8849 - val_loss: 0.2460 - val_accuracy: 0.8833\n","Epoch 229/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2298 - accuracy: 0.8833 - val_loss: 0.2448 - val_accuracy: 0.8814\n","Epoch 230/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2334 - accuracy: 0.8863 - val_loss: 0.2463 - val_accuracy: 0.8806\n","Epoch 231/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2299 - accuracy: 0.8863 - val_loss: 0.2491 - val_accuracy: 0.8806\n","Epoch 232/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2323 - accuracy: 0.8853 - val_loss: 0.2452 - val_accuracy: 0.8812\n","Epoch 233/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2353 - accuracy: 0.8860 - val_loss: 0.2481 - val_accuracy: 0.8812\n","Epoch 234/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2284 - accuracy: 0.8875 - val_loss: 0.2476 - val_accuracy: 0.8797\n","Epoch 235/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2305 - accuracy: 0.8854 - val_loss: 0.2450 - val_accuracy: 0.8819\n","Epoch 236/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2286 - accuracy: 0.8876 - val_loss: 0.2438 - val_accuracy: 0.8816\n","Epoch 237/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2337 - accuracy: 0.8840 - val_loss: 0.2453 - val_accuracy: 0.8817\n","Epoch 238/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2322 - accuracy: 0.8852 - val_loss: 0.2468 - val_accuracy: 0.8813\n","Epoch 239/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2323 - accuracy: 0.8868 - val_loss: 0.2486 - val_accuracy: 0.8831\n","Epoch 240/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2346 - accuracy: 0.8840 - val_loss: 0.2463 - val_accuracy: 0.8826\n","Epoch 241/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2390 - accuracy: 0.8797 - val_loss: 0.2448 - val_accuracy: 0.8805\n","Epoch 242/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2285 - accuracy: 0.8889 - val_loss: 0.2449 - val_accuracy: 0.8819\n","Epoch 243/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2311 - accuracy: 0.8880 - val_loss: 0.2459 - val_accuracy: 0.8828\n","Epoch 244/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2333 - accuracy: 0.8848 - val_loss: 0.2472 - val_accuracy: 0.8833\n","Epoch 245/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2278 - accuracy: 0.8864 - val_loss: 0.2447 - val_accuracy: 0.8833\n","Epoch 246/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2285 - accuracy: 0.8846 - val_loss: 0.2463 - val_accuracy: 0.8822\n","Epoch 247/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2283 - accuracy: 0.8866 - val_loss: 0.2451 - val_accuracy: 0.8820\n","Epoch 248/500\n","24/24 [==============================] - 1s 53ms/step - loss: 0.2293 - accuracy: 0.8854 - val_loss: 0.2502 - val_accuracy: 0.8822\n","Epoch 249/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2315 - accuracy: 0.8863 - val_loss: 0.2503 - val_accuracy: 0.8803\n","Epoch 250/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2306 - accuracy: 0.8882 - val_loss: 0.2504 - val_accuracy: 0.8811\n","Epoch 251/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2318 - accuracy: 0.8853 - val_loss: 0.2489 - val_accuracy: 0.8809\n","Epoch 252/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2324 - accuracy: 0.8851 - val_loss: 0.2463 - val_accuracy: 0.8826\n","Epoch 253/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2296 - accuracy: 0.8848 - val_loss: 0.2458 - val_accuracy: 0.8808\n","Epoch 254/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2264 - accuracy: 0.8843 - val_loss: 0.2489 - val_accuracy: 0.8806\n","Epoch 255/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2253 - accuracy: 0.8882 - val_loss: 0.2482 - val_accuracy: 0.8819\n","Epoch 256/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2300 - accuracy: 0.8856 - val_loss: 0.2468 - val_accuracy: 0.8817\n","Epoch 257/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2318 - accuracy: 0.8865 - val_loss: 0.2466 - val_accuracy: 0.8815\n","Epoch 258/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2271 - accuracy: 0.8871 - val_loss: 0.2521 - val_accuracy: 0.8809\n","Epoch 259/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2276 - accuracy: 0.8873 - val_loss: 0.2511 - val_accuracy: 0.8811\n","Epoch 260/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2289 - accuracy: 0.8850 - val_loss: 0.2466 - val_accuracy: 0.8810\n","Epoch 261/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2239 - accuracy: 0.8918 - val_loss: 0.2503 - val_accuracy: 0.8816\n","Epoch 262/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2319 - accuracy: 0.8845 - val_loss: 0.2469 - val_accuracy: 0.8817\n","Epoch 263/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2300 - accuracy: 0.8861 - val_loss: 0.2469 - val_accuracy: 0.8826\n","Epoch 264/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2258 - accuracy: 0.8882 - val_loss: 0.2487 - val_accuracy: 0.8819\n","Epoch 265/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2256 - accuracy: 0.8882 - val_loss: 0.2499 - val_accuracy: 0.8799\n","Epoch 266/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2325 - accuracy: 0.8839 - val_loss: 0.2463 - val_accuracy: 0.8824\n","Epoch 267/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2274 - accuracy: 0.8868 - val_loss: 0.2467 - val_accuracy: 0.8817\n","Epoch 268/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2297 - accuracy: 0.8860 - val_loss: 0.2518 - val_accuracy: 0.8792\n","Epoch 269/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2290 - accuracy: 0.8897 - val_loss: 0.2463 - val_accuracy: 0.8811\n","Epoch 270/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2246 - accuracy: 0.8894 - val_loss: 0.2486 - val_accuracy: 0.8801\n","Epoch 271/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2275 - accuracy: 0.8867 - val_loss: 0.2504 - val_accuracy: 0.8819\n","Epoch 272/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2258 - accuracy: 0.8866 - val_loss: 0.2471 - val_accuracy: 0.8809\n","Epoch 273/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2251 - accuracy: 0.8879 - val_loss: 0.2548 - val_accuracy: 0.8835\n","Epoch 274/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2291 - accuracy: 0.8846 - val_loss: 0.2488 - val_accuracy: 0.8804\n","Epoch 275/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2279 - accuracy: 0.8858 - val_loss: 0.2463 - val_accuracy: 0.8821\n","Epoch 276/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2268 - accuracy: 0.8866 - val_loss: 0.2494 - val_accuracy: 0.8826\n","Epoch 277/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2252 - accuracy: 0.8894 - val_loss: 0.2498 - val_accuracy: 0.8819\n","Epoch 278/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2233 - accuracy: 0.8905 - val_loss: 0.2474 - val_accuracy: 0.8814\n","Epoch 279/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2252 - accuracy: 0.8901 - val_loss: 0.2498 - val_accuracy: 0.8794\n","Epoch 280/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2282 - accuracy: 0.8872 - val_loss: 0.2474 - val_accuracy: 0.8814\n","Epoch 281/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2258 - accuracy: 0.8873 - val_loss: 0.2522 - val_accuracy: 0.8804\n","Epoch 282/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2298 - accuracy: 0.8877 - val_loss: 0.2494 - val_accuracy: 0.8832\n","Epoch 283/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2254 - accuracy: 0.8853 - val_loss: 0.2505 - val_accuracy: 0.8811\n","Epoch 284/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2260 - accuracy: 0.8856 - val_loss: 0.2501 - val_accuracy: 0.8809\n","Epoch 285/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2255 - accuracy: 0.8880 - val_loss: 0.2482 - val_accuracy: 0.8814\n","Epoch 286/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2283 - accuracy: 0.8844 - val_loss: 0.2482 - val_accuracy: 0.8824\n","Epoch 287/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2276 - accuracy: 0.8861 - val_loss: 0.2495 - val_accuracy: 0.8830\n","Epoch 288/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2232 - accuracy: 0.8876 - val_loss: 0.2492 - val_accuracy: 0.8796\n","Epoch 289/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2249 - accuracy: 0.8865 - val_loss: 0.2485 - val_accuracy: 0.8814\n","Epoch 290/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2252 - accuracy: 0.8841 - val_loss: 0.2537 - val_accuracy: 0.8797\n","Epoch 291/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2256 - accuracy: 0.8867 - val_loss: 0.2500 - val_accuracy: 0.8819\n","Epoch 292/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2268 - accuracy: 0.8867 - val_loss: 0.2519 - val_accuracy: 0.8788\n","Epoch 293/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2234 - accuracy: 0.8892 - val_loss: 0.2539 - val_accuracy: 0.8816\n","Epoch 294/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2244 - accuracy: 0.8874 - val_loss: 0.2503 - val_accuracy: 0.8826\n","Epoch 295/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2302 - accuracy: 0.8865 - val_loss: 0.2544 - val_accuracy: 0.8798\n","Epoch 296/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2336 - accuracy: 0.8816 - val_loss: 0.2496 - val_accuracy: 0.8813\n","Epoch 297/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2267 - accuracy: 0.8894 - val_loss: 0.2532 - val_accuracy: 0.8814\n","Epoch 298/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2238 - accuracy: 0.8897 - val_loss: 0.2507 - val_accuracy: 0.8802\n","Epoch 299/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2205 - accuracy: 0.8907 - val_loss: 0.2483 - val_accuracy: 0.8824\n","Epoch 300/500\n","24/24 [==============================] - 1s 54ms/step - loss: 0.2270 - accuracy: 0.8865 - val_loss: 0.2495 - val_accuracy: 0.8825\n","Epoch 301/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2192 - accuracy: 0.8899 - val_loss: 0.2518 - val_accuracy: 0.8795\n","Epoch 302/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2228 - accuracy: 0.8878 - val_loss: 0.2540 - val_accuracy: 0.8808\n","Epoch 303/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2257 - accuracy: 0.8891 - val_loss: 0.2514 - val_accuracy: 0.8812\n","Epoch 304/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2228 - accuracy: 0.8913 - val_loss: 0.2498 - val_accuracy: 0.8814\n","Epoch 305/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2214 - accuracy: 0.8906 - val_loss: 0.2544 - val_accuracy: 0.8815\n","Epoch 306/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2267 - accuracy: 0.8862 - val_loss: 0.2525 - val_accuracy: 0.8821\n","Epoch 307/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2238 - accuracy: 0.8873 - val_loss: 0.2503 - val_accuracy: 0.8802\n","Epoch 308/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2238 - accuracy: 0.8898 - val_loss: 0.2487 - val_accuracy: 0.8805\n","Epoch 309/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2273 - accuracy: 0.8863 - val_loss: 0.2502 - val_accuracy: 0.8796\n","Epoch 310/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2213 - accuracy: 0.8891 - val_loss: 0.2520 - val_accuracy: 0.8783\n","Epoch 311/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2220 - accuracy: 0.8875 - val_loss: 0.2521 - val_accuracy: 0.8801\n","Epoch 312/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2225 - accuracy: 0.8885 - val_loss: 0.2546 - val_accuracy: 0.8820\n","Epoch 313/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2183 - accuracy: 0.8897 - val_loss: 0.2525 - val_accuracy: 0.8817\n","Epoch 314/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2236 - accuracy: 0.8874 - val_loss: 0.2546 - val_accuracy: 0.8821\n","Epoch 315/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2234 - accuracy: 0.8886 - val_loss: 0.2521 - val_accuracy: 0.8800\n","Epoch 316/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2230 - accuracy: 0.8888 - val_loss: 0.2514 - val_accuracy: 0.8807\n","Epoch 317/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2204 - accuracy: 0.8894 - val_loss: 0.2531 - val_accuracy: 0.8802\n","Epoch 318/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2254 - accuracy: 0.8906 - val_loss: 0.2526 - val_accuracy: 0.8812\n","Epoch 319/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2223 - accuracy: 0.8885 - val_loss: 0.2514 - val_accuracy: 0.8791\n","Epoch 320/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2238 - accuracy: 0.8876 - val_loss: 0.2536 - val_accuracy: 0.8808\n","Epoch 321/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2210 - accuracy: 0.8885 - val_loss: 0.2543 - val_accuracy: 0.8787\n","Epoch 322/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2213 - accuracy: 0.8909 - val_loss: 0.2533 - val_accuracy: 0.8828\n","Epoch 323/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2230 - accuracy: 0.8855 - val_loss: 0.2543 - val_accuracy: 0.8807\n","Epoch 324/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2221 - accuracy: 0.8904 - val_loss: 0.2540 - val_accuracy: 0.8813\n","Epoch 325/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2216 - accuracy: 0.8896 - val_loss: 0.2521 - val_accuracy: 0.8813\n","Epoch 326/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2232 - accuracy: 0.8902 - val_loss: 0.2542 - val_accuracy: 0.8813\n","Epoch 327/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2230 - accuracy: 0.8860 - val_loss: 0.2529 - val_accuracy: 0.8814\n","Epoch 328/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2205 - accuracy: 0.8921 - val_loss: 0.2558 - val_accuracy: 0.8804\n","Epoch 329/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2248 - accuracy: 0.8867 - val_loss: 0.2625 - val_accuracy: 0.8774\n","Epoch 330/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2268 - accuracy: 0.8859 - val_loss: 0.2634 - val_accuracy: 0.8802\n","Epoch 331/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2279 - accuracy: 0.8886 - val_loss: 0.2522 - val_accuracy: 0.8819\n","Epoch 332/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2201 - accuracy: 0.8899 - val_loss: 0.2528 - val_accuracy: 0.8795\n","Epoch 333/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2256 - accuracy: 0.8873 - val_loss: 0.2542 - val_accuracy: 0.8822\n","Epoch 334/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2192 - accuracy: 0.8892 - val_loss: 0.2521 - val_accuracy: 0.8802\n","Epoch 335/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2203 - accuracy: 0.8906 - val_loss: 0.2565 - val_accuracy: 0.8781\n","Epoch 336/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2208 - accuracy: 0.8868 - val_loss: 0.2532 - val_accuracy: 0.8793\n","Epoch 337/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2175 - accuracy: 0.8921 - val_loss: 0.2543 - val_accuracy: 0.8809\n","Epoch 338/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2186 - accuracy: 0.8934 - val_loss: 0.2536 - val_accuracy: 0.8798\n","Epoch 339/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2197 - accuracy: 0.8918 - val_loss: 0.2575 - val_accuracy: 0.8811\n","Epoch 340/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2208 - accuracy: 0.8895 - val_loss: 0.2559 - val_accuracy: 0.8799\n","Epoch 341/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2140 - accuracy: 0.8927 - val_loss: 0.2572 - val_accuracy: 0.8800\n","Epoch 342/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2199 - accuracy: 0.8909 - val_loss: 0.2556 - val_accuracy: 0.8790\n","Epoch 343/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2229 - accuracy: 0.8887 - val_loss: 0.2563 - val_accuracy: 0.8782\n","Epoch 344/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2192 - accuracy: 0.8890 - val_loss: 0.2589 - val_accuracy: 0.8795\n","Epoch 345/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2202 - accuracy: 0.8900 - val_loss: 0.2566 - val_accuracy: 0.8799\n","Epoch 346/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2184 - accuracy: 0.8908 - val_loss: 0.2571 - val_accuracy: 0.8806\n","Epoch 347/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2209 - accuracy: 0.8892 - val_loss: 0.2552 - val_accuracy: 0.8801\n","Epoch 348/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2210 - accuracy: 0.8880 - val_loss: 0.2587 - val_accuracy: 0.8780\n","Epoch 349/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2229 - accuracy: 0.8892 - val_loss: 0.2574 - val_accuracy: 0.8814\n","Epoch 350/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2188 - accuracy: 0.8904 - val_loss: 0.2552 - val_accuracy: 0.8788\n","Epoch 351/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2210 - accuracy: 0.8889 - val_loss: 0.2610 - val_accuracy: 0.8766\n","Epoch 352/500\n","24/24 [==============================] - 1s 53ms/step - loss: 0.2199 - accuracy: 0.8916 - val_loss: 0.2531 - val_accuracy: 0.8805\n","Epoch 353/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2182 - accuracy: 0.8911 - val_loss: 0.2554 - val_accuracy: 0.8811\n","Epoch 354/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2128 - accuracy: 0.8950 - val_loss: 0.2573 - val_accuracy: 0.8811\n","Epoch 355/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2184 - accuracy: 0.8907 - val_loss: 0.2546 - val_accuracy: 0.8809\n","Epoch 356/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2165 - accuracy: 0.8892 - val_loss: 0.2603 - val_accuracy: 0.8796\n","Epoch 357/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2206 - accuracy: 0.8875 - val_loss: 0.2565 - val_accuracy: 0.8793\n","Epoch 358/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2209 - accuracy: 0.8870 - val_loss: 0.2632 - val_accuracy: 0.8803\n","Epoch 359/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2224 - accuracy: 0.8889 - val_loss: 0.2610 - val_accuracy: 0.8767\n","Epoch 360/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2201 - accuracy: 0.8909 - val_loss: 0.2597 - val_accuracy: 0.8792\n","Epoch 361/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2139 - accuracy: 0.8940 - val_loss: 0.2556 - val_accuracy: 0.8808\n","Epoch 362/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2184 - accuracy: 0.8904 - val_loss: 0.2572 - val_accuracy: 0.8793\n","Epoch 363/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2155 - accuracy: 0.8915 - val_loss: 0.2571 - val_accuracy: 0.8805\n","Epoch 364/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2205 - accuracy: 0.8912 - val_loss: 0.2582 - val_accuracy: 0.8802\n","Epoch 365/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2214 - accuracy: 0.8895 - val_loss: 0.2621 - val_accuracy: 0.8758\n","Epoch 366/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2193 - accuracy: 0.8923 - val_loss: 0.2590 - val_accuracy: 0.8807\n","Epoch 367/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2186 - accuracy: 0.8890 - val_loss: 0.2577 - val_accuracy: 0.8813\n","Epoch 368/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2153 - accuracy: 0.8930 - val_loss: 0.2608 - val_accuracy: 0.8812\n","Epoch 369/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2118 - accuracy: 0.8927 - val_loss: 0.2609 - val_accuracy: 0.8765\n","Epoch 370/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2169 - accuracy: 0.8941 - val_loss: 0.2562 - val_accuracy: 0.8798\n","Epoch 371/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2177 - accuracy: 0.8899 - val_loss: 0.2589 - val_accuracy: 0.8794\n","Epoch 372/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2193 - accuracy: 0.8916 - val_loss: 0.2663 - val_accuracy: 0.8778\n","Epoch 373/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2187 - accuracy: 0.8911 - val_loss: 0.2569 - val_accuracy: 0.8811\n","Epoch 374/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2194 - accuracy: 0.8923 - val_loss: 0.2560 - val_accuracy: 0.8809\n","Epoch 375/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2138 - accuracy: 0.8934 - val_loss: 0.2592 - val_accuracy: 0.8824\n","Epoch 376/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2135 - accuracy: 0.8927 - val_loss: 0.2559 - val_accuracy: 0.8794\n","Epoch 377/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2206 - accuracy: 0.8883 - val_loss: 0.2602 - val_accuracy: 0.8794\n","Epoch 378/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2127 - accuracy: 0.8933 - val_loss: 0.2591 - val_accuracy: 0.8791\n","Epoch 379/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2147 - accuracy: 0.8920 - val_loss: 0.2607 - val_accuracy: 0.8795\n","Epoch 380/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2124 - accuracy: 0.8954 - val_loss: 0.2623 - val_accuracy: 0.8779\n","Epoch 381/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2155 - accuracy: 0.8939 - val_loss: 0.2598 - val_accuracy: 0.8804\n","Epoch 382/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2134 - accuracy: 0.8937 - val_loss: 0.2619 - val_accuracy: 0.8799\n","Epoch 383/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2124 - accuracy: 0.8937 - val_loss: 0.2605 - val_accuracy: 0.8799\n","Epoch 384/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2169 - accuracy: 0.8901 - val_loss: 0.2590 - val_accuracy: 0.8805\n","Epoch 385/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2130 - accuracy: 0.8939 - val_loss: 0.2598 - val_accuracy: 0.8815\n","Epoch 386/500\n","24/24 [==============================] - 1s 52ms/step - loss: 0.2151 - accuracy: 0.8926 - val_loss: 0.2618 - val_accuracy: 0.8780\n","Epoch 387/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2139 - accuracy: 0.8938 - val_loss: 0.2609 - val_accuracy: 0.8804\n","Epoch 388/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2188 - accuracy: 0.8901 - val_loss: 0.2636 - val_accuracy: 0.8780\n","Epoch 389/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2162 - accuracy: 0.8904 - val_loss: 0.2583 - val_accuracy: 0.8781\n","Epoch 390/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2111 - accuracy: 0.8948 - val_loss: 0.2584 - val_accuracy: 0.8798\n","Epoch 391/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2146 - accuracy: 0.8932 - val_loss: 0.2670 - val_accuracy: 0.8813\n","Epoch 392/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2165 - accuracy: 0.8931 - val_loss: 0.2669 - val_accuracy: 0.8799\n","Epoch 393/500\n","24/24 [==============================] - 1s 48ms/step - loss: 0.2205 - accuracy: 0.8901 - val_loss: 0.2619 - val_accuracy: 0.8764\n","Epoch 394/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2176 - accuracy: 0.8902 - val_loss: 0.2600 - val_accuracy: 0.8800\n","Epoch 395/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2174 - accuracy: 0.8916 - val_loss: 0.2596 - val_accuracy: 0.8783\n","Epoch 396/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2120 - accuracy: 0.8928 - val_loss: 0.2587 - val_accuracy: 0.8797\n","Epoch 397/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2142 - accuracy: 0.8915 - val_loss: 0.2619 - val_accuracy: 0.8800\n","Epoch 398/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2128 - accuracy: 0.8952 - val_loss: 0.2661 - val_accuracy: 0.8797\n","Epoch 399/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2137 - accuracy: 0.8913 - val_loss: 0.2628 - val_accuracy: 0.8790\n","Epoch 400/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2112 - accuracy: 0.8926 - val_loss: 0.2652 - val_accuracy: 0.8734\n","Epoch 401/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2157 - accuracy: 0.8922 - val_loss: 0.2618 - val_accuracy: 0.8799\n","Epoch 402/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2101 - accuracy: 0.8941 - val_loss: 0.2608 - val_accuracy: 0.8798\n","Epoch 403/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2182 - accuracy: 0.8926 - val_loss: 0.2627 - val_accuracy: 0.8822\n","Epoch 404/500\n","24/24 [==============================] - 1s 52ms/step - loss: 0.2153 - accuracy: 0.8920 - val_loss: 0.2598 - val_accuracy: 0.8790\n","Epoch 405/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2150 - accuracy: 0.8916 - val_loss: 0.2647 - val_accuracy: 0.8794\n","Epoch 406/500\n","24/24 [==============================] - 1s 52ms/step - loss: 0.2157 - accuracy: 0.8915 - val_loss: 0.2633 - val_accuracy: 0.8797\n","Epoch 407/500\n","24/24 [==============================] - 1s 61ms/step - loss: 0.2116 - accuracy: 0.8935 - val_loss: 0.2664 - val_accuracy: 0.8791\n","Epoch 408/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2109 - accuracy: 0.8944 - val_loss: 0.2653 - val_accuracy: 0.8780\n","Epoch 409/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2083 - accuracy: 0.8976 - val_loss: 0.2670 - val_accuracy: 0.8791\n","Epoch 410/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2169 - accuracy: 0.8924 - val_loss: 0.2679 - val_accuracy: 0.8764\n","Epoch 411/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2174 - accuracy: 0.8904 - val_loss: 0.2631 - val_accuracy: 0.8797\n","Epoch 412/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2119 - accuracy: 0.8936 - val_loss: 0.2644 - val_accuracy: 0.8812\n","Epoch 413/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2091 - accuracy: 0.8945 - val_loss: 0.2652 - val_accuracy: 0.8793\n","Epoch 414/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2150 - accuracy: 0.8922 - val_loss: 0.2640 - val_accuracy: 0.8756\n","Epoch 415/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2134 - accuracy: 0.8937 - val_loss: 0.2642 - val_accuracy: 0.8787\n","Epoch 416/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2071 - accuracy: 0.8996 - val_loss: 0.2658 - val_accuracy: 0.8777\n","Epoch 417/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2154 - accuracy: 0.8945 - val_loss: 0.2678 - val_accuracy: 0.8790\n","Epoch 418/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2106 - accuracy: 0.8929 - val_loss: 0.2661 - val_accuracy: 0.8810\n","Epoch 419/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2069 - accuracy: 0.8968 - val_loss: 0.2706 - val_accuracy: 0.8808\n","Epoch 420/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2128 - accuracy: 0.8940 - val_loss: 0.2678 - val_accuracy: 0.8775\n","Epoch 421/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2111 - accuracy: 0.8971 - val_loss: 0.2654 - val_accuracy: 0.8791\n","Epoch 422/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2089 - accuracy: 0.8962 - val_loss: 0.2647 - val_accuracy: 0.8793\n","Epoch 423/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2064 - accuracy: 0.8964 - val_loss: 0.2640 - val_accuracy: 0.8767\n","Epoch 424/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2122 - accuracy: 0.8932 - val_loss: 0.2710 - val_accuracy: 0.8792\n","Epoch 425/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2080 - accuracy: 0.8967 - val_loss: 0.2692 - val_accuracy: 0.8790\n","Epoch 426/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2118 - accuracy: 0.8914 - val_loss: 0.2682 - val_accuracy: 0.8787\n","Epoch 427/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2127 - accuracy: 0.8914 - val_loss: 0.2741 - val_accuracy: 0.8791\n","Epoch 428/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2087 - accuracy: 0.8927 - val_loss: 0.2732 - val_accuracy: 0.8798\n","Epoch 429/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2118 - accuracy: 0.8951 - val_loss: 0.2682 - val_accuracy: 0.8797\n","Epoch 430/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2085 - accuracy: 0.8967 - val_loss: 0.2684 - val_accuracy: 0.8775\n","Epoch 431/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2120 - accuracy: 0.8925 - val_loss: 0.2705 - val_accuracy: 0.8781\n","Epoch 432/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2101 - accuracy: 0.8935 - val_loss: 0.2690 - val_accuracy: 0.8760\n","Epoch 433/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2083 - accuracy: 0.8970 - val_loss: 0.2714 - val_accuracy: 0.8768\n","Epoch 434/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2078 - accuracy: 0.8953 - val_loss: 0.2686 - val_accuracy: 0.8776\n","Epoch 435/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2083 - accuracy: 0.8938 - val_loss: 0.2708 - val_accuracy: 0.8794\n","Epoch 436/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2144 - accuracy: 0.8930 - val_loss: 0.2687 - val_accuracy: 0.8797\n","Epoch 437/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2099 - accuracy: 0.8936 - val_loss: 0.2732 - val_accuracy: 0.8817\n","Epoch 438/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2104 - accuracy: 0.8935 - val_loss: 0.2710 - val_accuracy: 0.8797\n","Epoch 439/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2074 - accuracy: 0.8958 - val_loss: 0.2686 - val_accuracy: 0.8786\n","Epoch 440/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2063 - accuracy: 0.8949 - val_loss: 0.2730 - val_accuracy: 0.8807\n","Epoch 441/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2086 - accuracy: 0.8958 - val_loss: 0.2686 - val_accuracy: 0.8784\n","Epoch 442/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2074 - accuracy: 0.8950 - val_loss: 0.2719 - val_accuracy: 0.8760\n","Epoch 443/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2053 - accuracy: 0.8978 - val_loss: 0.2728 - val_accuracy: 0.8780\n","Epoch 444/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2087 - accuracy: 0.8949 - val_loss: 0.2722 - val_accuracy: 0.8796\n","Epoch 445/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2081 - accuracy: 0.8952 - val_loss: 0.2738 - val_accuracy: 0.8800\n","Epoch 446/500\n","24/24 [==============================] - 1s 52ms/step - loss: 0.2102 - accuracy: 0.8954 - val_loss: 0.2710 - val_accuracy: 0.8764\n","Epoch 447/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2083 - accuracy: 0.8950 - val_loss: 0.2708 - val_accuracy: 0.8776\n","Epoch 448/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2092 - accuracy: 0.8977 - val_loss: 0.2791 - val_accuracy: 0.8797\n","Epoch 449/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2085 - accuracy: 0.8955 - val_loss: 0.2750 - val_accuracy: 0.8799\n","Epoch 450/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2124 - accuracy: 0.8948 - val_loss: 0.2777 - val_accuracy: 0.8800\n","Epoch 451/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2076 - accuracy: 0.8955 - val_loss: 0.2730 - val_accuracy: 0.8768\n","Epoch 452/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2110 - accuracy: 0.8957 - val_loss: 0.2779 - val_accuracy: 0.8783\n","Epoch 453/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2148 - accuracy: 0.8907 - val_loss: 0.2735 - val_accuracy: 0.8823\n","Epoch 454/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2074 - accuracy: 0.8957 - val_loss: 0.2740 - val_accuracy: 0.8763\n","Epoch 455/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2065 - accuracy: 0.8968 - val_loss: 0.2709 - val_accuracy: 0.8776\n","Epoch 456/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2130 - accuracy: 0.8923 - val_loss: 0.2715 - val_accuracy: 0.8774\n","Epoch 457/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2100 - accuracy: 0.8922 - val_loss: 0.2727 - val_accuracy: 0.8782\n","Epoch 458/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2095 - accuracy: 0.8935 - val_loss: 0.2740 - val_accuracy: 0.8801\n","Epoch 459/500\n","24/24 [==============================] - 1s 55ms/step - loss: 0.2070 - accuracy: 0.8972 - val_loss: 0.2762 - val_accuracy: 0.8759\n","Epoch 460/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2060 - accuracy: 0.8949 - val_loss: 0.2724 - val_accuracy: 0.8771\n","Epoch 461/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2048 - accuracy: 0.8994 - val_loss: 0.2756 - val_accuracy: 0.8794\n","Epoch 462/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2078 - accuracy: 0.8964 - val_loss: 0.2733 - val_accuracy: 0.8798\n","Epoch 463/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2064 - accuracy: 0.8960 - val_loss: 0.2749 - val_accuracy: 0.8786\n","Epoch 464/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2011 - accuracy: 0.9004 - val_loss: 0.2747 - val_accuracy: 0.8774\n","Epoch 465/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2051 - accuracy: 0.8966 - val_loss: 0.2763 - val_accuracy: 0.8781\n","Epoch 466/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2073 - accuracy: 0.8962 - val_loss: 0.2728 - val_accuracy: 0.8777\n","Epoch 467/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2086 - accuracy: 0.8967 - val_loss: 0.2726 - val_accuracy: 0.8788\n","Epoch 468/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2072 - accuracy: 0.8994 - val_loss: 0.2761 - val_accuracy: 0.8768\n","Epoch 469/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2055 - accuracy: 0.8988 - val_loss: 0.2772 - val_accuracy: 0.8792\n","Epoch 470/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2082 - accuracy: 0.8959 - val_loss: 0.2747 - val_accuracy: 0.8774\n","Epoch 471/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2058 - accuracy: 0.8970 - val_loss: 0.2740 - val_accuracy: 0.8749\n","Epoch 472/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2043 - accuracy: 0.8954 - val_loss: 0.2760 - val_accuracy: 0.8807\n","Epoch 473/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2017 - accuracy: 0.9004 - val_loss: 0.2792 - val_accuracy: 0.8813\n","Epoch 474/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2076 - accuracy: 0.8959 - val_loss: 0.2760 - val_accuracy: 0.8781\n","Epoch 475/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2060 - accuracy: 0.8970 - val_loss: 0.2763 - val_accuracy: 0.8775\n","Epoch 476/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.1997 - accuracy: 0.8990 - val_loss: 0.2791 - val_accuracy: 0.8786\n","Epoch 477/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2057 - accuracy: 0.8971 - val_loss: 0.2753 - val_accuracy: 0.8750\n","Epoch 478/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2027 - accuracy: 0.8976 - val_loss: 0.2792 - val_accuracy: 0.8817\n","Epoch 479/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2094 - accuracy: 0.8947 - val_loss: 0.2800 - val_accuracy: 0.8753\n","Epoch 480/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2004 - accuracy: 0.9015 - val_loss: 0.2782 - val_accuracy: 0.8783\n","Epoch 481/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2081 - accuracy: 0.8965 - val_loss: 0.2792 - val_accuracy: 0.8763\n","Epoch 482/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2046 - accuracy: 0.8979 - val_loss: 0.2806 - val_accuracy: 0.8744\n","Epoch 483/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2010 - accuracy: 0.9017 - val_loss: 0.2807 - val_accuracy: 0.8741\n","Epoch 484/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2054 - accuracy: 0.8985 - val_loss: 0.2808 - val_accuracy: 0.8746\n","Epoch 485/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2085 - accuracy: 0.8944 - val_loss: 0.2826 - val_accuracy: 0.8780\n","Epoch 486/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2082 - accuracy: 0.8968 - val_loss: 0.2863 - val_accuracy: 0.8769\n","Epoch 487/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2082 - accuracy: 0.8946 - val_loss: 0.2815 - val_accuracy: 0.8775\n","Epoch 488/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2043 - accuracy: 0.8963 - val_loss: 0.2832 - val_accuracy: 0.8805\n","Epoch 489/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2066 - accuracy: 0.8956 - val_loss: 0.2808 - val_accuracy: 0.8809\n","Epoch 490/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2048 - accuracy: 0.8978 - val_loss: 0.2805 - val_accuracy: 0.8761\n","Epoch 491/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2026 - accuracy: 0.8967 - val_loss: 0.2807 - val_accuracy: 0.8794\n","Epoch 492/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2034 - accuracy: 0.8964 - val_loss: 0.2815 - val_accuracy: 0.8787\n","Epoch 493/500\n","24/24 [==============================] - 1s 51ms/step - loss: 0.2010 - accuracy: 0.8993 - val_loss: 0.2820 - val_accuracy: 0.8765\n","Epoch 494/500\n","24/24 [==============================] - 1s 49ms/step - loss: 0.2032 - accuracy: 0.8975 - val_loss: 0.2773 - val_accuracy: 0.8793\n","Epoch 495/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2018 - accuracy: 0.8983 - val_loss: 0.2844 - val_accuracy: 0.8775\n","Epoch 496/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2020 - accuracy: 0.8977 - val_loss: 0.2839 - val_accuracy: 0.8767\n","Epoch 497/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2051 - accuracy: 0.8963 - val_loss: 0.2846 - val_accuracy: 0.8759\n","Epoch 498/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.1999 - accuracy: 0.9001 - val_loss: 0.2814 - val_accuracy: 0.8804\n","Epoch 499/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2021 - accuracy: 0.9005 - val_loss: 0.2783 - val_accuracy: 0.8778\n","Epoch 500/500\n","24/24 [==============================] - 1s 50ms/step - loss: 0.2019 - accuracy: 0.9007 - val_loss: 0.2818 - val_accuracy: 0.8771\n","time: 9min 38s (started: 2021-01-09 03:27:52 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gQdeKMIwBOCF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610163455580,"user_tz":-420,"elapsed":589115,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"02342ca6-6cfd-4f39-9594-58a596885c02"},"source":["_, train_acc = model.evaluate(X_train, y_train, verbose=0)\r\n","_, test_acc = model.evaluate(X_test, y_test, verbose=0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 3.22 s (started: 2021-01-09 03:37:31 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qtqtdZBWCkfU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610163455581,"user_tz":-420,"elapsed":589112,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"a6d12068-e6b9-4577-cef0-ea49ea597209"},"source":["print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train: 0.901, Test: 0.877\n","time: 831 µs (started: 2021-01-09 03:37:34 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r-TigtSodiYY"},"source":["## Decision Tree"]},{"cell_type":"code","metadata":{"id":"3R_KFiT9dhdn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610163455583,"user_tz":-420,"elapsed":589109,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"7512f82d-7f35-40bb-dbf8-35245df4d32a"},"source":["param_dt = {\r\n","    'test_size': [0.9, 0.7, 0.5, 0.3, 0.1],\r\n","    'max_depth': [3, 5, 7],\r\n","    'criterion': ['gini', 'entropy']\r\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 2.26 ms (started: 2021-01-09 03:37:34 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mHqSQIvTfdO4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610163457686,"user_tz":-420,"elapsed":591207,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"4523eb5b-43af-48bc-ee6e-53a09ae14793"},"source":["row_format =\"{:>10}\" * (len(param_dt) + 2)\r\n","print(row_format.format('t_size', 'max_depth', 'criterion', 'akurasi', 'f1'))\r\n","acc_bfr = -math.inf\r\n","for i in param_dt['test_size']:\r\n","  for j in param_dt['max_depth']:\r\n","    for k in param_dt['criterion']:\r\n","      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\r\n","      dt = DecisionTreeClassifier(random_state=42, max_depth=j, criterion=k)\r\n","      dt.fit(X_train, y_train)\r\n","\r\n","      # print(y_test)\r\n","      pred = dt.predict(X_test)\r\n","      acc = metrics.accuracy_score(y_test, pred)\r\n","      f1 = metrics.f1_score(y_test, pred)\r\n","      if(acc > acc_bfr):\r\n","        acc_bfr = acc\r\n","        best_param_dt = {'t_size': i, 'max_depth': j, 'criterion': k, 'accuracy': acc, 'f1': f1}\r\n","        best_dt = dt\r\n","      print(row_format.format(str(i), str(j), str(k), '%.3f' % acc, '%.3f' % f1))\r\n","print('best param: ', best_param_dt)     "],"execution_count":null,"outputs":[{"output_type":"stream","text":["    t_size max_depth criterion   akurasi        f1\n","       0.9         3      gini     0.863     0.855\n","       0.9         3   entropy     0.857     0.851\n","       0.9         5      gini     0.879     0.862\n","       0.9         5   entropy     0.877     0.860\n","       0.9         7      gini     0.877     0.860\n","       0.9         7   entropy     0.877     0.859\n","       0.7         3      gini     0.865     0.857\n","       0.7         3   entropy     0.855     0.818\n","       0.7         5      gini     0.879     0.860\n","       0.7         5   entropy     0.872     0.844\n","       0.7         7      gini     0.880     0.864\n","       0.7         7   entropy     0.876     0.851\n","       0.5         3      gini     0.878     0.864\n","       0.5         3   entropy     0.859     0.825\n","       0.5         5      gini     0.882     0.868\n","       0.5         5   entropy     0.874     0.848\n","       0.5         7      gini     0.881     0.862\n","       0.5         7   entropy     0.883     0.868\n","       0.3         3      gini     0.877     0.864\n","       0.3         3   entropy     0.858     0.826\n","       0.3         5      gini     0.881     0.867\n","       0.3         5   entropy     0.877     0.866\n","       0.3         7      gini     0.884     0.870\n","       0.3         7   entropy     0.882     0.868\n","       0.1         3      gini     0.880     0.868\n","       0.1         3   entropy     0.860     0.830\n","       0.1         5      gini     0.884     0.871\n","       0.1         5   entropy     0.875     0.852\n","       0.1         7      gini     0.885     0.872\n","       0.1         7   entropy     0.885     0.871\n","best param:  {'t_size': 0.1, 'max_depth': 7, 'criterion': 'gini', 'accuracy': 0.8852118695811454, 'f1': 0.8724905046120457}\n","time: 2.27 s (started: 2021-01-09 03:37:34 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c5uVDVPwgXlP"},"source":["## SVM"]},{"cell_type":"code","metadata":{"id":"S0thU-8DggA3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610163457686,"user_tz":-420,"elapsed":591202,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"0731603b-429d-47b9-a4a2-720bc5c280cc"},"source":["param_svm = {\r\n","  'test_size': [0.9, 0.7, 0.5, 0.3, 0.1],  \r\n","  'C'    : [1, 10, 100, 0.1],\r\n","  'gamma': [0.1, 0.01, 0.001, 1.0],\r\n","  'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\r\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 3.49 ms (started: 2021-01-09 03:37:36 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwS1Kovsghju","executionInfo":{"status":"ok","timestamp":1610175592443,"user_tz":-420,"elapsed":12725954,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"140fa4e4-96af-4614-df4e-49e2e48759a1"},"source":["row_format =\"{:>10}\" * (len(param_svm) + 2)\r\n","print(row_format.format(*param_svm, 'akurasi', 'f1'))\r\n","acc_bfr = -math.inf\r\n","for i in param_svm['test_size']:\r\n","  for j in param_svm['C']:\r\n","    for k in param_svm['gamma']:\r\n","      for l in param_svm['kernel']:\r\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\r\n","        svc = SVC(C=j, gamma=k, kernel=l)\r\n","        svc.fit(X_train, y_train)\r\n","\r\n","        # print(y_test)\r\n","        pred = svc.predict(X_test)\r\n","        acc = metrics.accuracy_score(y_test, pred)\r\n","        f1 = metrics.f1_score(y_test, pred)\r\n","        if(acc > acc_bfr):\r\n","          acc_bfr = acc\r\n","          best_param_svm = {'t_size': i, 'C': j, 'gamma': k, 'kernel': l, 'accuracy': acc, 'f1': f1}\r\n","        print(row_format.format(str(i), str(j), str(k), str(l), '%.3f' % acc, '%.3f' % f1))\r\n","print('best param: ', best_param_svm)     "],"execution_count":null,"outputs":[{"output_type":"stream","text":[" test_size         C     gamma    kernel   akurasi        f1\n","       0.9         1       0.1    linear     0.879     0.860\n","       0.9         1       0.1      poly     0.856     0.814\n","       0.9         1       0.1       rbf     0.879     0.860\n","       0.9         1       0.1   sigmoid     0.879     0.860\n","       0.9         1      0.01    linear     0.879     0.860\n","       0.9         1      0.01      poly     0.564     0.000\n","       0.9         1      0.01       rbf     0.879     0.859\n","       0.9         1      0.01   sigmoid     0.879     0.859\n","       0.9         1     0.001    linear     0.879     0.860\n","       0.9         1     0.001      poly     0.564     0.000\n","       0.9         1     0.001       rbf     0.878     0.856\n","       0.9         1     0.001   sigmoid     0.877     0.853\n","       0.9         1       1.0    linear     0.879     0.860\n","       0.9         1       1.0      poly     0.877     0.852\n","       0.9         1       1.0       rbf     0.881     0.862\n","       0.9         1       1.0   sigmoid     0.591     0.533\n","       0.9        10       0.1    linear     0.879     0.860\n","       0.9        10       0.1      poly     0.874     0.847\n","       0.9        10       0.1       rbf     0.879     0.860\n","       0.9        10       0.1   sigmoid     0.879     0.860\n","       0.9        10      0.01    linear     0.879     0.860\n","       0.9        10      0.01      poly     0.564     0.000\n","       0.9        10      0.01       rbf     0.879     0.860\n","       0.9        10      0.01   sigmoid     0.879     0.860\n","       0.9        10     0.001    linear     0.879     0.860\n","       0.9        10     0.001      poly     0.564     0.000\n","       0.9        10     0.001       rbf     0.879     0.859\n","       0.9        10     0.001   sigmoid     0.879     0.859\n","       0.9        10       1.0    linear     0.879     0.860\n","       0.9        10       1.0      poly     0.877     0.853\n","       0.9        10       1.0       rbf     0.881     0.862\n","       0.9        10       1.0   sigmoid     0.590     0.532\n","       0.9       100       0.1    linear     0.879     0.860\n","       0.9       100       0.1      poly     0.877     0.851\n","       0.9       100       0.1       rbf     0.879     0.862\n","       0.9       100       0.1   sigmoid     0.877     0.854\n","       0.9       100      0.01    linear     0.879     0.860\n","       0.9       100      0.01      poly     0.755     0.614\n","       0.9       100      0.01       rbf     0.879     0.860\n","       0.9       100      0.01   sigmoid     0.879     0.860\n","       0.9       100     0.001    linear     0.879     0.860\n","       0.9       100     0.001      poly     0.564     0.000\n","       0.9       100     0.001       rbf     0.879     0.860\n","       0.9       100     0.001   sigmoid     0.879     0.860\n","       0.9       100       1.0    linear     0.879     0.860\n","       0.9       100       1.0      poly     0.877     0.853\n","       0.9       100       1.0       rbf     0.882     0.863\n","       0.9       100       1.0   sigmoid     0.590     0.532\n","       0.9       0.1       0.1    linear     0.879     0.860\n","       0.9       0.1       0.1      poly     0.755     0.614\n","       0.9       0.1       0.1       rbf     0.879     0.860\n","       0.9       0.1       0.1   sigmoid     0.879     0.859\n","       0.9       0.1      0.01    linear     0.879     0.860\n","       0.9       0.1      0.01      poly     0.564     0.000\n","       0.9       0.1      0.01       rbf     0.878     0.856\n","       0.9       0.1      0.01   sigmoid     0.877     0.853\n","       0.9       0.1     0.001    linear     0.879     0.860\n","       0.9       0.1     0.001      poly     0.564     0.000\n","       0.9       0.1     0.001       rbf     0.564     0.000\n","       0.9       0.1     0.001   sigmoid     0.564     0.000\n","       0.9       0.1       1.0    linear     0.879     0.860\n","       0.9       0.1       1.0      poly     0.877     0.851\n","       0.9       0.1       1.0       rbf     0.880     0.861\n","       0.9       0.1       1.0   sigmoid     0.600     0.544\n","       0.7         1       0.1    linear     0.880     0.860\n","       0.7         1       0.1      poly     0.867     0.835\n","       0.7         1       0.1       rbf     0.880     0.860\n","       0.7         1       0.1   sigmoid     0.880     0.861\n","       0.7         1      0.01    linear     0.880     0.860\n","       0.7         1      0.01      poly     0.562     0.000\n","       0.7         1      0.01       rbf     0.880     0.860\n","       0.7         1      0.01   sigmoid     0.879     0.860\n","       0.7         1     0.001    linear     0.880     0.860\n","       0.7         1     0.001      poly     0.562     0.000\n","       0.7         1     0.001       rbf     0.878     0.857\n","       0.7         1     0.001   sigmoid     0.878     0.856\n","       0.7         1       1.0    linear     0.880     0.860\n","       0.7         1       1.0      poly     0.876     0.851\n","       0.7         1       1.0       rbf     0.881     0.860\n","       0.7         1       1.0   sigmoid     0.588     0.525\n","       0.7        10       0.1    linear     0.880     0.860\n","       0.7        10       0.1      poly     0.875     0.848\n","       0.7        10       0.1       rbf     0.879     0.858\n","       0.7        10       0.1   sigmoid     0.879     0.860\n","       0.7        10      0.01    linear     0.880     0.860\n","       0.7        10      0.01      poly     0.562     0.000\n","       0.7        10      0.01       rbf     0.880     0.861\n","       0.7        10      0.01   sigmoid     0.880     0.860\n","       0.7        10     0.001    linear     0.880     0.860\n","       0.7        10     0.001      poly     0.562     0.000\n","       0.7        10     0.001       rbf     0.880     0.860\n","       0.7        10     0.001   sigmoid     0.879     0.860\n","       0.7        10       1.0    linear     0.880     0.860\n","       0.7        10       1.0      poly     0.877     0.852\n","       0.7        10       1.0       rbf     0.881     0.861\n","       0.7        10       1.0   sigmoid     0.588     0.524\n","       0.7       100       0.1    linear     0.880     0.860\n","       0.7       100       0.1      poly     0.876     0.850\n","       0.7       100       0.1       rbf     0.881     0.861\n","       0.7       100       0.1   sigmoid     0.874     0.851\n","       0.7       100      0.01    linear     0.880     0.860\n","       0.7       100      0.01      poly     0.823     0.755\n","       0.7       100      0.01       rbf     0.880     0.860\n","       0.7       100      0.01   sigmoid     0.880     0.861\n","       0.7       100     0.001    linear     0.880     0.860\n","       0.7       100     0.001      poly     0.562     0.000\n","       0.7       100     0.001       rbf     0.880     0.860\n","       0.7       100     0.001   sigmoid     0.880     0.860\n","       0.7       100       1.0    linear     0.880     0.860\n","       0.7       100       1.0      poly     0.877     0.851\n","       0.7       100       1.0       rbf     0.882     0.862\n","       0.7       100       1.0   sigmoid     0.588     0.524\n","       0.7       0.1       0.1    linear     0.880     0.860\n","       0.7       0.1       0.1      poly     0.823     0.755\n","       0.7       0.1       0.1       rbf     0.880     0.860\n","       0.7       0.1       0.1   sigmoid     0.880     0.860\n","       0.7       0.1      0.01    linear     0.880     0.860\n","       0.7       0.1      0.01      poly     0.562     0.000\n","       0.7       0.1      0.01       rbf     0.878     0.857\n","       0.7       0.1      0.01   sigmoid     0.878     0.856\n","       0.7       0.1     0.001    linear     0.880     0.860\n","       0.7       0.1     0.001      poly     0.562     0.000\n","       0.7       0.1     0.001       rbf     0.869     0.838\n","       0.7       0.1     0.001   sigmoid     0.565     0.014\n","       0.7       0.1       1.0    linear     0.880     0.860\n","       0.7       0.1       1.0      poly     0.876     0.850\n","       0.7       0.1       1.0       rbf     0.880     0.860\n","       0.7       0.1       1.0   sigmoid     0.591     0.528\n","       0.5         1       0.1    linear     0.881     0.861\n","       0.5         1       0.1      poly     0.870     0.840\n","       0.5         1       0.1       rbf     0.880     0.860\n","       0.5         1       0.1   sigmoid     0.880     0.861\n","       0.5         1      0.01    linear     0.881     0.861\n","       0.5         1      0.01      poly     0.563     0.000\n","       0.5         1      0.01       rbf     0.880     0.861\n","       0.5         1      0.01   sigmoid     0.880     0.861\n","       0.5         1     0.001    linear     0.881     0.861\n","       0.5         1     0.001      poly     0.563     0.000\n","       0.5         1     0.001       rbf     0.879     0.858\n","       0.5         1     0.001   sigmoid     0.879     0.857\n","       0.5         1       1.0    linear     0.881     0.861\n","       0.5         1       1.0      poly     0.877     0.852\n","       0.5         1       1.0       rbf     0.881     0.861\n","       0.5         1       1.0   sigmoid     0.590     0.527\n","       0.5        10       0.1    linear     0.881     0.861\n","       0.5        10       0.1      poly     0.876     0.850\n","       0.5        10       0.1       rbf     0.880     0.860\n","       0.5        10       0.1   sigmoid     0.864     0.845\n","       0.5        10      0.01    linear     0.881     0.861\n","       0.5        10      0.01      poly     0.625     0.249\n","       0.5        10      0.01       rbf     0.881     0.861\n","       0.5        10      0.01   sigmoid     0.880     0.861\n","       0.5        10     0.001    linear     0.881     0.861\n","       0.5        10     0.001      poly     0.563     0.000\n","       0.5        10     0.001       rbf     0.881     0.861\n","       0.5        10     0.001   sigmoid     0.880     0.861\n","       0.5        10       1.0    linear     0.881     0.861\n","       0.5        10       1.0      poly     0.877     0.852\n","       0.5        10       1.0       rbf     0.882     0.862\n","       0.5        10       1.0   sigmoid     0.590     0.526\n","       0.5       100       0.1    linear     0.881     0.861\n","       0.5       100       0.1      poly     0.877     0.851\n","       0.5       100       0.1       rbf     0.881     0.861\n","       0.5       100       0.1   sigmoid     0.863     0.840\n","       0.5       100      0.01    linear     0.881     0.861\n","       0.5       100      0.01      poly     0.839     0.785\n","       0.5       100      0.01       rbf     0.880     0.860\n","       0.5       100      0.01   sigmoid     0.880     0.861\n","       0.5       100     0.001    linear     0.881     0.861\n","       0.5       100     0.001      poly     0.563     0.000\n","       0.5       100     0.001       rbf     0.880     0.861\n","       0.5       100     0.001   sigmoid     0.880     0.861\n","       0.5       100       1.0    linear     0.881     0.861\n","       0.5       100       1.0      poly     0.877     0.852\n","       0.5       100       1.0       rbf     0.882     0.863\n","       0.5       100       1.0   sigmoid     0.590     0.526\n","       0.5       0.1       0.1    linear     0.880     0.861\n","       0.5       0.1       0.1      poly     0.839     0.785\n","       0.5       0.1       0.1       rbf     0.881     0.861\n","       0.5       0.1       0.1   sigmoid     0.880     0.861\n","       0.5       0.1      0.01    linear     0.880     0.861\n","       0.5       0.1      0.01      poly     0.563     0.000\n","       0.5       0.1      0.01       rbf     0.879     0.858\n","       0.5       0.1      0.01   sigmoid     0.878     0.857\n","       0.5       0.1     0.001    linear     0.880     0.861\n","       0.5       0.1     0.001      poly     0.563     0.000\n","       0.5       0.1     0.001       rbf     0.876     0.852\n","       0.5       0.1     0.001   sigmoid     0.841     0.788\n","       0.5       0.1       1.0    linear     0.880     0.861\n","       0.5       0.1       1.0      poly     0.877     0.851\n","       0.5       0.1       1.0       rbf     0.881     0.861\n","       0.5       0.1       1.0   sigmoid     0.592     0.529\n","       0.3         1       0.1    linear     0.880     0.861\n","       0.3         1       0.1      poly     0.873     0.844\n","       0.3         1       0.1       rbf     0.880     0.861\n","       0.3         1       0.1   sigmoid     0.880     0.861\n","       0.3         1      0.01    linear     0.880     0.861\n","       0.3         1      0.01      poly     0.560     0.000\n","       0.3         1      0.01       rbf     0.880     0.862\n","       0.3         1      0.01   sigmoid     0.880     0.861\n","       0.3         1     0.001    linear     0.880     0.861\n","       0.3         1     0.001      poly     0.560     0.000\n","       0.3         1     0.001       rbf     0.879     0.860\n","       0.3         1     0.001   sigmoid     0.878     0.858\n","       0.3         1       1.0    linear     0.880     0.861\n","       0.3         1       1.0      poly     0.878     0.854\n","       0.3         1       1.0       rbf     0.881     0.862\n","       0.3         1       1.0   sigmoid     0.587     0.528\n","       0.3        10       0.1    linear     0.880     0.861\n","       0.3        10       0.1      poly     0.877     0.852\n","       0.3        10       0.1       rbf     0.879     0.861\n","       0.3        10       0.1   sigmoid     0.860     0.841\n","       0.3        10      0.01    linear     0.880     0.861\n","       0.3        10      0.01      poly     0.703     0.493\n","       0.3        10      0.01       rbf     0.880     0.861\n","       0.3        10      0.01   sigmoid     0.880     0.861\n","       0.3        10     0.001    linear     0.880     0.861\n","       0.3        10     0.001      poly     0.560     0.000\n","       0.3        10     0.001       rbf     0.880     0.862\n","       0.3        10     0.001   sigmoid     0.880     0.861\n","       0.3        10       1.0    linear     0.880     0.861\n","       0.3        10       1.0      poly     0.877     0.853\n","       0.3        10       1.0       rbf     0.881     0.863\n","       0.3        10       1.0   sigmoid     0.587     0.528\n","       0.3       100       0.1    linear     0.880     0.861\n","       0.3       100       0.1      poly     0.878     0.853\n","       0.3       100       0.1       rbf     0.881     0.862\n","       0.3       100       0.1   sigmoid     0.857     0.836\n","       0.3       100      0.01    linear     0.880     0.861\n","       0.3       100      0.01      poly     0.847     0.800\n","       0.3       100      0.01       rbf     0.880     0.861\n","       0.3       100      0.01   sigmoid     0.880     0.861\n","       0.3       100     0.001    linear     0.880     0.861\n","       0.3       100     0.001      poly     0.560     0.000\n","       0.3       100     0.001       rbf     0.880     0.861\n","       0.3       100     0.001   sigmoid     0.880     0.861\n","       0.3       100       1.0    linear     0.880     0.861\n","       0.3       100       1.0      poly     0.877     0.853\n","       0.3       100       1.0       rbf     0.882     0.864\n","       0.3       100       1.0   sigmoid     0.587     0.528\n","       0.3       0.1       0.1    linear     0.880     0.861\n","       0.3       0.1       0.1      poly     0.847     0.800\n","       0.3       0.1       0.1       rbf     0.880     0.861\n","       0.3       0.1       0.1   sigmoid     0.880     0.861\n","       0.3       0.1      0.01    linear     0.880     0.861\n","       0.3       0.1      0.01      poly     0.560     0.000\n","       0.3       0.1      0.01       rbf     0.879     0.860\n","       0.3       0.1      0.01   sigmoid     0.878     0.858\n","       0.3       0.1     0.001    linear     0.880     0.861\n","       0.3       0.1     0.001      poly     0.560     0.000\n","       0.3       0.1     0.001       rbf     0.878     0.855\n","       0.3       0.1     0.001   sigmoid     0.875     0.849\n","       0.3       0.1       1.0    linear     0.880     0.861\n","       0.3       0.1       1.0      poly     0.878     0.853\n","       0.3       0.1       1.0       rbf     0.880     0.861\n","       0.3       0.1       1.0   sigmoid     0.589     0.530\n","       0.1         1       0.1    linear     0.882     0.865\n","       0.1         1       0.1      poly     0.876     0.851\n","       0.1         1       0.1       rbf     0.882     0.865\n","       0.1         1       0.1   sigmoid     0.881     0.865\n","       0.1         1      0.01    linear     0.882     0.865\n","       0.1         1      0.01      poly     0.556     0.000\n","       0.1         1      0.01       rbf     0.882     0.865\n","       0.1         1      0.01   sigmoid     0.882     0.865\n","       0.1         1     0.001    linear     0.882     0.865\n","       0.1         1     0.001      poly     0.556     0.000\n","       0.1         1     0.001       rbf     0.881     0.863\n","       0.1         1     0.001   sigmoid     0.879     0.861\n","       0.1         1       1.0    linear     0.882     0.865\n","       0.1         1       1.0      poly     0.879     0.858\n","       0.1         1       1.0       rbf     0.882     0.865\n","       0.1         1       1.0   sigmoid     0.587     0.529\n","       0.1        10       0.1    linear     0.882     0.865\n","       0.1        10       0.1      poly     0.878     0.855\n","       0.1        10       0.1       rbf     0.881     0.864\n","       0.1        10       0.1   sigmoid     0.878     0.858\n","       0.1        10      0.01    linear     0.882     0.865\n","       0.1        10      0.01      poly     0.741     0.592\n","       0.1        10      0.01       rbf     0.882     0.865\n","       0.1        10      0.01   sigmoid     0.882     0.865\n","       0.1        10     0.001    linear     0.882     0.865\n","       0.1        10     0.001      poly     0.556     0.000\n","       0.1        10     0.001       rbf     0.882     0.865\n","       0.1        10     0.001   sigmoid     0.882     0.865\n","       0.1        10       1.0    linear     0.882     0.865\n","       0.1        10       1.0      poly     0.880     0.858\n","       0.1        10       1.0       rbf     0.883     0.867\n","       0.1        10       1.0   sigmoid     0.586     0.529\n","       0.1       100       0.1    linear     0.882     0.865\n","       0.1       100       0.1      poly     0.880     0.857\n","       0.1       100       0.1       rbf     0.882     0.864\n","       0.1       100       0.1   sigmoid     0.856     0.837\n","       0.1       100      0.01    linear     0.882     0.865\n","       0.1       100      0.01      poly     0.855     0.815\n","       0.1       100      0.01       rbf     0.882     0.865\n","       0.1       100      0.01   sigmoid     0.882     0.865\n","       0.1       100     0.001    linear     0.882     0.865\n","       0.1       100     0.001      poly     0.556     0.000\n","       0.1       100     0.001       rbf     0.882     0.865\n","       0.1       100     0.001   sigmoid     0.882     0.865\n","       0.1       100       1.0    linear     0.882     0.865\n","       0.1       100       1.0      poly     0.880     0.858\n","       0.1       100       1.0       rbf     0.883     0.867\n","       0.1       100       1.0   sigmoid     0.586     0.529\n","       0.1       0.1       0.1    linear     0.882     0.865\n","       0.1       0.1       0.1      poly     0.855     0.815\n","       0.1       0.1       0.1       rbf     0.882     0.864\n","       0.1       0.1       0.1   sigmoid     0.882     0.865\n","       0.1       0.1      0.01    linear     0.882     0.865\n","       0.1       0.1      0.01      poly     0.556     0.000\n","       0.1       0.1      0.01       rbf     0.881     0.863\n","       0.1       0.1      0.01   sigmoid     0.879     0.860\n","       0.1       0.1     0.001    linear     0.882     0.865\n","       0.1       0.1     0.001      poly     0.556     0.000\n","       0.1       0.1     0.001       rbf     0.879     0.859\n","       0.1       0.1     0.001   sigmoid     0.877     0.855\n","       0.1       0.1       1.0    linear     0.882     0.865\n","       0.1       0.1       1.0      poly     0.880     0.857\n","       0.1       0.1       1.0       rbf     0.881     0.864\n","       0.1       0.1       1.0   sigmoid     0.588     0.530\n","best param:  {'t_size': 0.1, 'C': 10, 'gamma': 1.0, 'kernel': 'rbf', 'accuracy': 0.8832580290633777, 'f1': 0.866778149386845}\n","time: 3h 22min 14s (started: 2021-01-09 03:37:36 +00:00)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kwTUuS5ShORg"},"source":["## KNN"]},{"cell_type":"code","metadata":{"id":"zVqmjSfBhSP_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610176700523,"user_tz":-420,"elapsed":948,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"166532a2-efc9-491b-f190-86e47ca96315"},"source":["param_knn = {\r\n","  'test_size': [0.9, 0.7, 0.5, 0.3, 0.1],  \r\n","  'n_neighbor': [3, 5],\r\n","  'weights': ['uniform', 'distance'],\r\n","  'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\r\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 1.59 ms (started: 2021-01-09 07:18:19 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3uKkftDihU_O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610177119332,"user_tz":-420,"elapsed":418377,"user":{"displayName":"Kevin Angga Wijaya","photoUrl":"","userId":"13239624994805969288"}},"outputId":"95840024-f7ed-412d-ba1f-909c0e123202"},"source":["row_format =\"{:>10}\" * (len(param_knn) + 2)\r\n","print(row_format.format(*param_knn, 'akurasi', 'f1'))\r\n","acc_bfr = -math.inf\r\n","for i in param_knn['test_size']:\r\n","  for j in param_knn['n_neighbor']:\r\n","    for k in param_knn['weights']:\r\n","      for l in param_knn['algorithm']:\r\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=i, random_state=42)\r\n","        knn = KNeighborsClassifier(n_neighbors=j, weights=k, algorithm=l)\r\n","        knn.fit(X_train, y_train)\r\n","\r\n","        # print(y_test)\r\n","        pred = knn.predict(X_test)\r\n","        acc = metrics.accuracy_score(y_test, pred)\r\n","        f1 = metrics.f1_score(y_test, pred)\r\n","        if(acc > acc_bfr):\r\n","          acc_bfr = acc\r\n","          best_param_knn = {'t_size': i, 'n_beighbors': j, 'weights': k, 'algorithm': l, 'accuracy': acc, 'f1': f1}\r\n","        print(row_format.format(str(i), str(j), str(k), str(l), '%.3f' % acc, '%.3f' % f1))\r\n","print('best param: ', best_param_knn)     "],"execution_count":null,"outputs":[{"output_type":"stream","text":[" test_sizen_neighbor   weights algorithm   akurasi        f1\n","       0.9         3   uniform      auto     0.865     0.846\n","       0.9         3   uniform ball_tree     0.865     0.845\n","       0.9         3   uniform   kd_tree     0.865     0.846\n","       0.9         3   uniform     brute     0.865     0.846\n","       0.9         3  distance      auto     0.865     0.846\n","       0.9         3  distance ball_tree     0.865     0.846\n","       0.9         3  distance   kd_tree     0.865     0.846\n","       0.9         3  distance     brute     0.865     0.846\n","       0.9         5   uniform      auto     0.871     0.852\n","       0.9         5   uniform ball_tree     0.871     0.851\n","       0.9         5   uniform   kd_tree     0.871     0.852\n","       0.9         5   uniform     brute     0.871     0.851\n","       0.9         5  distance      auto     0.870     0.851\n","       0.9         5  distance ball_tree     0.870     0.851\n","       0.9         5  distance   kd_tree     0.870     0.851\n","       0.9         5  distance     brute     0.870     0.851\n","       0.7         3   uniform      auto     0.870     0.851\n","       0.7         3   uniform ball_tree     0.871     0.851\n","       0.7         3   uniform   kd_tree     0.870     0.851\n","       0.7         3   uniform     brute     0.870     0.850\n","       0.7         3  distance      auto     0.875     0.855\n","       0.7         3  distance ball_tree     0.875     0.856\n","       0.7         3  distance   kd_tree     0.875     0.855\n","       0.7         3  distance     brute     0.875     0.856\n","       0.7         5   uniform      auto     0.873     0.854\n","       0.7         5   uniform ball_tree     0.873     0.854\n","       0.7         5   uniform   kd_tree     0.873     0.854\n","       0.7         5   uniform     brute     0.873     0.854\n","       0.7         5  distance      auto     0.879     0.860\n","       0.7         5  distance ball_tree     0.879     0.860\n","       0.7         5  distance   kd_tree     0.879     0.860\n","       0.7         5  distance     brute     0.879     0.860\n","       0.5         3   uniform      auto     0.876     0.857\n","       0.5         3   uniform ball_tree     0.876     0.857\n","       0.5         3   uniform   kd_tree     0.876     0.857\n","       0.5         3   uniform     brute     0.875     0.856\n","       0.5         3  distance      auto     0.887     0.868\n","       0.5         3  distance ball_tree     0.887     0.868\n","       0.5         3  distance   kd_tree     0.887     0.868\n","       0.5         3  distance     brute     0.886     0.867\n","       0.5         5   uniform      auto     0.877     0.859\n","       0.5         5   uniform ball_tree     0.877     0.859\n","       0.5         5   uniform   kd_tree     0.877     0.859\n","       0.5         5   uniform     brute     0.878     0.859\n","       0.5         5  distance      auto     0.888     0.870\n","       0.5         5  distance ball_tree     0.888     0.870\n","       0.5         5  distance   kd_tree     0.888     0.870\n","       0.5         5  distance     brute     0.888     0.870\n","       0.3         3   uniform      auto     0.878     0.861\n","       0.3         3   uniform ball_tree     0.878     0.861\n","       0.3         3   uniform   kd_tree     0.878     0.861\n","       0.3         3   uniform     brute     0.878     0.861\n","       0.3         3  distance      auto     0.890     0.874\n","       0.3         3  distance ball_tree     0.890     0.874\n","       0.3         3  distance   kd_tree     0.890     0.874\n","       0.3         3  distance     brute     0.891     0.875\n","       0.3         5   uniform      auto     0.878     0.860\n","       0.3         5   uniform ball_tree     0.878     0.860\n","       0.3         5   uniform   kd_tree     0.878     0.860\n","       0.3         5   uniform     brute     0.879     0.861\n","       0.3         5  distance      auto     0.893     0.876\n","       0.3         5  distance ball_tree     0.893     0.876\n","       0.3         5  distance   kd_tree     0.893     0.876\n","       0.3         5  distance     brute     0.894     0.877\n","       0.1         3   uniform      auto     0.884     0.868\n","       0.1         3   uniform ball_tree     0.884     0.868\n","       0.1         3   uniform   kd_tree     0.884     0.868\n","       0.1         3   uniform     brute     0.880     0.863\n","       0.1         3  distance      auto     0.900     0.885\n","       0.1         3  distance ball_tree     0.900     0.885\n","       0.1         3  distance   kd_tree     0.900     0.885\n","       0.1         3  distance     brute     0.896     0.881\n","       0.1         5   uniform      auto     0.883     0.868\n","       0.1         5   uniform ball_tree     0.883     0.868\n","       0.1         5   uniform   kd_tree     0.883     0.868\n","       0.1         5   uniform     brute     0.881     0.865\n","       0.1         5  distance      auto     0.901     0.886\n","       0.1         5  distance ball_tree     0.901     0.886\n","       0.1         5  distance   kd_tree     0.901     0.886\n","       0.1         5  distance     brute     0.901     0.886\n","best param:  {'t_size': 0.1, 'n_beighbors': 5, 'weights': 'distance', 'algorithm': 'auto', 'accuracy': 0.9013310538527293, 'f1': 0.8864530635188307}\n","time: 6min 57s (started: 2021-01-09 07:18:20 +00:00)\n"],"name":"stdout"}]}]}